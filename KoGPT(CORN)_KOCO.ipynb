{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "MODEL_NAME= \"skt/kogpt2-base-v2\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME,\n",
    "                                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                                                    pad_token='<pad>', mask_token='<mask>') \n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39b0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='left', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21abbfd",
   "metadata": {},
   "source": [
    "# Load Koco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  hate\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...     2\n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...     0\n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...     2\n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데     0\n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...     2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_hate_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_hate_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"hate\"].values\n",
    "test_label =  koco_test_df[\"hate\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c08e8e",
   "metadata": {},
   "source": [
    "# 모델 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4cc2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.losses import CoralLoss, corn_loss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label\n",
    "from typing import Optional, Union, Tuple\n",
    "from transformers.activations import get_activation\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb42205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput, SequenceClassifierOutputWithPast\n",
    "from transformers import GPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76842350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2PreTrainedModel, GPT2Model\n",
    "class GPT2ForSequenceClassification(GPT2PreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.score = nn.Linear(config.n_embd, self.num_labels, bias=False)\n",
    "        self.coral_layer = CoralLayer(config.n_embd, config.num_labels)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels-1)\n",
    "        self.hidden_states = None\n",
    "        self.logits = None\n",
    "        self.pooled_logits = None\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        #logits = self.coral_layer(hidden_states)\n",
    "        logits = self.classifier(hidden_states)\n",
    "        self.hidden_states = hidden_states\n",
    "        self.logits = logits\n",
    "        #logits = self.coral_layer(hidden_states)\n",
    "        #probas = torch.sigmoid(logits)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            batch_size, sequence_length = input_ids.shape[:2]\n",
    "        else:\n",
    "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
    "\n",
    "        assert (\n",
    "            self.config.pad_token_id is not None or batch_size == 1\n",
    "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
    "        if self.config.pad_token_id is None:\n",
    "            sequence_lengths = -1\n",
    "        else:\n",
    "            if input_ids is not None:\n",
    "                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n",
    "            else:\n",
    "                sequence_lengths = -1\n",
    "                logger.warning(\n",
    "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
    "                    \"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
    "                )\n",
    "\n",
    "        pooled_logits = logits[torch.arange(batch_size, device=logits.device), sequence_lengths] #probas\n",
    "        #logits = self.coral_layer(pooled_logits)\n",
    "        probas = torch.sigmoid(pooled_logits)\n",
    "        probas = torch.cumprod(probas, dim=1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(pooled_logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(pooled_logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(pooled_logits, labels)\n",
    "            elif self.config.problem_type == \"CORAL\":\n",
    "                # iw = torch.tensor([0.7, 0.3]).to(device)\n",
    "                # loss_fct = CoralLoss()\n",
    "                # levels = levels_from_labelbatch(labels.view(-1) , num_classes=3).to(device)\n",
    "                #loss = loss_fct(pooled_logits, levels, importance_weights=iw)\n",
    "                loss = corn_loss(pooled_logits, labels, self.config.num_labels)\n",
    "                    \n",
    "        if not return_dict:\n",
    "            output = (pooled_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=probas,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c0a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight', 'classifier.bias', 'coral_layer.coral_weights.weight', 'coral_layer.coral_bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       "  (coral_layer): CoralLayer(\n",
       "    (coral_weights): Linear(in_features=768, out_features=1, bias=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, problem_type='CORAL')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/', # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size=4,      # train batch_size 설정\n",
    "    per_device_eval_batch_size=32,      # test batch_size 설정\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/logs/',# 학습log 저장경로\n",
    "    logging_steps=500,                  # 학습log 기록 단위\n",
    "    save_total_limit=2,                 # 학습결과 저장 최대갯수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 학습하고자하는 🤗 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 Training Arguments\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30264903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 20:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.726600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.606100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.519300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.361300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.286200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.198400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.192900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-11000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORN_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.30748700177657445, metrics={'train_runtime': 1210.3603, 'train_samples_per_second': 65.237, 'train_steps_per_second': 16.309, 'total_flos': 2579092194631680.0, 'train_loss': 0.30748700177657445, 'epoch': 10.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.947604775428772,\n",
       " 'eval_accuracy': 0.33970276008492567,\n",
       " 'eval_f1': 0.16904384574749076,\n",
       " 'eval_precision': 0.11323425336164189,\n",
       " 'eval_recall': 0.3333333333333333,\n",
       " 'eval_runtime': 0.5279,\n",
       " 'eval_samples_per_second': 892.297,\n",
       " 'eval_steps_per_second': 28.417,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d8cdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.34584869e-05, 3.12554876e-05],\n",
       "       [1.02491397e-02, 3.48568754e-03],\n",
       "       [9.98082280e-01, 8.15229677e-03],\n",
       "       [9.99873996e-01, 1.20132572e-04],\n",
       "       [9.99516964e-01, 2.21643073e-04],\n",
       "       [9.99983549e-01, 9.99959111e-01],\n",
       "       [1.28755682e-05, 7.72064504e-06],\n",
       "       [1.19047647e-04, 6.16094621e-05],\n",
       "       [9.98489022e-01, 3.99109675e-04],\n",
       "       [9.90348697e-01, 2.61074468e-03],\n",
       "       [9.99447405e-01, 3.00809625e-04],\n",
       "       [9.99870777e-01, 5.31758706e-05],\n",
       "       [3.03598827e-05, 1.26358045e-05],\n",
       "       [9.99828339e-01, 6.13847442e-05],\n",
       "       [9.98658776e-01, 9.97622430e-01],\n",
       "       [1.09768909e-04, 3.96498181e-05],\n",
       "       [9.99773800e-01, 9.99499977e-01],\n",
       "       [9.99814093e-01, 9.99769270e-01],\n",
       "       [9.99749124e-01, 1.84025503e-05],\n",
       "       [8.88717890e-01, 8.45892057e-02],\n",
       "       [9.99730527e-01, 1.63846766e-04],\n",
       "       [6.46131521e-04, 4.04144230e-04],\n",
       "       [9.99828339e-01, 2.07283942e-04],\n",
       "       [9.98678505e-01, 1.88843391e-04],\n",
       "       [1.97966147e-05, 1.32486002e-05],\n",
       "       [6.47741617e-05, 1.66838072e-05],\n",
       "       [9.97922719e-01, 1.87665434e-03],\n",
       "       [9.99822915e-01, 9.99710381e-01],\n",
       "       [1.31543766e-05, 8.78536048e-06],\n",
       "       [9.99888182e-01, 2.74592985e-05],\n",
       "       [9.90783691e-01, 5.64732403e-02],\n",
       "       [5.28212004e-05, 2.95367208e-05],\n",
       "       [1.22233789e-04, 3.24011780e-05],\n",
       "       [1.23772508e-04, 6.47782872e-05],\n",
       "       [4.12398140e-06, 1.96810151e-06],\n",
       "       [9.98747230e-01, 7.37640914e-03],\n",
       "       [9.99817669e-01, 1.20929344e-05],\n",
       "       [3.59057194e-05, 1.16608826e-05],\n",
       "       [8.28238964e-01, 8.09365451e-01],\n",
       "       [4.02970436e-05, 3.18589919e-05],\n",
       "       [9.99789298e-01, 9.99677598e-01],\n",
       "       [9.99803245e-01, 9.99506295e-01],\n",
       "       [9.99883533e-01, 9.99828815e-01],\n",
       "       [9.21127617e-01, 1.27965240e-02],\n",
       "       [9.98960257e-01, 1.99328060e-03],\n",
       "       [9.84681964e-01, 2.12975945e-02],\n",
       "       [9.99761879e-01, 9.99631405e-01],\n",
       "       [2.56832009e-05, 1.46592729e-05],\n",
       "       [9.99390244e-01, 8.10565252e-04],\n",
       "       [9.99537587e-01, 2.42502007e-04],\n",
       "       [9.99194562e-01, 9.98213649e-01],\n",
       "       [2.08443832e-02, 7.50327483e-03],\n",
       "       [9.97827590e-01, 2.27433741e-02],\n",
       "       [9.99837995e-01, 4.54114670e-05],\n",
       "       [9.99260247e-01, 5.21032314e-04],\n",
       "       [9.99066055e-01, 5.85963193e-04],\n",
       "       [5.05920507e-05, 3.18054408e-05],\n",
       "       [9.99851704e-01, 1.55029265e-05],\n",
       "       [9.99307394e-01, 1.28665270e-04],\n",
       "       [3.70833732e-05, 1.70759886e-05],\n",
       "       [7.09638916e-05, 2.51451547e-05],\n",
       "       [9.99297261e-01, 5.25130192e-04],\n",
       "       [3.96695214e-05, 1.83907523e-05],\n",
       "       [9.88526583e-01, 4.17437077e-01],\n",
       "       [9.99322414e-01, 9.98601139e-01],\n",
       "       [5.21574802e-05, 2.34353975e-05],\n",
       "       [9.97866690e-01, 2.88804178e-03],\n",
       "       [5.89267467e-04, 9.46992004e-05],\n",
       "       [2.64380978e-05, 1.36407025e-05],\n",
       "       [9.99845147e-01, 9.99818325e-01],\n",
       "       [1.37825773e-04, 3.70857197e-05],\n",
       "       [4.05556493e-05, 1.56314727e-05],\n",
       "       [2.09182836e-05, 1.15904977e-05],\n",
       "       [9.99796689e-01, 5.96476661e-04],\n",
       "       [6.46736880e-05, 1.81789110e-05],\n",
       "       [5.25097221e-06, 3.00246711e-06],\n",
       "       [9.97015595e-01, 9.93827581e-01],\n",
       "       [9.99432027e-01, 9.83805239e-01],\n",
       "       [1.13533506e-05, 6.62664161e-06],\n",
       "       [9.99743640e-01, 5.99624065e-04],\n",
       "       [4.59249577e-06, 1.75781429e-06],\n",
       "       [2.51179124e-04, 1.62027616e-04],\n",
       "       [9.99408245e-01, 9.99271214e-01],\n",
       "       [5.01015456e-04, 2.14675965e-04],\n",
       "       [5.08167874e-03, 3.18363868e-03],\n",
       "       [9.99391913e-01, 3.98689182e-04],\n",
       "       [2.17186789e-05, 1.16254723e-05],\n",
       "       [2.32180446e-06, 1.53507995e-06],\n",
       "       [7.59445102e-05, 3.31715491e-05],\n",
       "       [9.99863386e-01, 3.70550842e-04],\n",
       "       [1.08913246e-05, 8.76308695e-06],\n",
       "       [8.74984107e-05, 7.81716008e-05],\n",
       "       [9.99862909e-01, 7.08535517e-05],\n",
       "       [9.99305248e-01, 2.08924967e-03],\n",
       "       [9.99927998e-01, 9.99911427e-01],\n",
       "       [3.93194059e-05, 3.39022226e-05],\n",
       "       [9.99935269e-01, 9.99910831e-01],\n",
       "       [9.99971986e-01, 9.99952316e-01],\n",
       "       [9.98271108e-01, 9.20878025e-04],\n",
       "       [9.99472082e-01, 9.97667789e-01],\n",
       "       [9.99679327e-01, 7.18505034e-05],\n",
       "       [9.94587898e-01, 9.92514133e-01],\n",
       "       [2.98147425e-02, 2.12479569e-02],\n",
       "       [9.99524832e-01, 2.98888393e-04],\n",
       "       [2.84657115e-04, 7.93343570e-05],\n",
       "       [9.98274088e-01, 9.97696459e-01],\n",
       "       [9.99953032e-01, 9.99945402e-01],\n",
       "       [6.10165371e-05, 2.80138229e-05],\n",
       "       [9.84920442e-01, 5.76669350e-04],\n",
       "       [1.22560814e-04, 9.49111636e-05],\n",
       "       [1.37568946e-04, 1.06888983e-04],\n",
       "       [9.98767495e-01, 4.76195058e-03],\n",
       "       [9.99967337e-01, 9.99947548e-01],\n",
       "       [5.58649376e-03, 5.51325153e-04],\n",
       "       [9.99740899e-01, 9.99595881e-01],\n",
       "       [9.97247040e-01, 2.22250982e-03],\n",
       "       [9.99902129e-01, 1.38016519e-04],\n",
       "       [9.98887718e-01, 4.55503643e-04],\n",
       "       [9.99787152e-01, 9.99560773e-01],\n",
       "       [9.99498844e-01, 9.98662889e-01],\n",
       "       [2.54598453e-05, 1.42341014e-05],\n",
       "       [9.75653470e-01, 1.12854154e-03],\n",
       "       [1.37659408e-05, 8.19114030e-06],\n",
       "       [9.95218098e-01, 9.70115125e-01],\n",
       "       [4.17002011e-05, 2.90849748e-05],\n",
       "       [1.33131416e-05, 9.49799414e-06],\n",
       "       [7.77603927e-05, 5.89043484e-05],\n",
       "       [9.97075438e-01, 9.95391548e-01],\n",
       "       [9.99793589e-01, 9.99667466e-01],\n",
       "       [2.22390844e-03, 9.34704905e-04],\n",
       "       [2.24344749e-05, 1.31266825e-05],\n",
       "       [4.86813951e-06, 4.08982623e-06],\n",
       "       [9.99485254e-01, 9.99118626e-01],\n",
       "       [2.65415579e-01, 1.52348414e-01],\n",
       "       [9.98567104e-01, 9.97511268e-01],\n",
       "       [2.76703868e-05, 1.80683237e-05],\n",
       "       [5.77458486e-05, 3.29102440e-05],\n",
       "       [3.69923837e-05, 2.00406193e-05],\n",
       "       [9.99662519e-01, 2.22517541e-04],\n",
       "       [9.80971932e-01, 1.62491109e-02],\n",
       "       [9.98006642e-01, 1.32412929e-03],\n",
       "       [9.98399675e-01, 2.05409480e-03],\n",
       "       [9.41795661e-05, 2.00386039e-05],\n",
       "       [1.37615434e-05, 6.14363898e-06],\n",
       "       [9.98550832e-01, 9.52811539e-03],\n",
       "       [5.81471022e-06, 3.84265513e-06],\n",
       "       [5.12885017e-05, 2.75544844e-05],\n",
       "       [9.97438669e-01, 8.52100737e-03],\n",
       "       [9.99727309e-01, 4.41534285e-05],\n",
       "       [9.99863505e-01, 9.99740839e-01],\n",
       "       [9.99535918e-01, 7.64256183e-05],\n",
       "       [9.99871135e-01, 9.99608755e-01],\n",
       "       [2.17820270e-05, 1.46605180e-05],\n",
       "       [9.25141513e-01, 9.08688664e-01],\n",
       "       [3.35437740e-04, 1.15404699e-04],\n",
       "       [9.99786675e-01, 9.99455094e-01],\n",
       "       [9.66444969e-01, 4.61617187e-02],\n",
       "       [1.17936521e-04, 4.55756090e-05],\n",
       "       [9.99871135e-01, 8.12072540e-05],\n",
       "       [2.53488690e-01, 1.30177557e-01],\n",
       "       [1.63607510e-05, 9.82369329e-06],\n",
       "       [2.17060897e-05, 1.26433897e-05],\n",
       "       [9.97823477e-01, 1.22783182e-04],\n",
       "       [9.98192847e-01, 8.33912811e-04],\n",
       "       [3.45579057e-04, 1.85343175e-04],\n",
       "       [1.38757068e-05, 9.36455763e-06],\n",
       "       [2.12580671e-05, 1.29811424e-05],\n",
       "       [4.83133970e-03, 1.77882530e-03],\n",
       "       [9.99561846e-01, 1.28830317e-03],\n",
       "       [9.99625683e-01, 1.70759813e-04],\n",
       "       [9.99787390e-01, 9.99631524e-01],\n",
       "       [1.91474755e-04, 4.40798285e-05],\n",
       "       [1.41543569e-05, 8.15596195e-06],\n",
       "       [9.99959946e-01, 9.99914646e-01],\n",
       "       [9.99810278e-01, 4.57509086e-05],\n",
       "       [9.99689460e-01, 9.99484301e-01],\n",
       "       [8.90290394e-05, 4.86784120e-05],\n",
       "       [8.11404680e-05, 3.45116787e-05],\n",
       "       [9.99677539e-01, 1.57375151e-04],\n",
       "       [9.98384237e-01, 3.10643855e-03],\n",
       "       [1.14753435e-04, 4.99136440e-05],\n",
       "       [9.96920943e-01, 7.04241975e-04],\n",
       "       [7.57264615e-06, 5.58431429e-06],\n",
       "       [1.11921385e-04, 3.90990099e-05],\n",
       "       [9.33771074e-01, 1.76675558e-01],\n",
       "       [2.90314824e-06, 1.28036083e-06],\n",
       "       [9.99654531e-01, 9.99470472e-01],\n",
       "       [9.45807934e-01, 2.27361545e-01],\n",
       "       [9.99889970e-01, 1.64886209e-04],\n",
       "       [6.70850204e-05, 2.12248997e-05],\n",
       "       [3.92063303e-05, 1.63311233e-05],\n",
       "       [7.86231612e-05, 3.62664505e-05],\n",
       "       [3.22751212e-03, 1.52966590e-03],\n",
       "       [8.19283783e-01, 1.16280671e-02],\n",
       "       [9.99690652e-01, 1.60176787e-04],\n",
       "       [2.75282619e-05, 2.16550143e-05],\n",
       "       [9.91438091e-01, 1.96399726e-03],\n",
       "       [9.99002159e-01, 8.88976356e-05],\n",
       "       [9.99480546e-01, 9.99204755e-01],\n",
       "       [9.99084592e-01, 3.32661148e-04],\n",
       "       [1.45330280e-03, 5.01101662e-04],\n",
       "       [9.99848247e-01, 2.21173483e-04],\n",
       "       [4.05360879e-05, 2.16879271e-05],\n",
       "       [9.99758065e-01, 1.03175516e-04],\n",
       "       [1.83265540e-04, 4.06513464e-05],\n",
       "       [1.35717622e-04, 1.01201775e-04],\n",
       "       [9.13747208e-05, 4.04056045e-05],\n",
       "       [9.99825418e-01, 9.99731243e-01],\n",
       "       [2.12870164e-05, 1.04926794e-05],\n",
       "       [9.99764383e-01, 6.06581511e-04],\n",
       "       [9.98524964e-01, 9.97673988e-01],\n",
       "       [9.99537826e-01, 3.68401292e-03],\n",
       "       [4.92406194e-04, 4.40148520e-04],\n",
       "       [9.99974966e-01, 9.99961138e-01],\n",
       "       [4.29120118e-04, 2.84039212e-04],\n",
       "       [9.99863625e-01, 8.11854334e-05],\n",
       "       [9.93606567e-01, 9.33816612e-01],\n",
       "       [9.99046147e-01, 1.46666216e-03],\n",
       "       [9.98866677e-01, 9.97827291e-01],\n",
       "       [9.96385455e-01, 9.90759611e-01],\n",
       "       [9.98922110e-01, 1.59968785e-03],\n",
       "       [9.99841690e-01, 5.24968957e-04],\n",
       "       [1.12821709e-03, 2.70323799e-04],\n",
       "       [9.99653459e-01, 1.68592378e-03],\n",
       "       [9.99624133e-01, 1.39309137e-04],\n",
       "       [9.99838829e-01, 2.98095692e-04],\n",
       "       [5.11284219e-04, 3.91122187e-04],\n",
       "       [5.14780841e-05, 2.22686558e-05],\n",
       "       [6.61595695e-05, 3.29787399e-05],\n",
       "       [9.99079108e-01, 1.40008645e-03],\n",
       "       [6.37898513e-04, 3.01186839e-04],\n",
       "       [9.99585211e-01, 9.99526799e-01],\n",
       "       [3.88053834e-01, 2.04011556e-02],\n",
       "       [1.41485807e-05, 1.21479579e-05],\n",
       "       [3.15995738e-02, 1.78286880e-02],\n",
       "       [9.99375403e-01, 3.93935014e-04],\n",
       "       [9.99297619e-01, 2.05491277e-04],\n",
       "       [9.98488545e-01, 4.20851680e-03],\n",
       "       [1.05294521e-05, 7.28968507e-06],\n",
       "       [2.14139654e-05, 1.20932909e-05],\n",
       "       [1.55169710e-05, 1.12997486e-05],\n",
       "       [9.34298158e-01, 9.20500338e-01],\n",
       "       [9.99528408e-01, 6.58665522e-05],\n",
       "       [9.99979496e-01, 9.99963522e-01],\n",
       "       [2.80674867e-04, 1.49853047e-04],\n",
       "       [7.02960242e-05, 2.88540941e-05],\n",
       "       [9.99500632e-01, 8.98501239e-05],\n",
       "       [2.26642660e-05, 1.20417135e-05],\n",
       "       [9.99343932e-01, 2.55789695e-04],\n",
       "       [9.98426557e-01, 1.89763366e-03],\n",
       "       [9.95426238e-01, 2.33228109e-03],\n",
       "       [3.58049183e-05, 2.93967532e-05],\n",
       "       [9.99524951e-01, 7.10578961e-03],\n",
       "       [4.67371365e-06, 1.88946660e-06],\n",
       "       [9.99721587e-01, 8.57186678e-05],\n",
       "       [3.52497242e-04, 2.27010401e-04],\n",
       "       [1.48141753e-05, 1.03186130e-05],\n",
       "       [6.83141081e-03, 1.12809578e-03],\n",
       "       [9.99811828e-01, 8.45587405e-04],\n",
       "       [1.62061726e-04, 5.36387670e-05],\n",
       "       [3.73384637e-06, 2.63691049e-06],\n",
       "       [1.10174051e-05, 8.10612892e-06],\n",
       "       [2.04877157e-04, 6.66072083e-05],\n",
       "       [2.26643533e-05, 1.25905181e-05],\n",
       "       [9.99912262e-01, 9.99794483e-01],\n",
       "       [1.74442283e-03, 1.30940892e-03],\n",
       "       [1.99584792e-05, 1.51334161e-05],\n",
       "       [9.50034801e-03, 7.72660645e-03],\n",
       "       [1.94950371e-05, 9.65661638e-06],\n",
       "       [9.96000350e-01, 2.34902036e-04],\n",
       "       [9.99912143e-01, 3.81189493e-05],\n",
       "       [9.99445140e-01, 9.97961521e-01],\n",
       "       [3.52241223e-05, 1.62376873e-05],\n",
       "       [9.99842644e-01, 9.99706268e-01],\n",
       "       [7.14397811e-06, 4.49398158e-06],\n",
       "       [2.81518842e-05, 1.64293360e-05],\n",
       "       [6.44930478e-05, 1.80873776e-05],\n",
       "       [1.08421396e-03, 6.73157920e-04],\n",
       "       [9.95734394e-01, 1.41560733e-02],\n",
       "       [9.92581844e-01, 9.03693378e-01],\n",
       "       [9.99889016e-01, 4.31649205e-05],\n",
       "       [7.29132211e-04, 4.37902025e-04],\n",
       "       [9.99744356e-01, 2.05174656e-04],\n",
       "       [9.91145670e-01, 1.30041607e-03],\n",
       "       [9.97975647e-01, 2.16578152e-02],\n",
       "       [4.57206770e-05, 2.76123083e-05],\n",
       "       [9.99927163e-01, 9.99880672e-01],\n",
       "       [6.00576714e-05, 2.38994890e-05],\n",
       "       [9.97606754e-01, 2.76686694e-03],\n",
       "       [9.99153733e-01, 2.04332493e-04],\n",
       "       [9.68310237e-01, 1.11214239e-02],\n",
       "       [9.99788582e-01, 2.05738892e-04],\n",
       "       [1.25084640e-04, 4.82200012e-05],\n",
       "       [9.99755442e-01, 7.74739892e-05],\n",
       "       [1.29664304e-05, 9.68741369e-06],\n",
       "       [9.99782860e-01, 3.76698998e-04],\n",
       "       [2.32373313e-05, 1.39884396e-05],\n",
       "       [9.99448717e-01, 9.01175081e-04],\n",
       "       [9.99046504e-01, 1.42413424e-03],\n",
       "       [9.99670863e-01, 3.54381686e-04],\n",
       "       [4.21958357e-05, 1.66244317e-05],\n",
       "       [9.99383569e-01, 9.99155104e-01],\n",
       "       [9.99729455e-01, 1.47511251e-04],\n",
       "       [2.70645542e-04, 2.26311284e-04],\n",
       "       [9.99790370e-01, 7.41439580e-05],\n",
       "       [9.99612153e-01, 5.61435190e-05],\n",
       "       [3.38166246e-05, 1.58290186e-05],\n",
       "       [9.99804199e-01, 9.41788094e-05],\n",
       "       [6.50393311e-04, 2.51830090e-04],\n",
       "       [9.99911666e-01, 5.78616819e-05],\n",
       "       [9.98782098e-01, 2.81950401e-04],\n",
       "       [8.80627632e-01, 1.97029680e-01],\n",
       "       [8.12721191e-06, 6.23890401e-06],\n",
       "       [2.77279401e-06, 1.91961522e-06],\n",
       "       [9.99760091e-01, 9.99524891e-01],\n",
       "       [3.19180690e-05, 1.58957628e-05],\n",
       "       [9.99564826e-01, 4.33520800e-05],\n",
       "       [7.12056635e-06, 3.16874730e-06],\n",
       "       [1.66144146e-05, 1.03464236e-05],\n",
       "       [9.99970555e-01, 9.99943018e-01],\n",
       "       [9.59718108e-01, 2.14904726e-01],\n",
       "       [9.99482274e-01, 9.99365032e-01],\n",
       "       [9.98970032e-01, 1.47579738e-03],\n",
       "       [1.11994304e-04, 1.97461977e-05],\n",
       "       [9.97501194e-01, 9.96214449e-01],\n",
       "       [9.99515653e-01, 4.41233788e-05],\n",
       "       [9.95968580e-01, 1.96858570e-02],\n",
       "       [9.99968886e-01, 9.99957323e-01],\n",
       "       [9.99693632e-01, 9.99597311e-01],\n",
       "       [9.99785602e-01, 1.30267770e-04],\n",
       "       [9.99888182e-01, 9.99788642e-01],\n",
       "       [2.72982586e-02, 2.41058450e-02],\n",
       "       [1.87107318e-04, 6.34666867e-05],\n",
       "       [1.02119916e-03, 4.14066890e-04],\n",
       "       [1.06508651e-05, 7.36102174e-06],\n",
       "       [9.99641418e-01, 2.53619452e-04],\n",
       "       [9.98412013e-01, 9.96639609e-01],\n",
       "       [9.99777973e-01, 3.08102724e-04],\n",
       "       [9.83454704e-01, 5.01475204e-03],\n",
       "       [9.99306083e-01, 1.98033085e-04],\n",
       "       [9.99814093e-01, 9.99487400e-01],\n",
       "       [9.88390923e-01, 2.43287743e-03],\n",
       "       [9.99840260e-01, 9.99757648e-01],\n",
       "       [9.97191370e-01, 9.95691538e-01],\n",
       "       [1.18596421e-03, 5.66789124e-04],\n",
       "       [1.29296596e-03, 2.82904482e-04],\n",
       "       [9.99128520e-01, 5.60114044e-04],\n",
       "       [9.97888148e-01, 9.97093678e-01],\n",
       "       [9.99706686e-01, 2.11580977e-04],\n",
       "       [1.10458452e-04, 4.90644343e-05],\n",
       "       [6.68351495e-05, 2.18304504e-05],\n",
       "       [9.99942541e-01, 9.99853492e-01],\n",
       "       [9.99279082e-01, 1.42332035e-04],\n",
       "       [6.39368445e-05, 2.42101996e-05],\n",
       "       [9.99311566e-01, 9.98621702e-01],\n",
       "       [9.99427974e-01, 3.90177651e-04],\n",
       "       [9.99279678e-01, 9.97415900e-01],\n",
       "       [2.17992329e-05, 1.16293832e-05],\n",
       "       [9.52820718e-01, 6.74152374e-03],\n",
       "       [9.99547184e-01, 7.60032708e-05],\n",
       "       [3.64638254e-05, 2.57046358e-05],\n",
       "       [9.97171223e-01, 9.94810879e-01],\n",
       "       [9.99950886e-01, 9.99938846e-01],\n",
       "       [9.99780476e-01, 4.84156626e-04],\n",
       "       [4.48172468e-05, 1.58420444e-05],\n",
       "       [9.99703705e-01, 6.48854242e-04],\n",
       "       [9.88730848e-01, 5.53831132e-03],\n",
       "       [9.98626590e-01, 6.34200987e-04],\n",
       "       [9.99507189e-01, 6.06840942e-04],\n",
       "       [8.72367236e-05, 4.67478130e-05],\n",
       "       [9.99673963e-01, 2.97863269e-04],\n",
       "       [1.13566886e-04, 6.08982191e-05],\n",
       "       [9.99931335e-01, 9.99839783e-01],\n",
       "       [9.99602258e-01, 2.53491278e-04],\n",
       "       [9.99772370e-01, 3.49810784e-04],\n",
       "       [4.69626904e-01, 3.68692465e-02],\n",
       "       [9.99853849e-01, 8.52400117e-05],\n",
       "       [1.00155848e-04, 5.90211639e-05],\n",
       "       [9.99527812e-01, 9.99157131e-01],\n",
       "       [1.26871862e-04, 8.54024838e-05],\n",
       "       [9.78312492e-01, 9.77814496e-01],\n",
       "       [9.99801457e-01, 9.01328283e-04],\n",
       "       [7.83659634e-05, 3.17095073e-05],\n",
       "       [8.78153151e-06, 6.36871937e-06],\n",
       "       [9.98762131e-01, 1.55686610e-03],\n",
       "       [9.99363959e-01, 9.99047756e-01],\n",
       "       [6.20022274e-06, 1.98653743e-06],\n",
       "       [9.98662949e-01, 9.97346938e-01],\n",
       "       [4.87227589e-05, 2.41909238e-05],\n",
       "       [9.99944448e-01, 9.99932766e-01],\n",
       "       [9.99446929e-01, 5.62859059e-04],\n",
       "       [1.83641809e-04, 1.20912955e-04],\n",
       "       [8.85048628e-01, 7.34325409e-01],\n",
       "       [9.99326706e-01, 8.41824221e-04],\n",
       "       [9.99748051e-01, 1.06533924e-04],\n",
       "       [9.99156952e-01, 4.83309338e-03],\n",
       "       [9.79931235e-01, 9.75031674e-01],\n",
       "       [1.62425116e-04, 6.97738942e-05],\n",
       "       [3.52496223e-04, 1.37069874e-04],\n",
       "       [1.19729866e-05, 1.90881497e-06],\n",
       "       [9.99108732e-01, 1.42027216e-03],\n",
       "       [9.95873868e-01, 3.97803058e-04],\n",
       "       [5.48838489e-06, 3.81355426e-06],\n",
       "       [9.99938726e-01, 9.99923229e-01],\n",
       "       [9.99910235e-01, 2.40400532e-05],\n",
       "       [8.13786683e-05, 5.01529503e-05],\n",
       "       [1.18090575e-04, 5.00786264e-05],\n",
       "       [6.18608465e-05, 3.07622722e-05],\n",
       "       [9.99879599e-01, 9.99695599e-01],\n",
       "       [5.66886010e-05, 2.93888588e-05],\n",
       "       [1.98662674e-05, 1.26611112e-05],\n",
       "       [7.25335194e-05, 5.33087914e-05],\n",
       "       [6.09813165e-03, 1.03868707e-03],\n",
       "       [8.54394166e-05, 6.25423272e-05],\n",
       "       [1.51162258e-05, 1.10316187e-05],\n",
       "       [6.96687712e-05, 5.24360221e-05],\n",
       "       [2.14905958e-04, 8.69683063e-05],\n",
       "       [7.55418841e-06, 3.98252632e-06],\n",
       "       [9.09807205e-01, 8.92624080e-01],\n",
       "       [3.29303148e-05, 2.42858368e-05],\n",
       "       [3.32073541e-04, 9.08159345e-05],\n",
       "       [9.83929396e-01, 9.77273285e-01],\n",
       "       [1.62277895e-04, 8.22281436e-05],\n",
       "       [9.99032736e-01, 5.83343615e-04],\n",
       "       [9.99849081e-01, 4.86057979e-05],\n",
       "       [9.99111235e-01, 9.67205386e-04],\n",
       "       [9.99888420e-01, 1.38023053e-04],\n",
       "       [5.02189032e-05, 2.23780589e-05],\n",
       "       [1.86218662e-04, 6.52158997e-05],\n",
       "       [9.99733627e-01, 1.63943361e-04],\n",
       "       [9.99831080e-01, 3.40331753e-04],\n",
       "       [2.55934196e-04, 1.10184628e-04],\n",
       "       [9.99925017e-01, 9.99872684e-01],\n",
       "       [9.99853969e-01, 4.23228747e-04],\n",
       "       [9.99629617e-01, 2.33155885e-03],\n",
       "       [9.99928355e-01, 1.00186866e-04],\n",
       "       [9.92243946e-01, 1.66661665e-02],\n",
       "       [9.97762799e-01, 1.01202801e-02],\n",
       "       [9.99826133e-01, 7.53634376e-05],\n",
       "       [9.99556959e-01, 9.99112546e-01],\n",
       "       [9.99613822e-01, 1.79713606e-04],\n",
       "       [6.13370957e-03, 2.93339952e-04],\n",
       "       [5.36984066e-04, 1.99990827e-04],\n",
       "       [9.91623700e-01, 5.74218035e-01],\n",
       "       [5.40584642e-06, 3.87266391e-06],\n",
       "       [9.95302916e-01, 5.69933094e-03],\n",
       "       [9.99983788e-01, 9.99932528e-01],\n",
       "       [9.97989178e-01, 2.19346635e-04],\n",
       "       [9.99523759e-01, 1.60240277e-03],\n",
       "       [5.92493780e-05, 1.53125111e-05],\n",
       "       [2.06478010e-03, 1.31155306e-03],\n",
       "       [2.66265397e-06, 1.37094628e-06],\n",
       "       [9.99942422e-01, 9.99873281e-01],\n",
       "       [9.99942303e-01, 9.99906421e-01],\n",
       "       [3.89547313e-05, 1.91090239e-05],\n",
       "       [1.01296137e-04, 5.26467848e-05],\n",
       "       [9.99720871e-01, 1.35895447e-04],\n",
       "       [9.99418378e-01, 1.14562201e-04],\n",
       "       [5.77019015e-03, 4.94114449e-03],\n",
       "       [6.54730684e-05, 2.04904136e-05],\n",
       "       [9.99716341e-01, 2.31653583e-04],\n",
       "       [7.62417985e-05, 5.50462755e-05],\n",
       "       [8.68977606e-03, 6.00459008e-03],\n",
       "       [9.99915600e-01, 5.91856551e-05],\n",
       "       [9.99657154e-01, 1.84581048e-04],\n",
       "       [5.26552612e-04, 1.29996886e-04],\n",
       "       [1.06665189e-04, 7.81917042e-05],\n",
       "       [9.99238014e-01, 9.97375131e-01],\n",
       "       [9.99701798e-01, 1.59468094e-04],\n",
       "       [9.99932528e-01, 9.99894381e-01],\n",
       "       [9.96307492e-01, 9.84120309e-01]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       160\n",
      "           1       0.56      0.52      0.54       189\n",
      "           2       0.65      0.50      0.56       122\n",
      "\n",
      "    accuracy                           0.60       471\n",
      "   macro avg       0.61      0.60      0.59       471\n",
      "weighted avg       0.60      0.60      0.59       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = corn_label_from_logits(torch.tensor(predictions.predictions))\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4437)\n",
      "tensor(0.5287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f16cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca61759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.7, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca7af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       342\n",
      "           1       0.20      0.02      0.03        62\n",
      "           2       0.33      0.78      0.46        67\n",
      "\n",
      "    accuracy                           0.69       471\n",
      "   macro avg       0.47      0.53      0.45       471\n",
      "weighted avg       0.72      0.69      0.68       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e469c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4735)\n",
      "tensor(0.8089)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9ad4c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66073d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[9.95555747e-05, 3.75124291e-05],\n",
       "       [1.90776882e-05, 7.18809815e-06],\n",
       "       [4.26126033e-01, 2.18610957e-01],\n",
       "       [1.54090267e-05, 5.80580036e-06],\n",
       "       [4.43542629e-01, 2.30959401e-01],\n",
       "       [4.85832632e-01, 2.62543648e-01],\n",
       "       [5.36891021e-05, 2.02294377e-05],\n",
       "       [5.09416386e-05, 1.91941908e-05],\n",
       "       [1.41160726e-05, 5.31863770e-06],\n",
       "       [7.37917617e-06, 2.78030598e-06],\n",
       "       [4.76031780e-01, 2.55013168e-01],\n",
       "       [6.24308495e-06, 2.35225093e-06],\n",
       "       [1.23269429e-05, 4.64452569e-06],\n",
       "       [4.51042235e-01, 2.36391559e-01],\n",
       "       [4.45150799e-05, 1.67726739e-05],\n",
       "       [6.73745490e-06, 2.53851863e-06],\n",
       "       [4.78512853e-01, 2.56907135e-01],\n",
       "       [2.71430588e-04, 1.02285703e-04],\n",
       "       [5.93937980e-03, 2.24612933e-03],\n",
       "       [4.83804179e-05, 1.82291060e-05],\n",
       "       [1.14722243e-05, 4.32248407e-06],\n",
       "       [1.10954734e-05, 4.18053560e-06],\n",
       "       [9.99904394e-01, 9.99746144e-01],\n",
       "       [2.32294424e-05, 8.75241130e-06],\n",
       "       [1.62869003e-02, 6.19943859e-03],\n",
       "       [9.62229296e-06, 3.62546984e-06],\n",
       "       [2.35431045e-01, 1.03958115e-01],\n",
       "       [5.51715136e-01, 3.16803277e-01],\n",
       "       [1.23942518e-05, 4.66988649e-06],\n",
       "       [4.07451615e-02, 1.57517772e-02],\n",
       "       [4.42693412e-01, 2.30348736e-01],\n",
       "       [1.08170963e-03, 4.07836837e-04],\n",
       "       [5.47421814e-06, 2.06256050e-06],\n",
       "       [1.22197368e-03, 4.60761104e-04],\n",
       "       [6.39658756e-05, 2.41017369e-05],\n",
       "       [1.25678371e-05, 4.73529508e-06],\n",
       "       [9.99880314e-01, 9.99682546e-01],\n",
       "       [2.72748340e-03, 1.02939981e-03],\n",
       "       [1.43525367e-05, 5.40773362e-06],\n",
       "       [1.15586072e-05, 4.35503125e-06],\n",
       "       [1.08809509e-04, 4.09995409e-05],\n",
       "       [6.10807474e-05, 2.30146288e-05],\n",
       "       [4.35249239e-01, 2.25033447e-01],\n",
       "       [4.56413036e-05, 1.71970332e-05],\n",
       "       [4.11365569e-01, 2.08427861e-01],\n",
       "       [5.58990041e-06, 2.10614508e-06],\n",
       "       [5.60627460e-01, 3.24669152e-01],\n",
       "       [8.30146484e-03, 3.14405677e-03],\n",
       "       [4.26402294e-05, 1.60662366e-05],\n",
       "       [9.99932528e-01, 9.99821126e-01],\n",
       "       [4.13400710e-01, 2.09816873e-01],\n",
       "       [1.49963613e-04, 5.65078990e-05],\n",
       "       [4.62326898e-05, 1.74198467e-05],\n",
       "       [5.48559474e-04, 2.06754572e-04],\n",
       "       [1.25929089e-02, 4.78223432e-03],\n",
       "       [4.35033172e-01, 2.24880219e-01],\n",
       "       [8.14615305e-06, 3.06928678e-06],\n",
       "       [2.38494843e-01, 1.05547160e-01],\n",
       "       [2.89829586e-06, 1.09200880e-06],\n",
       "       [7.68991777e-06, 2.89738682e-06],\n",
       "       [6.98136455e-06, 2.63041875e-06],\n",
       "       [2.86067370e-05, 1.07785208e-05],\n",
       "       [6.92954700e-06, 2.61089735e-06],\n",
       "       [1.26335712e-03, 4.76377405e-04],\n",
       "       [8.63575190e-03, 3.27134808e-03],\n",
       "       [4.16346711e-06, 1.56869805e-06],\n",
       "       [1.24288752e-04, 4.68326325e-05],\n",
       "       [9.99955416e-01, 9.99881625e-01],\n",
       "       [1.85868657e-06, 7.00308362e-07],\n",
       "       [4.55023535e-03, 1.71929458e-03],\n",
       "       [5.89149931e-06, 2.21978098e-06],\n",
       "       [2.18142050e-05, 8.21917092e-06],\n",
       "       [5.62247078e-06, 2.11841689e-06],\n",
       "       [2.36396445e-04, 8.90816082e-05],\n",
       "       [2.09166064e-05, 7.88096804e-06],\n",
       "       [9.74311115e-06, 3.67098778e-06],\n",
       "       [2.73951940e-04, 1.03236111e-04],\n",
       "       [4.69005406e-01, 2.49694422e-01],\n",
       "       [4.44144547e-01, 2.31392816e-01],\n",
       "       [4.79001194e-01, 2.57280916e-01],\n",
       "       [1.16968840e-05, 4.40713166e-06],\n",
       "       [1.46506381e-05, 5.52005758e-06],\n",
       "       [9.99852896e-01, 9.99609649e-01],\n",
       "       [5.59670552e-05, 2.10877515e-05],\n",
       "       [4.17964548e-01, 2.12949127e-01],\n",
       "       [6.23270898e-05, 2.34842355e-05],\n",
       "       [8.17416367e-05, 3.07998198e-05],\n",
       "       [1.17286050e-04, 4.41937445e-05],\n",
       "       [1.90553412e-01, 8.14712346e-02],\n",
       "       [4.39977258e-01, 2.28401452e-01],\n",
       "       [5.87610248e-06, 2.21398182e-06],\n",
       "       [3.51609639e-03, 1.32768916e-03],\n",
       "       [4.90597904e-01, 2.66252875e-01],\n",
       "       [4.56508279e-01, 2.40395457e-01],\n",
       "       [9.99904156e-01, 9.99745548e-01],\n",
       "       [2.35799421e-02, 9.01686121e-03],\n",
       "       [9.99666929e-01, 9.99116480e-01],\n",
       "       [9.99932051e-01, 9.99819577e-01],\n",
       "       [4.93578821e-01, 2.68589437e-01],\n",
       "       [7.99197033e-02, 3.16902325e-02],\n",
       "       [4.90796089e-01, 2.66407877e-01],\n",
       "       [4.46780503e-01, 2.33296096e-01],\n",
       "       [2.04736298e-05, 7.71406758e-06],\n",
       "       [5.04351192e-06, 1.90027947e-06],\n",
       "       [1.44684709e-05, 5.45141575e-06],\n",
       "       [3.80845159e-01, 1.88151300e-01],\n",
       "       [4.23969150e-01, 2.17107043e-01],\n",
       "       [8.40778754e-04, 3.16951075e-04],\n",
       "       [8.01080932e-06, 3.01829505e-06],\n",
       "       [4.46523100e-01, 2.33109817e-01],\n",
       "       [7.26158714e-06, 2.73600358e-06],\n",
       "       [8.10644488e-05, 3.05446410e-05],\n",
       "       [4.33213741e-01, 2.23591849e-01],\n",
       "       [4.47263181e-01, 2.33645529e-01],\n",
       "       [2.88464618e-03, 1.08882203e-03],\n",
       "       [7.66853409e-05, 2.88945412e-05],\n",
       "       [2.03749169e-05, 7.67687470e-06],\n",
       "       [5.34789870e-05, 2.01502644e-05],\n",
       "       [9.99627948e-01, 9.99013186e-01],\n",
       "       [4.26836967e-01, 2.19107822e-01],\n",
       "       [6.13161319e-06, 2.31025069e-06],\n",
       "       [1.30784510e-05, 4.92768004e-06],\n",
       "       [3.37689635e-05, 1.27235990e-05],\n",
       "       [4.92303483e-02, 1.91359222e-02],\n",
       "       [5.00303795e-05, 1.88508275e-05],\n",
       "       [7.17336161e-06, 2.70276178e-06],\n",
       "       [2.94557842e-03, 1.11186411e-03],\n",
       "       [4.77178007e-01, 2.55887091e-01],\n",
       "       [9.99875307e-01, 9.99669313e-01],\n",
       "       [1.48718445e-05, 5.60340368e-06],\n",
       "       [4.46479635e-06, 1.68223062e-06],\n",
       "       [4.65939229e-06, 1.75555169e-06],\n",
       "       [4.56940174e-01, 2.40713462e-01],\n",
       "       [1.59534993e-05, 6.01094780e-06],\n",
       "       [9.99155521e-01, 9.97761607e-01],\n",
       "       [2.34522730e-01, 1.03488356e-01],\n",
       "       [1.23228519e-05, 4.64298455e-06],\n",
       "       [9.16825593e-06, 3.45439730e-06],\n",
       "       [4.44926977e-01, 2.31956840e-01],\n",
       "       [2.01039352e-02, 7.67078716e-03],\n",
       "       [2.53462046e-01, 1.13413587e-01],\n",
       "       [4.88387614e-01, 2.64528453e-01],\n",
       "       [1.81589930e-05, 6.84194811e-06],\n",
       "       [8.02587419e-06, 3.02396825e-06],\n",
       "       [4.85387981e-01, 2.62199134e-01],\n",
       "       [2.34264135e-05, 8.82662789e-06],\n",
       "       [2.82479188e-04, 1.06449974e-04],\n",
       "       [9.99610126e-01, 9.98965979e-01],\n",
       "       [3.97473620e-03, 1.50130375e-03],\n",
       "       [9.99874353e-01, 9.99666572e-01],\n",
       "       [8.63913228e-05, 3.25518922e-05],\n",
       "       [1.69948973e-02, 6.47181505e-03],\n",
       "       [6.05471314e-06, 2.28127851e-06],\n",
       "       [8.73041154e-06, 3.28942679e-06],\n",
       "       [1.64233115e-05, 6.18797185e-06],\n",
       "       [1.11245050e-03, 4.19435120e-04],\n",
       "       [3.84281611e-06, 1.44788260e-06],\n",
       "       [1.15572839e-05, 4.35453694e-06],\n",
       "       [3.74511146e-04, 1.41139637e-04],\n",
       "       [1.81649157e-05, 6.84418046e-06],\n",
       "       [1.04740575e-05, 3.94639846e-06],\n",
       "       [9.00261330e-06, 3.39198687e-06],\n",
       "       [1.09051998e-05, 4.10884422e-06],\n",
       "       [1.87738871e-04, 7.07437575e-05],\n",
       "       [2.37020049e-05, 8.93047672e-06],\n",
       "       [3.84515588e-05, 1.44879541e-05],\n",
       "       [2.50320300e-05, 9.43160376e-06],\n",
       "       [9.40493483e-05, 3.54376025e-05],\n",
       "       [5.05993128e-01, 2.78456390e-01],\n",
       "       [1.00122215e-05, 3.77238371e-06],\n",
       "       [9.99510646e-01, 9.98702407e-01],\n",
       "       [1.21861658e-05, 4.59148850e-06],\n",
       "       [5.51818403e-06, 2.07912376e-06],\n",
       "       [4.81466830e-01, 2.59172916e-01],\n",
       "       [9.99898434e-01, 9.99730408e-01],\n",
       "       [9.99840736e-01, 9.99577582e-01],\n",
       "       [3.86242900e-05, 1.45530366e-05],\n",
       "       [6.04028310e-06, 2.27583951e-06],\n",
       "       [4.42402035e-01, 2.30139434e-01],\n",
       "       [4.43094581e-01, 2.30637103e-01],\n",
       "       [3.87175942e-06, 1.45878766e-06],\n",
       "       [1.75603400e-05, 6.61637887e-06],\n",
       "       [6.76825039e-06, 2.55012424e-06],\n",
       "       [1.10772044e-05, 4.17364799e-06],\n",
       "       [4.53029573e-01, 2.37842903e-01],\n",
       "       [6.78134074e-06, 2.55505392e-06],\n",
       "       [9.99773204e-01, 9.99398112e-01],\n",
       "       [4.26965833e-01, 2.19197974e-01],\n",
       "       [2.19033379e-03, 8.26393021e-04],\n",
       "       [8.99168117e-06, 3.38786822e-06],\n",
       "       [2.49658274e-06, 9.40652683e-07],\n",
       "       [1.34003949e-05, 5.04898298e-06],\n",
       "       [9.09069877e-06, 3.42517228e-06],\n",
       "       [1.48316476e-05, 5.58825377e-06],\n",
       "       [4.51687664e-01, 2.36862376e-01],\n",
       "       [4.84608572e-05, 1.82594322e-05],\n",
       "       [4.95284348e-06, 1.86611771e-06],\n",
       "       [2.32969847e-04, 8.77901766e-05],\n",
       "       [3.11311036e-01, 1.45529613e-01],\n",
       "       [3.00808279e-05, 1.13339320e-05],\n",
       "       [1.88158512e-01, 8.03112686e-02],\n",
       "       [9.99569356e-01, 9.98857975e-01],\n",
       "       [4.47332131e-05, 1.68548668e-05],\n",
       "       [1.42122532e-04, 5.35530344e-05],\n",
       "       [7.62034906e-05, 2.87129715e-05],\n",
       "       [4.77325375e-06, 1.79845222e-06],\n",
       "       [9.59324825e-05, 3.61471757e-05],\n",
       "       [5.28969646e-01, 2.97319174e-01],\n",
       "       [7.92217907e-06, 2.98490090e-06],\n",
       "       [5.80064661e-05, 2.18562272e-05],\n",
       "       [9.72013877e-05, 3.66253553e-05],\n",
       "       [4.32151645e-01, 2.22841620e-01],\n",
       "       [4.17175740e-01, 2.12406024e-01],\n",
       "       [5.03750741e-01, 2.76657641e-01],\n",
       "       [2.01995172e-05, 7.61077990e-06],\n",
       "       [9.98906255e-01, 9.97102320e-01],\n",
       "       [5.06621838e-01, 2.78962016e-01],\n",
       "       [1.04845343e-02, 3.97629989e-03],\n",
       "       [9.99799907e-01, 9.99468982e-01],\n",
       "       [4.12210829e-05, 1.55315083e-05],\n",
       "       [9.79238093e-01, 9.46725607e-01],\n",
       "       [4.35808241e-01, 2.25430265e-01],\n",
       "       [4.02578086e-01, 2.02484250e-01],\n",
       "       [5.05249845e-05, 1.90371957e-05],\n",
       "       [4.48649943e-01, 2.34651163e-01],\n",
       "       [1.83155723e-02, 6.98054349e-03],\n",
       "       [2.17883417e-06, 8.20932542e-07],\n",
       "       [5.96250356e-06, 2.24653400e-06],\n",
       "       [7.02923853e-06, 2.64845676e-06],\n",
       "       [3.58897728e-06, 1.35224184e-06],\n",
       "       [4.49245036e-01, 2.35083371e-01],\n",
       "       [9.99685407e-01, 9.99165535e-01],\n",
       "       [9.96917606e-06, 3.75616878e-06],\n",
       "       [4.44307357e-01, 2.31510118e-01],\n",
       "       [4.74798024e-01, 2.54074454e-01],\n",
       "       [1.70775002e-05, 6.43445856e-06],\n",
       "       [2.44206720e-04, 9.20251259e-05],\n",
       "       [3.24626424e-04, 1.22336045e-04],\n",
       "       [4.41232532e-06, 1.66246082e-06],\n",
       "       [1.05697654e-05, 3.98245902e-06],\n",
       "       [1.98477865e-05, 7.47825152e-06],\n",
       "       [9.99915719e-01, 9.99776304e-01],\n",
       "       [2.09256650e-05, 7.88438865e-06],\n",
       "       [4.76653039e-01, 2.55486637e-01],\n",
       "       [8.80113002e-05, 3.31623523e-05],\n",
       "       [1.37820651e-04, 5.19319547e-05],\n",
       "       [4.98802274e-01, 2.72714049e-01],\n",
       "       [1.30956232e-05, 4.93415519e-06],\n",
       "       [1.82513803e-01, 7.75927231e-02],\n",
       "       [4.51584190e-01, 2.36786857e-01],\n",
       "       [1.03958072e-02, 3.94243235e-03],\n",
       "       [7.04002650e-06, 2.65252129e-06],\n",
       "       [4.55495030e-01, 2.39650413e-01],\n",
       "       [9.07540198e-06, 3.41941177e-06],\n",
       "       [9.99759614e-01, 9.99362171e-01],\n",
       "       [8.47363408e-05, 3.19282663e-05],\n",
       "       [6.92015556e-06, 2.60735646e-06],\n",
       "       [4.95867462e-05, 1.86836478e-05],\n",
       "       [9.10567451e-06, 3.43081820e-06],\n",
       "       [4.98675287e-01, 2.72613347e-01],\n",
       "       [5.94186440e-06, 2.23875759e-06],\n",
       "       [4.12962527e-06, 1.55594728e-06],\n",
       "       [1.42827666e-05, 5.38144423e-06],\n",
       "       [2.60966754e-05, 9.83274731e-06],\n",
       "       [4.83293265e-01, 2.60579854e-01],\n",
       "       [3.16446930e-01, 1.48520336e-01],\n",
       "       [1.15873681e-05, 4.36586788e-06],\n",
       "       [1.33570458e-04, 5.03303236e-05],\n",
       "       [7.55344672e-06, 2.84597013e-06],\n",
       "       [3.02182976e-04, 1.13876595e-04],\n",
       "       [4.52095363e-03, 1.70819834e-03],\n",
       "       [9.99402165e-01, 9.98414874e-01],\n",
       "       [3.17680569e-05, 1.19696742e-05],\n",
       "       [4.33615409e-03, 1.63818453e-03],\n",
       "       [6.49848243e-06, 2.44848138e-06],\n",
       "       [5.21041193e-06, 1.96316205e-06],\n",
       "       [5.64852147e-04, 2.12897488e-04],\n",
       "       [1.80353527e-05, 6.79536242e-06],\n",
       "       [4.92035210e-01, 2.67377973e-01],\n",
       "       [4.04609746e-04, 1.52485562e-04],\n",
       "       [9.99697089e-01, 9.99196470e-01],\n",
       "       [2.04202230e-03, 7.70365121e-04],\n",
       "       [4.88770101e-03, 1.84719474e-03],\n",
       "       [1.32356927e-05, 4.98692589e-06],\n",
       "       [5.49828587e-03, 2.07874458e-03],\n",
       "       [4.25537701e-06, 1.60332615e-06],\n",
       "       [4.14942592e-01, 2.10872427e-01],\n",
       "       [2.75894708e-05, 1.03952152e-05],\n",
       "       [4.12197232e-01, 2.08994925e-01],\n",
       "       [4.73411322e-01, 2.53021866e-01],\n",
       "       [4.19007629e-01, 2.13668361e-01],\n",
       "       [6.46684784e-04, 2.43753340e-04],\n",
       "       [5.08865778e-05, 1.91734453e-05],\n",
       "       [3.14653444e-05, 1.18556136e-05],\n",
       "       [3.55263725e-02, 1.36885503e-02],\n",
       "       [4.31377500e-01, 2.22295627e-01],\n",
       "       [7.92217068e-03, 2.99969339e-03],\n",
       "       [9.99601662e-01, 9.98943388e-01],\n",
       "       [3.92121039e-02, 1.51442643e-02],\n",
       "       [2.70396049e-05, 1.01880332e-05],\n",
       "       [2.73834430e-05, 1.03175862e-05],\n",
       "       [1.65132515e-04, 6.22242951e-05],\n",
       "       [3.79352772e-04, 1.42964695e-04],\n",
       "       [7.99469126e-06, 3.01221894e-06],\n",
       "       [4.30064261e-01, 2.21371144e-01],\n",
       "       [1.76807553e-05, 6.66175583e-06],\n",
       "       [7.31364298e-06, 2.75561683e-06],\n",
       "       [2.89646996e-05, 1.09133871e-05],\n",
       "       [1.87918831e-05, 7.08040488e-06],\n",
       "       [4.47151572e-01, 2.33564675e-01],\n",
       "       [9.99901652e-01, 9.99739110e-01],\n",
       "       [5.00606402e-05, 1.88622271e-05],\n",
       "       [8.49946446e-06, 3.20241020e-06],\n",
       "       [6.65064681e-06, 2.50581388e-06],\n",
       "       [9.99926448e-01, 9.99804676e-01],\n",
       "       [1.30952485e-05, 4.93401421e-06],\n",
       "       [3.45106363e-01, 1.65656999e-01],\n",
       "       [7.52144524e-06, 2.83391228e-06],\n",
       "       [8.85684040e-06, 3.33706225e-06],\n",
       "       [9.97171223e-01, 9.92526889e-01],\n",
       "       [4.43696231e-01, 2.31069997e-01],\n",
       "       [9.99859929e-01, 9.99628425e-01],\n",
       "       [1.57554809e-03, 5.94212033e-04],\n",
       "       [2.61020556e-04, 9.83622376e-05],\n",
       "       [1.24126498e-04, 4.67714854e-05],\n",
       "       [9.36284050e-06, 3.52770985e-06],\n",
       "       [2.45945557e-05, 9.26677785e-06],\n",
       "       [9.99832630e-01, 9.99556005e-01],\n",
       "       [9.99888778e-01, 9.99704897e-01],\n",
       "       [1.09567911e-04, 4.12853660e-05],\n",
       "       [4.35420066e-01, 2.25154743e-01],\n",
       "       [1.89224756e-05, 7.12961082e-06],\n",
       "       [1.27393575e-02, 4.83829621e-03],\n",
       "       [4.32241112e-01, 2.22904772e-01],\n",
       "       [3.19364494e-06, 1.20328957e-06],\n",
       "       [3.30468616e-03, 1.24769576e-03],\n",
       "       [4.70909953e-01, 2.51129597e-01],\n",
       "       [4.37065244e-01, 2.26323888e-01],\n",
       "       [9.99592006e-01, 9.98917937e-01],\n",
       "       [4.20527458e-01, 2.14718655e-01],\n",
       "       [6.54848525e-04, 2.46831769e-04],\n",
       "       [5.04983564e-06, 1.90266223e-06],\n",
       "       [9.99854445e-01, 9.99613822e-01],\n",
       "       [4.31347847e-01, 2.22274750e-01],\n",
       "       [4.70690995e-01, 2.50964433e-01],\n",
       "       [2.18867240e-06, 8.24639301e-07],\n",
       "       [1.05990166e-05, 3.99347709e-06],\n",
       "       [6.46496665e-06, 2.43585328e-06],\n",
       "       [4.35084194e-01, 2.24916443e-01],\n",
       "       [1.23340906e-05, 4.64721961e-06],\n",
       "       [2.11869883e-05, 7.98284418e-06],\n",
       "       [4.99647737e-01, 2.73385346e-01],\n",
       "       [4.70259517e-01, 2.50638932e-01],\n",
       "       [1.70012554e-05, 6.40573126e-06],\n",
       "       [6.66575725e-05, 2.51159854e-05],\n",
       "       [4.43330828e-05, 1.67040962e-05],\n",
       "       [2.92552413e-05, 1.10228593e-05],\n",
       "       [1.51793693e-05, 5.71926921e-06],\n",
       "       [5.18126860e-02, 2.01731753e-02],\n",
       "       [4.11996573e-01, 2.08858043e-01],\n",
       "       [3.13292571e-06, 1.18041203e-06],\n",
       "       [7.06535684e-06, 2.66206484e-06],\n",
       "       [9.99661803e-01, 9.99102831e-01],\n",
       "       [2.16686912e-03, 8.17527645e-04],\n",
       "       [2.47707176e-05, 9.33315368e-06],\n",
       "       [9.99608099e-01, 9.98960376e-01],\n",
       "       [4.18366402e-01, 2.13226050e-01],\n",
       "       [7.00685719e-04, 2.64116708e-04],\n",
       "       [4.34297532e-01, 2.24358827e-01],\n",
       "       [3.43251327e-06, 1.29329101e-06],\n",
       "       [4.03717240e-06, 1.52111147e-06],\n",
       "       [1.96777492e-05, 7.41418489e-06],\n",
       "       [9.99902248e-01, 9.99740779e-01],\n",
       "       [4.56937879e-01, 2.40711778e-01],\n",
       "       [1.44196820e-05, 5.43303713e-06],\n",
       "       [1.66893855e-03, 6.29470509e-04],\n",
       "       [2.76128994e-03, 1.04218046e-03],\n",
       "       [9.11987536e-06, 3.43616853e-06],\n",
       "       [9.99904871e-01, 9.99747574e-01],\n",
       "       [2.50957037e-05, 9.45559532e-06],\n",
       "       [1.39137998e-01, 5.74013330e-02],\n",
       "       [6.66884996e-04, 2.51370540e-04],\n",
       "       [1.42152348e-04, 5.35643230e-05],\n",
       "       [8.99790939e-06, 3.39021449e-06],\n",
       "       [3.35542828e-01, 1.59852520e-01],\n",
       "       [9.97528136e-01, 9.93466079e-01],\n",
       "       [1.78008086e-05, 6.70699046e-06],\n",
       "       [4.68545586e-01, 2.49348670e-01],\n",
       "       [1.33059330e-05, 5.01339082e-06],\n",
       "       [1.35352011e-05, 5.09977599e-06],\n",
       "       [1.00241647e-04, 3.77709584e-05],\n",
       "       [6.36448618e-04, 2.39893547e-04],\n",
       "       [5.57501480e-05, 2.10060425e-05],\n",
       "       [9.30609986e-06, 3.50633059e-06],\n",
       "       [4.47702587e-01, 2.33963922e-01],\n",
       "       [9.98819768e-01, 9.96873736e-01],\n",
       "       [4.76782531e-01, 2.55585372e-01],\n",
       "       [2.36872274e-05, 8.92490061e-06],\n",
       "       [3.59894443e-06, 1.35599726e-06],\n",
       "       [2.40319350e-04, 9.05600900e-05],\n",
       "       [9.99907017e-01, 9.99753296e-01],\n",
       "       [1.08165586e-05, 4.07544621e-06],\n",
       "       [1.99859078e-05, 7.53029417e-06],\n",
       "       [5.88899411e-06, 2.21883920e-06],\n",
       "       [4.20734286e-01, 2.14861810e-01],\n",
       "       [1.07592541e-05, 4.05385481e-06],\n",
       "       [1.25353508e-05, 4.72305464e-06],\n",
       "       [8.80197331e-06, 3.31638626e-06],\n",
       "       [4.82287288e-01, 2.59804398e-01],\n",
       "       [3.05375773e-02, 1.17290476e-02],\n",
       "       [6.37490666e-06, 2.40191844e-06],\n",
       "       [3.79149133e-05, 1.42857498e-05],\n",
       "       [1.06561383e-05, 4.01499938e-06],\n",
       "       [6.69913692e-03, 2.53465539e-03],\n",
       "       [1.25146616e-05, 4.71525482e-06],\n",
       "       [3.94831374e-02, 1.52515853e-02],\n",
       "       [3.22933101e-06, 1.21673656e-06],\n",
       "       [1.41549499e-05, 5.33328557e-06],\n",
       "       [9.97589469e-01, 9.93627667e-01],\n",
       "       [6.31203966e-06, 2.37823156e-06],\n",
       "       [2.44471885e-05, 9.21124229e-06],\n",
       "       [4.40120935e-01, 2.28504255e-01],\n",
       "       [7.09942105e-05, 2.67500654e-05],\n",
       "       [3.82274069e-04, 1.44065911e-04],\n",
       "       [4.15257424e-01, 2.11088285e-01],\n",
       "       [3.50612514e-02, 1.35053387e-02],\n",
       "       [3.86371084e-06, 1.45575518e-06],\n",
       "       [5.86496162e-06, 2.20978200e-06],\n",
       "       [1.95117755e-05, 7.35165668e-06],\n",
       "       [1.93635114e-02, 7.38482317e-03],\n",
       "       [2.19750655e-05, 8.27977965e-06],\n",
       "       [4.59332079e-01, 2.42478907e-01],\n",
       "       [9.99952435e-01, 9.99873638e-01],\n",
       "       [2.36670421e-05, 8.91730269e-06],\n",
       "       [9.99744236e-01, 9.99321342e-01],\n",
       "       [4.65245508e-02, 1.80527698e-02],\n",
       "       [4.16859329e-01, 2.12188363e-01],\n",
       "       [2.42160779e-04, 9.12541218e-05],\n",
       "       [1.52099878e-04, 5.73129400e-05],\n",
       "       [1.36554163e-05, 5.14507519e-06],\n",
       "       [4.81839836e-01, 2.59459943e-01],\n",
       "       [4.20167208e-01, 2.14469478e-01],\n",
       "       [9.84069266e-06, 3.70775524e-06],\n",
       "       [4.51892167e-01, 2.37011641e-01],\n",
       "       [4.77418189e-06, 1.79880203e-06],\n",
       "       [1.16660751e-01, 4.74012978e-02],\n",
       "       [4.57245409e-01, 2.40938321e-01],\n",
       "       [2.88387400e-05, 1.08659369e-05],\n",
       "       [9.99966860e-01, 9.99912024e-01],\n",
       "       [3.64116636e-06, 1.37190546e-06],\n",
       "       [5.11126200e-06, 1.92580455e-06],\n",
       "       [6.02546288e-06, 2.27025544e-06],\n",
       "       [4.35276330e-01, 2.25052699e-01],\n",
       "       [9.99565065e-01, 9.98846292e-01],\n",
       "       [1.74375818e-05, 6.57012561e-06],\n",
       "       [8.35686296e-06, 3.14867771e-06],\n",
       "       [4.40176904e-01, 2.28544325e-01],\n",
       "       [1.02985970e-04, 3.88051194e-05],\n",
       "       [4.42075288e-05, 1.66567897e-05],\n",
       "       [7.91530783e-06, 2.98231157e-06],\n",
       "       [5.14678955e-01, 2.85493582e-01],\n",
       "       [2.40563841e-05, 9.06399328e-06],\n",
       "       [5.76123653e-04, 2.17147375e-04],\n",
       "       [4.95266577e-04, 1.86662015e-04],\n",
       "       [7.16244131e-02, 2.82472502e-02],\n",
       "       [1.96877718e-05, 7.41796930e-06],\n",
       "       [7.29956446e-05, 2.75042239e-05],\n",
       "       [1.09981757e-03, 4.14668757e-04],\n",
       "       [4.15842295e-01, 2.11489603e-01],\n",
       "       [9.99716103e-01, 9.99247074e-01],\n",
       "       [9.99935627e-01, 9.99829054e-01]], dtype=float32), label_ids=array([0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 1, 2, 2], dtype=int64), metrics={'test_loss': 0.7081089615821838, 'test_accuracy': 0.7261146496815286, 'test_f1': 0.2804428044280443, 'test_precision': 0.24203821656050953, 'test_recall': 0.3333333333333333, 'test_runtime': 0.5675, 'test_samples_per_second': 829.938, 'test_steps_per_second': 26.431})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51f5d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.071624', '0.028247']\n"
     ]
    }
   ],
   "source": [
    "item = [7.16244131e-02, 2.82472502e-02]\n",
    "print([format(x, 'f') for x in item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b62df80",
   "metadata": {},
   "source": [
    "# Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9efbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_hate_df = pd.read_csv(data_path+\"kaggle_hate_test.txt\", sep='\\t')\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(kaggle_hate_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874117b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label =  kaggle_hate_df[\"hate\"].values\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cabf94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0280b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORN_outputs/output/pytorch_model.bin'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 학습하고자하는 🤗 Transformers model                # 위에서 정의한 Training Arguments\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdfca9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 974\n",
      "  Batch size = 8\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122/122 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04abcc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corn_label_from_logits(logits):\n",
    "    #probas = torch.cumprod(logits, dim=1)\n",
    "    #probas = logits\n",
    "    probas = logits\n",
    "    predict_levels = probas > 0.5\n",
    "    predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6f0c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = corn_label_from_logits(torch.tensor(predictions.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb74ab5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "969  0\n",
       "970  2\n",
       "971  1\n",
       "972  2\n",
       "973  0\n",
       "\n",
       "[974 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(preds_list)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "260a2aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "969  0\n",
       "970  2\n",
       "971  1\n",
       "972  2\n",
       "973  0\n",
       "\n",
       "[974 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e65c7a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>장현승 얘도 참 이젠 짠하다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>난 조보아 이뻐서 보는데 백종원 관심무</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  label\n",
       "0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ      1\n",
       "1                                        둘다 넘 좋다~행복하세요      0\n",
       "2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데      2\n",
       "3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요      0\n",
       "4                                   장현승 얘도 참 이젠 짠하다...      0\n",
       "..                                                 ...    ...\n",
       "969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹      0\n",
       "970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...      2\n",
       "971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...      1\n",
       "972                               입에 손가릭이 10개 있으니 징그럽다      2\n",
       "973                              난 조보아 이뻐서 보는데 백종원 관심무      0\n",
       "\n",
       "[974 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df = pd.concat([kaggle_hate_df['comments'], pred_df[0]], axis=1)\n",
    "kaggle_df.columns = ['comments', 'label']\n",
    "kaggle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33069a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv(\"kaggle_hate_KoGPT2_CORN2.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5d099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
