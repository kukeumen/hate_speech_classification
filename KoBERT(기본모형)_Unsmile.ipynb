{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6026f360",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-85b761a7dd58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmetrics_for_multilabel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolwise_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbert_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mData_for_BERT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBERTClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\2022_master\\KoBERT\\bert_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# KoBERT 모델\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from metrics_for_multilabel import calculate_metrics, colwise_accuracy\n",
    "\n",
    "from bert_model import Data_for_BERT, BERTClassifier, EarlyStopping\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a1cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python36\\site-packages\\mxnet\\optimizer\\optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f6cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfad38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ef82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133147d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47cae028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183a8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\.cache\\kobert_v1.zip\n",
      "using cached model. C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "kobert_get_tokenizer = get_tokenizer()\n",
    "kobert_model, kobert_vocab = get_pytorch_kobert_model()\n",
    "kobert_tokenizer = nlp.data.BERTSPTokenizer(kobert_get_tokenizer, kobert_vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b1fbb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일안하는 시간은 쉬고싶어서 그런게 아닐까</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>홍팍에도 어버이연합인가 보내요 뭐 이런뎃글 있는데 이거 어버이연합측에 신고하면 그쪽...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아놔 왜 여기 댓들은 다 여자들이 김치녀라고 먼저 불렸다! 여자들은 더 심하게 그런...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  문장  \\\n",
       "0                             일안하는 시간은 쉬고싶어서 그런게 아닐까   \n",
       "1  아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...   \n",
       "2  루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...   \n",
       "3  홍팍에도 어버이연합인가 보내요 뭐 이런뎃글 있는데 이거 어버이연합측에 신고하면 그쪽...   \n",
       "4  아놔 왜 여기 댓들은 다 여자들이 김치녀라고 먼저 불렸다! 여자들은 더 심하게 그런...   \n",
       "\n",
       "                           labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "unsmile_train_dataset = pd.read_csv(data_path+\"Unsmile_train_dataset.csv\")\n",
    "unsmile_train_dataset = pd.concat([unsmile_train_dataset['문장'], unsmile_train_dataset['labels']], axis=1)\n",
    "unsmile_test_dataset = pd.read_csv(data_path+\"Unsmile_test_dataset.csv\")\n",
    "unsmile_test_dataset = pd.concat([unsmile_test_dataset['문장'], unsmile_test_dataset['labels']], axis=1)\n",
    "unsmile_train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40012d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "짠돌이보단 낫다\n",
      "['[CLS]', '▁', '짠', '돌', '이', '보', '단', '▁', '낫', '다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "idx = 70\n",
    "detoken_list = detokenizer(token_list[idx][0])\n",
    "print(koco_test_dataset[idx][0])\n",
    "print(detoken_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de87db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8ea4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "koco_train_BERTDataset = BERTDataset(koco_train_dataset, 0, 1, kobert_tokenizer, max_len, True, False)\n",
    "koco_test_BERTDataset = BERTDataset(koco_test_dataset, 0, 1, kobert_tokenizer, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b67dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2,  517,   54,  517,   54,  517,   54,  517,   54, 4958, 7206,\n",
       "        2149, 7119, 7095, 1678, 2468,  517,   54,  517,   54,  517,   54,\n",
       "        1458, 5655,  517, 5450, 5439, 6797, 6117, 5785, 6213, 6699,  517,\n",
       "          54,  517,   54,  517,   54, 1185, 6213, 6699, 5916, 7095, 2948,\n",
       "        7766, 7088, 2149, 7416, 3166, 7318, 6224, 7864, 5703,    0,    3,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " array(55),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "koco_train_BERTDataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfdd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "koco_train_dataloader = torch.utils.data.DataLoader(koco_train_BERTDataset, batch_size=batch_size, num_workers=0)\n",
    "koco_test_dataloader = torch.utils.data.DataLoader(koco_test_BERTDataset, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915df2f9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d32ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=3,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a29fef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(num_classes,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6763bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be3769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.BCWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46886f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(koco_train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe77fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a71f8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c946441",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af7f83ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66681444b7bf4ef3a02e6edf20c6408c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.0209240913391113 train acc 0.5\n",
      "epoch 1 train acc 0.6294942876344086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201374d7617f4f7d93a3fa63a80fed04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.8348466157913208 train acc 0.625\n",
      "epoch 2 train acc 0.7232862903225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d254dfab5047a2a4b96d8345f5e7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.6860823035240173 train acc 0.71875\n",
      "epoch 3 train acc 0.790112567204301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2487b7e88947a2bab08db007345c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.5598117113113403 train acc 0.8125\n",
      "epoch 4 train acc 0.8501344086021506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2721b0d36a48228b47c2494ce8ec6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.5614600777626038 train acc 0.78125\n",
      "epoch 5 train acc 0.8866347446236559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d5f68fb2d2405fac9ab2137e569fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.2864173948764801 train acc 0.890625\n",
      "epoch 6 train acc 0.9367439516129032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d07fa263a04522a1ad542d5b8b4b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.2612796425819397 train acc 0.921875\n",
      "epoch 7 train acc 0.9536290322580645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b63e896d16d4d1c9d339481fc6f4de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.23065674304962158 train acc 0.921875\n",
      "epoch 8 train acc 0.9712701612903226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23717d4dc24f41c5ad22bb6868a757bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.13765768706798553 train acc 0.953125\n",
      "epoch 9 train acc 0.9812247983870968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ddf7630435411b93c262402b54cd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.11843327432870865 train acc 0.96875\n",
      "epoch 10 train acc 0.9860131048387096\n",
      "train_run_time:  271.9274363517761\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# to track the training loss as the model trains\n",
    "train_losses = []\n",
    "# to track the validation loss as the model trains\n",
    "valid_losses = []\n",
    "# to track the average training loss per epoch as the model trains\n",
    "avg_train_losses = []\n",
    "# to track the average validation loss per epoch as the model trains\n",
    "avg_valid_losses = [] \n",
    "    \n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, path=path)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    model.train()\n",
    "    train_epoch_pred=[]\n",
    "    train_loss_record=[]\n",
    "    \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(koco_train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        \n",
    "        label = label.long().to(device)\n",
    "        \n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        \n",
    "        loss = loss_fn(out, label) #BCWithLogitloss loss\n",
    "        train_loss_record.append(loss)\n",
    "        train_pred=out.detach().cpu().numpy()\n",
    "        train_real=label.detach().cpu().numpy()\n",
    "        \n",
    "        train_epoch_pred.append(train_pred)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "        \n",
    "        del loss, label, token_ids, valid_length, segment_ids, out\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    train_epoch_pred = np.concatenate(train_epoch_pred)\n",
    "    train_epoch_target=train_dataloader.dataset.labels\n",
    "    train_epoch_result=calculate_metrics(target=train_epoch_target, pred=train_epoch_pred)\n",
    "       \n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "end_time = time.time()\n",
    "print(\"train_run_time: \", float(end_time) - float(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1427ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'koco_bias_kobert_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aabfec",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e66394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1674472242c54dd0b080b905dddeb7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_torch_list=[] #predict 값 list 생성\n",
    "test_acc=0\n",
    "#model_path = 'C:/Users/USER/Desktop/2022/koco_kobert_model.pt'\n",
    "#model_path = 'koco_kobert_model.pt'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(koco_test_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        preds_torch_list.append(out)\n",
    "        \n",
    "        del label, token_ids, valid_length, segment_ids, out\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ade8a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "preds_list = list()\n",
    "for temp_list in preds_torch_list:\n",
    "    max_vals, max_indices = torch.max(torch.tensor(temp_list), axis=1)\n",
    "    max_list = max_indices.tolist()\n",
    "    preds_list.extend(max_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311d479",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e92a7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = koco_test_BERTDataset.labels\n",
    "preds_list = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb5f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       342\n",
      "           1       0.42      0.53      0.47        62\n",
      "           2       0.69      0.70      0.70        67\n",
      "\n",
      "    accuracy                           0.78       471\n",
      "   macro avg       0.66      0.69      0.68       471\n",
      "weighted avg       0.80      0.78      0.79       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d03d4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "044310c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2824)\n",
      "tensor(0.4055)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d6fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10",
   "language": "python",
   "name": "badtext10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
