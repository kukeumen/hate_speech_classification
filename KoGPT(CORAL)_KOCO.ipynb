{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "MODEL_NAME= \"skt/kogpt2-base-v2\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME,\n",
    "                                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                                                    pad_token='<pad>', mask_token='<mask>') \n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39b0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='left', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21abbfd",
   "metadata": {},
   "source": [
    "# Load Koco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  hate\n",
       "0  (ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...     2\n",
       "1  ....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...     0\n",
       "2  ...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...     2\n",
       "3                 1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞     0\n",
       "4  1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...     2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_hate_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_hate_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"hate\"].values\n",
    "test_label =  koco_test_df[\"hate\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c08e8e",
   "metadata": {},
   "source": [
    "# Î™®Îç∏ ÌäúÎãù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4cc2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.losses import CoralLoss, corn_loss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label\n",
    "from typing import Optional, Union, Tuple\n",
    "from transformers.activations import get_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb42205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput, SequenceClassifierOutputWithPast\n",
    "from transformers import GPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76842350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2PreTrainedModel, GPT2Model\n",
    "import torch.nn as nn\n",
    "class GPT2ForSequenceClassification(GPT2PreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"h\\.\\d+\\.attn\\.masked_bias\", r\"lm_head.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.score = nn.Linear(config.n_embd, self.num_labels, bias=False)\n",
    "        self.coral_layer = CoralLayer(config.n_embd, config.num_labels)\n",
    "        #self.classifier = nn.Linear(config.hidden_size, config.num_labels-1)\n",
    "        self.hidden_states = None\n",
    "        self.logits = None\n",
    "        self.pooled_logits = None\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        #logits = self.coral_layer(hidden_states)\n",
    "        self.hidden_states = hidden_states\n",
    "        logits = self.coral_layer(hidden_states)\n",
    "        probas = torch.sigmoid(logits)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            batch_size, sequence_length = input_ids.shape[:2]\n",
    "        else:\n",
    "            batch_size, sequence_length = inputs_embeds.shape[:2]\n",
    "\n",
    "        assert (\n",
    "            self.config.pad_token_id is not None or batch_size == 1\n",
    "        ), \"Cannot handle batch sizes > 1 if no padding token is defined.\"\n",
    "        if self.config.pad_token_id is None:\n",
    "            sequence_lengths = -1\n",
    "        else:\n",
    "            if input_ids is not None:\n",
    "                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n",
    "            else:\n",
    "                sequence_lengths = -1\n",
    "                logger.warning(\n",
    "                    f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n",
    "                    \"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n",
    "                )\n",
    "\n",
    "        pooled_logits = logits[torch.arange(batch_size, device=logits.device), sequence_lengths] #probas\n",
    "        #logits = self.coral_layer(pooled_logits)\n",
    "        probas = torch.sigmoid(pooled_logits)\n",
    "        probas = torch.cumprod(probas, dim=1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(pooled_logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(pooled_logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(pooled_logits, labels)\n",
    "            elif self.config.problem_type == \"CORAL\":\n",
    "                iw = torch.tensor([0.3, 0.7]).to(device)\n",
    "                loss_fct = CoralLoss()\n",
    "                levels = levels_from_labelbatch(labels.view(-1) , num_classes=3).to(device)\n",
    "                loss = loss_fct(pooled_logits, levels, importance_weights=iw)\n",
    "                    \n",
    "        if not return_dict:\n",
    "            output = (pooled_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=probas,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c0a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\13bb826cf24517d7849a701e02452715a67c5e560142be3d4735442b2a545809.6b384eec6effdd44287f67715cd55bd0dff2cf846d843b932b43ba7b632b8b1e\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"problem_type\": \"CORAL\",\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/pytorch_model.bin from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\495b405e3742953dbcc56685d1560fa02a2d86fc50b891868990a4471b06c934.4ebf112d34c2c8fc657866680005d92d21859c52c0ef5e941fa640129b2f8f88\n",
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['coral_layer.coral_weights.weight', 'score.weight', 'coral_layer.coral_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       "  (coral_layer): CoralLayer(\n",
       "    (coral_weights): Linear(in_features=768, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = GPT2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, problem_type='CORAL')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/', # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    num_train_epochs=10,                # ÌïôÏäµ epoch ÏÑ§Ï†ï\n",
    "    per_device_train_batch_size=4,      # train batch_size ÏÑ§Ï†ï\n",
    "    per_device_eval_batch_size=32,      # test batch_size ÏÑ§Ï†ï\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/logs/',# ÌïôÏäµlog Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    logging_steps=500,                  # ÌïôÏäµlog Í∏∞Î°ù Îã®ÏúÑ\n",
    "    save_total_limit=2,                 # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû• ÏµúÎåÄÍ∞ØÏàò \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # ÌïôÏäµÌïòÍ≥†ÏûêÌïòÎäî ü§ó Transformers model\n",
    "    args=training_args,                  # ÏúÑÏóêÏÑú Ï†ïÏùòÌïú Training Arguments\n",
    "    train_dataset=train_dataset,         # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    eval_dataset=test_dataset,           # ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    compute_metrics=compute_metrics,     # ÌèâÍ∞ÄÏßÄÌëú\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30264903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 20:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.570300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.389600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.380200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.303900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.330700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.313200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.286200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.257800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.202800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.205900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.183600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.173100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.170300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.164400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_CORAL_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.2982992019576021, metrics={'train_runtime': 1223.9314, 'train_samples_per_second': 64.513, 'train_steps_per_second': 16.128, 'total_flos': 2579045561487360.0, 'train_loss': 0.2982992019576021, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.209944248199463,\n",
       " 'eval_accuracy': 0.33970276008492567,\n",
       " 'eval_f1': 0.16904384574749076,\n",
       " 'eval_precision': 0.11323425336164189,\n",
       " 'eval_recall': 0.3333333333333333,\n",
       " 'eval_runtime': 0.5645,\n",
       " 'eval_samples_per_second': 834.378,\n",
       " 'eval_steps_per_second': 26.573,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_CORAL_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d8cdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.78591573e-06, 7.75366230e-12],\n",
       "       [4.92729664e-01, 1.21924363e-01],\n",
       "       [9.99445140e-01, 9.97808635e-01],\n",
       "       [4.62864608e-01, 1.04528770e-01],\n",
       "       [4.41230357e-01, 9.30662006e-02],\n",
       "       [9.99999881e-01, 9.99999642e-01],\n",
       "       [5.10547443e-06, 8.82366489e-12],\n",
       "       [3.97832127e-06, 5.35767307e-12],\n",
       "       [3.54075074e-01, 5.54191433e-02],\n",
       "       [2.37681307e-02, 1.94288805e-04],\n",
       "       [3.83867025e-01, 6.68579936e-02],\n",
       "       [4.49080050e-01, 9.71191972e-02],\n",
       "       [2.39607725e-05, 1.94349689e-10],\n",
       "       [4.95105565e-01, 1.23390727e-01],\n",
       "       [4.55105186e-01, 1.00311428e-01],\n",
       "       [6.85246632e-05, 1.58960356e-09],\n",
       "       [4.67888057e-01, 1.07323997e-01],\n",
       "       [9.99978662e-01, 9.99915719e-01],\n",
       "       [4.65288699e-01, 1.05871193e-01],\n",
       "       [2.71543191e-04, 2.49649812e-08],\n",
       "       [2.66431871e-05, 2.40300890e-10],\n",
       "       [1.01605186e-03, 3.49702788e-07],\n",
       "       [5.31442821e-01, 1.47437155e-01],\n",
       "       [3.18801649e-05, 3.44053230e-10],\n",
       "       [6.62058243e-04, 1.48442339e-07],\n",
       "       [4.57022397e-05, 7.07071623e-10],\n",
       "       [4.46311474e-01, 9.56761390e-02],\n",
       "       [9.99995470e-01, 9.99982119e-01],\n",
       "       [2.53806820e-06, 2.18063349e-12],\n",
       "       [4.63121682e-01, 1.04670547e-01],\n",
       "       [9.99602735e-01, 9.98430490e-01],\n",
       "       [3.89911911e-05, 5.14658927e-10],\n",
       "       [3.67119446e-06, 4.56237652e-12],\n",
       "       [1.53346511e-03, 7.96826782e-07],\n",
       "       [3.54449039e-05, 4.25297797e-10],\n",
       "       [9.95722294e-01, 9.83244002e-01],\n",
       "       [4.57084775e-01, 1.01375923e-01],\n",
       "       [4.37129551e-04, 6.47024976e-08],\n",
       "       [4.79848742e-01, 1.14189602e-01],\n",
       "       [2.84947688e-04, 2.74908079e-08],\n",
       "       [4.93233174e-01, 1.22234084e-01],\n",
       "       [5.64133048e-01, 1.71864599e-01],\n",
       "       [9.99998689e-01, 9.99994993e-01],\n",
       "       [1.39508571e-04, 6.58896537e-09],\n",
       "       [4.13660020e-01, 7.97452778e-02],\n",
       "       [2.15908587e-01, 1.84095651e-02],\n",
       "       [9.99987960e-01, 9.99952316e-01],\n",
       "       [2.22974541e-05, 1.68303177e-10],\n",
       "       [5.15513122e-01, 1.36512637e-01],\n",
       "       [4.58593816e-01, 1.02192611e-01],\n",
       "       [9.99353111e-01, 9.97445881e-01],\n",
       "       [1.60714597e-04, 8.74444339e-09],\n",
       "       [4.27937359e-01, 8.64693224e-02],\n",
       "       [3.86724442e-01, 6.80294037e-02],\n",
       "       [4.72537667e-01, 1.09957404e-01],\n",
       "       [4.38362032e-01, 9.16146860e-02],\n",
       "       [2.53656030e-01, 2.61717569e-02],\n",
       "       [4.43850338e-01, 9.44057703e-02],\n",
       "       [4.45439816e-01, 9.52248722e-02],\n",
       "       [4.62431814e-07, 7.23887164e-14],\n",
       "       [5.21054826e-05, 9.19087972e-10],\n",
       "       [4.49507147e-01, 9.73431170e-02],\n",
       "       [9.11668831e-05, 2.81368662e-09],\n",
       "       [9.99962091e-01, 9.99850035e-01],\n",
       "       [9.97896552e-01, 9.91721094e-01],\n",
       "       [1.39066133e-05, 6.54669374e-11],\n",
       "       [4.72566634e-01, 1.09973967e-01],\n",
       "       [1.72947522e-03, 1.01368062e-06],\n",
       "       [3.28817987e-05, 3.66012526e-10],\n",
       "       [9.99999762e-01, 9.99998927e-01],\n",
       "       [5.82599205e-05, 1.14903131e-09],\n",
       "       [2.02518277e-05, 1.38838399e-10],\n",
       "       [8.30362842e-06, 2.33406836e-11],\n",
       "       [4.61002290e-01, 1.03505544e-01],\n",
       "       [6.88548025e-05, 1.60495761e-09],\n",
       "       [4.79465507e-06, 7.78200508e-12],\n",
       "       [6.78948283e-01, 2.83261925e-01],\n",
       "       [5.24716079e-01, 1.42748863e-01],\n",
       "       [5.14391741e-06, 8.95704518e-12],\n",
       "       [4.79861617e-01, 1.14197150e-01],\n",
       "       [1.10296401e-06, 4.11811346e-13],\n",
       "       [4.28171694e-01, 8.65827575e-02],\n",
       "       [9.99998689e-01, 9.99994874e-01],\n",
       "       [4.98469344e-05, 8.41136605e-10],\n",
       "       [4.15820003e-01, 8.07390735e-02],\n",
       "       [4.52398479e-01, 9.88685414e-02],\n",
       "       [2.87069797e-05, 2.78970708e-10],\n",
       "       [2.51654710e-05, 2.14384149e-10],\n",
       "       [3.81529510e-01, 6.59096390e-02],\n",
       "       [6.46527633e-02, 1.47819577e-03],\n",
       "       [2.39288261e-06, 1.93829024e-12],\n",
       "       [3.30850889e-05, 3.70552228e-10],\n",
       "       [4.51358616e-01, 9.83180329e-02],\n",
       "       [9.99646306e-01, 9.98602509e-01],\n",
       "       [9.99991655e-01, 9.99967098e-01],\n",
       "       [4.91340071e-01, 1.21072546e-01],\n",
       "       [9.99993086e-01, 9.99972582e-01],\n",
       "       [9.99999523e-01, 9.99998212e-01],\n",
       "       [4.97941256e-01, 1.25157297e-01],\n",
       "       [4.69149768e-01, 1.08034164e-01],\n",
       "       [9.99928117e-01, 9.99715984e-01],\n",
       "       [9.99972701e-01, 9.99892116e-01],\n",
       "       [4.51001585e-01, 9.81295258e-02],\n",
       "       [4.33214962e-01, 8.90488997e-02],\n",
       "       [9.62859858e-03, 3.15846773e-05],\n",
       "       [9.99941230e-01, 9.99767840e-01],\n",
       "       [9.76309657e-01, 9.11007226e-01],\n",
       "       [8.58149360e-05, 2.49302001e-09],\n",
       "       [3.91581823e-04, 5.19197592e-08],\n",
       "       [7.00082979e-04, 1.65987473e-07],\n",
       "       [9.65050640e-06, 3.15266840e-11],\n",
       "       [4.83848274e-01, 1.16552807e-01],\n",
       "       [9.99997020e-01, 9.99988079e-01],\n",
       "       [2.31073052e-01, 2.13360786e-02],\n",
       "       [9.99955416e-01, 9.99823809e-01],\n",
       "       [2.36927372e-04, 1.90052649e-08],\n",
       "       [4.44505483e-01, 9.47428122e-02],\n",
       "       [4.96782631e-01, 1.24433324e-01],\n",
       "       [9.99998450e-01, 9.99993682e-01],\n",
       "       [4.70513791e-01, 1.08805656e-01],\n",
       "       [5.29627898e-04, 9.49880459e-08],\n",
       "       [2.87443429e-01, 3.45358588e-02],\n",
       "       [2.30621104e-03, 1.80316931e-06],\n",
       "       [4.93160576e-01, 1.22189380e-01],\n",
       "       [1.07336846e-05, 3.90010316e-11],\n",
       "       [1.56868600e-06, 8.33005377e-13],\n",
       "       [4.54511076e-01, 9.99934822e-02],\n",
       "       [9.96866882e-01, 9.87696648e-01],\n",
       "       [9.99990582e-01, 9.99962687e-01],\n",
       "       [3.18510487e-04, 3.43490214e-08],\n",
       "       [1.30787726e-06, 5.79041426e-13],\n",
       "       [1.46196962e-05, 7.23529500e-11],\n",
       "       [5.40425062e-01, 1.53873011e-01],\n",
       "       [4.20086235e-01, 8.27263594e-02],\n",
       "       [9.99932051e-01, 9.99731481e-01],\n",
       "       [3.95439383e-05, 5.29354394e-10],\n",
       "       [3.23085260e-05, 3.53361285e-10],\n",
       "       [2.30066212e-06, 1.79176758e-12],\n",
       "       [9.96318102e-01, 9.85558808e-01],\n",
       "       [4.10158843e-01, 7.81518966e-02],\n",
       "       [4.40361381e-01, 9.26247910e-02],\n",
       "       [4.05881733e-01, 7.62344897e-02],\n",
       "       [1.04595547e-05, 3.70343478e-11],\n",
       "       [5.27923112e-06, 9.43448444e-12],\n",
       "       [7.75448084e-01, 4.17932540e-01],\n",
       "       [4.92871868e-06, 8.22327536e-12],\n",
       "       [2.49865971e-05, 2.11347287e-10],\n",
       "       [9.99994636e-01, 9.99978781e-01],\n",
       "       [1.46151186e-04, 7.23139371e-09],\n",
       "       [9.99459565e-01, 9.97865677e-01],\n",
       "       [4.35785741e-01, 9.03241858e-02],\n",
       "       [9.99994159e-01, 9.99976754e-01],\n",
       "       [8.19177421e-06, 2.27160912e-11],\n",
       "       [9.99987006e-01, 9.99948740e-01],\n",
       "       [5.33003331e-05, 9.61723923e-10],\n",
       "       [9.99981523e-01, 9.99926805e-01],\n",
       "       [4.99273986e-01, 1.25993773e-01],\n",
       "       [8.75494079e-05, 2.59481792e-09],\n",
       "       [3.78106833e-01, 6.45369515e-02],\n",
       "       [4.90947038e-01, 1.20832391e-01],\n",
       "       [2.75147818e-06, 2.56276207e-12],\n",
       "       [6.36158461e-07, 1.36995463e-13],\n",
       "       [3.97696704e-01, 7.26530477e-02],\n",
       "       [4.65353280e-01, 1.05907105e-01],\n",
       "       [1.57999311e-04, 8.45144754e-09],\n",
       "       [9.95886467e-07, 3.35733991e-13],\n",
       "       [1.48594963e-05, 7.47459664e-11],\n",
       "       [6.54574856e-03, 1.45672802e-05],\n",
       "       [4.43749368e-01, 9.43538994e-02],\n",
       "       [4.59354550e-01, 1.02606051e-01],\n",
       "       [9.99978781e-01, 9.99916077e-01],\n",
       "       [7.67559465e-03, 2.00451850e-05],\n",
       "       [9.75499279e-06, 3.22130621e-11],\n",
       "       [9.99980807e-01, 9.99924064e-01],\n",
       "       [4.39818710e-01, 9.23498869e-02],\n",
       "       [9.99987841e-01, 9.99951959e-01],\n",
       "       [4.62551361e-05, 7.24283467e-10],\n",
       "       [8.14590476e-06, 2.24624104e-11],\n",
       "       [3.22920948e-01, 4.48878445e-02],\n",
       "       [4.52471256e-01, 9.89071280e-02],\n",
       "       [2.25452686e-06, 1.72062722e-12],\n",
       "       [2.56127119e-02, 2.25895463e-04],\n",
       "       [1.08061307e-04, 3.95318178e-09],\n",
       "       [2.27538603e-05, 1.75263734e-10],\n",
       "       [5.39082757e-05, 9.83788384e-10],\n",
       "       [6.53211009e-06, 1.44438905e-11],\n",
       "       [9.99770939e-01, 9.99094725e-01],\n",
       "       [4.48283821e-01, 9.67026651e-02],\n",
       "       [2.01544585e-03, 1.37688289e-06],\n",
       "       [3.48923022e-05, 4.12139878e-10],\n",
       "       [3.01113892e-06, 3.06928896e-12],\n",
       "       [7.47225640e-05, 1.89016780e-09],\n",
       "       [4.41429377e-01, 9.31675211e-02],\n",
       "       [4.31823909e-01, 8.83639827e-02],\n",
       "       [1.95408031e-01, 1.48447072e-02],\n",
       "       [1.61082964e-04, 8.78457662e-09],\n",
       "       [6.31667441e-04, 1.35124353e-07],\n",
       "       [7.08924432e-04, 1.70207528e-07],\n",
       "       [9.99979138e-01, 9.99917388e-01],\n",
       "       [4.64558452e-01, 1.05465509e-01],\n",
       "       [3.30513794e-05, 3.69797498e-10],\n",
       "       [4.70942050e-01, 1.09048650e-01],\n",
       "       [6.52939343e-05, 1.44324408e-09],\n",
       "       [4.56384480e-01, 1.00998469e-01],\n",
       "       [5.31587377e-02, 9.91450623e-04],\n",
       "       [7.47944978e-06, 1.89372459e-11],\n",
       "       [1.32853596e-03, 5.98003510e-07],\n",
       "       [9.99999166e-01, 9.99996781e-01],\n",
       "       [1.12739190e-05, 4.30257462e-11],\n",
       "       [3.43139516e-04, 3.98671496e-08],\n",
       "       [9.99970078e-01, 9.99881625e-01],\n",
       "       [4.89105374e-01, 1.19711563e-01],\n",
       "       [2.79527921e-02, 2.69482873e-04],\n",
       "       [9.72444534e-01, 8.97330821e-01],\n",
       "       [9.88298689e-06, 3.30639439e-11],\n",
       "       [7.26213872e-01, 3.43573332e-01],\n",
       "       [4.86437559e-01, 1.18101105e-01],\n",
       "       [4.52074915e-01, 9.86970142e-02],\n",
       "       [9.99830008e-01, 9.99328315e-01],\n",
       "       [4.71280336e-01, 1.09240867e-01],\n",
       "       [5.05549550e-01, 1.29986703e-01],\n",
       "       [9.99863505e-01, 9.99460697e-01],\n",
       "       [4.45349753e-01, 9.51783359e-02],\n",
       "       [4.61611837e-01, 1.03839688e-01],\n",
       "       [4.24859524e-01, 8.49886239e-02],\n",
       "       [4.51009452e-01, 9.81336832e-02],\n",
       "       [5.71803093e-06, 1.10680215e-11],\n",
       "       [2.52216432e-05, 2.15342272e-10],\n",
       "       [2.30893711e-05, 1.80470472e-10],\n",
       "       [4.42318201e-01, 9.36208144e-02],\n",
       "       [2.19985736e-06, 1.63819273e-12],\n",
       "       [5.99288762e-01, 2.01425314e-01],\n",
       "       [4.12022561e-01, 7.89973959e-02],\n",
       "       [1.24889310e-03, 5.28426710e-07],\n",
       "       [4.25917983e-01, 8.54958817e-02],\n",
       "       [3.48387629e-01, 5.33907600e-02],\n",
       "       [2.98641294e-01, 3.76231931e-02],\n",
       "       [4.27923471e-01, 8.64626169e-02],\n",
       "       [7.75562694e-06, 2.03615770e-11],\n",
       "       [8.08690913e-07, 2.21381168e-13],\n",
       "       [3.08283393e-06, 3.21718845e-12],\n",
       "       [5.19851029e-01, 1.39426857e-01],\n",
       "       [4.45608437e-01, 9.53120515e-02],\n",
       "       [9.99968886e-01, 9.99876857e-01],\n",
       "       [1.16473675e-04, 4.59266092e-09],\n",
       "       [3.98050100e-01, 7.28053227e-02],\n",
       "       [4.85436797e-01, 1.17500953e-01],\n",
       "       [8.89384501e-06, 2.67766954e-11],\n",
       "       [4.39694524e-01, 9.22870412e-02],\n",
       "       [4.63604391e-01, 1.04937181e-01],\n",
       "       [4.54015076e-01, 9.97285917e-02],\n",
       "       [3.87806722e-06, 5.09104738e-12],\n",
       "       [5.05330863e-05, 8.64453065e-10],\n",
       "       [1.48856157e-06, 7.50083101e-13],\n",
       "       [4.21889544e-01, 8.35761800e-02],\n",
       "       [4.66518968e-01, 1.06557071e-01],\n",
       "       [6.89238141e-06, 1.60811069e-11],\n",
       "       [7.70258310e-04, 2.00941315e-07],\n",
       "       [5.59544098e-03, 1.06378639e-05],\n",
       "       [2.24170872e-05, 1.70114034e-10],\n",
       "       [1.48122963e-05, 7.42718734e-11],\n",
       "       [1.48576032e-06, 7.47262658e-13],\n",
       "       [3.62728679e-05, 4.45399273e-10],\n",
       "       [3.83181723e-05, 4.97045183e-10],\n",
       "       [9.99943495e-01, 9.99776602e-01],\n",
       "       [9.15585842e-05, 2.83791746e-09],\n",
       "       [2.49601385e-06, 2.10896817e-12],\n",
       "       [2.15307064e-05, 1.56927152e-10],\n",
       "       [4.18374257e-05, 5.92539406e-10],\n",
       "       [3.98328394e-01, 7.29253888e-02],\n",
       "       [4.66167718e-01, 1.06360912e-01],\n",
       "       [4.34518635e-01, 8.96940604e-02],\n",
       "       [5.68456562e-06, 1.09388462e-11],\n",
       "       [9.99990702e-01, 9.99963284e-01],\n",
       "       [4.72502325e-06, 7.55761165e-12],\n",
       "       [4.44867311e-07, 6.69940923e-14],\n",
       "       [1.32891553e-04, 5.97872107e-09],\n",
       "       [1.14334607e-03, 4.42852780e-07],\n",
       "       [8.62092316e-01, 5.85436821e-01],\n",
       "       [9.99701321e-01, 9.98819947e-01],\n",
       "       [4.95921761e-01, 1.23897351e-01],\n",
       "       [1.36254006e-03, 6.29021542e-07],\n",
       "       [4.45028752e-01, 9.50125754e-02],\n",
       "       [1.91604334e-03, 1.24433325e-06],\n",
       "       [9.99837756e-01, 9.99358714e-01],\n",
       "       [4.45059322e-06, 6.70521017e-12],\n",
       "       [9.99996185e-01, 9.99984860e-01],\n",
       "       [3.88146364e-05, 5.10008646e-10],\n",
       "       [4.54336494e-01, 9.99001861e-02],\n",
       "       [2.90034831e-01, 3.52359489e-02],\n",
       "       [4.59698617e-01, 1.02793433e-01],\n",
       "       [4.38957691e-01, 9.19148177e-02],\n",
       "       [3.27360570e-01, 4.63035032e-02],\n",
       "       [4.51064050e-01, 9.81624871e-02],\n",
       "       [6.05179775e-06, 1.23978362e-11],\n",
       "       [4.70841229e-01, 1.08991392e-01],\n",
       "       [1.76646631e-06, 1.05629817e-12],\n",
       "       [4.85251129e-01, 1.17389880e-01],\n",
       "       [4.64587003e-01, 1.05481364e-01],\n",
       "       [4.52025592e-01, 9.86708924e-02],\n",
       "       [1.83146985e-05, 1.13548178e-10],\n",
       "       [9.99978423e-01, 9.99914646e-01],\n",
       "       [4.60130304e-01, 1.03028841e-01],\n",
       "       [3.53252888e-01, 5.51229231e-02],\n",
       "       [4.59949881e-01, 1.02930404e-01],\n",
       "       [4.11041867e-04, 5.72091317e-08],\n",
       "       [1.79185517e-05, 1.08689176e-10],\n",
       "       [4.40053403e-01, 9.24687162e-02],\n",
       "       [1.84308603e-01, 1.30957821e-02],\n",
       "       [5.00078619e-01, 1.26500756e-01],\n",
       "       [4.73421037e-01, 1.10462815e-01],\n",
       "       [4.55107570e-01, 1.00312717e-01],\n",
       "       [1.88344973e-06, 1.20083674e-12],\n",
       "       [6.63240598e-06, 1.48908472e-11],\n",
       "       [9.99983430e-01, 9.99934316e-01],\n",
       "       [3.90652800e-03, 5.17941817e-06],\n",
       "       [4.37623084e-01, 9.12432596e-02],\n",
       "       [2.74113972e-05, 2.54358062e-10],\n",
       "       [2.95380528e-06, 2.95352024e-12],\n",
       "       [9.99977231e-01, 9.99910116e-01],\n",
       "       [9.98684824e-01, 9.94814873e-01],\n",
       "       [9.99997616e-01, 9.99990463e-01],\n",
       "       [4.60060745e-01, 1.02990903e-01],\n",
       "       [4.63427573e-01, 1.04839474e-01],\n",
       "       [9.99755085e-01, 9.99032199e-01],\n",
       "       [4.93673861e-01, 1.22505613e-01],\n",
       "       [4.66670930e-01, 1.06642008e-01],\n",
       "       [9.99999404e-01, 9.99997735e-01],\n",
       "       [9.99916792e-01, 9.99670923e-01],\n",
       "       [4.53879476e-01, 9.96562317e-02],\n",
       "       [9.99955893e-01, 9.99825597e-01],\n",
       "       [4.34198171e-01, 8.95351768e-02],\n",
       "       [6.50207454e-04, 1.43174532e-07],\n",
       "       [5.63423382e-03, 1.07861561e-05],\n",
       "       [4.47862612e-06, 6.78994447e-12],\n",
       "       [4.78791505e-01, 1.13570608e-01],\n",
       "       [9.99992490e-01, 9.99970317e-01],\n",
       "       [4.83898014e-01, 1.16582416e-01],\n",
       "       [4.45401579e-01, 9.52051058e-02],\n",
       "       [4.49693888e-01, 9.74411666e-02],\n",
       "       [9.20600772e-01, 7.33673453e-01],\n",
       "       [4.04981315e-01, 7.58348554e-02],\n",
       "       [9.99995112e-01, 9.99980569e-01],\n",
       "       [9.99973297e-01, 9.99894261e-01],\n",
       "       [5.60403278e-05, 1.06314557e-09],\n",
       "       [5.38354320e-03, 9.84602866e-06],\n",
       "       [4.41365749e-01, 9.31351185e-02],\n",
       "       [5.03480434e-01, 1.28660277e-01],\n",
       "       [4.85256970e-01, 1.17393360e-01],\n",
       "       [2.19552894e-05, 1.63177388e-10],\n",
       "       [4.13687994e-05, 5.79339354e-10],\n",
       "       [9.99987483e-01, 9.99950528e-01],\n",
       "       [4.51098979e-01, 9.81809348e-02],\n",
       "       [3.48990079e-06, 4.12289734e-12],\n",
       "       [9.99857903e-01, 9.99438286e-01],\n",
       "       [4.56452042e-01, 1.01034835e-01],\n",
       "       [6.04497135e-01, 2.06118211e-01],\n",
       "       [8.86244197e-06, 2.65879367e-11],\n",
       "       [3.51343066e-01, 5.44387586e-02],\n",
       "       [3.59330893e-01, 5.73369339e-02],\n",
       "       [7.48542288e-06, 1.89675029e-11],\n",
       "       [9.99989390e-01, 9.99958158e-01],\n",
       "       [9.99999881e-01, 9.99999523e-01],\n",
       "       [9.84469116e-01, 9.40632463e-01],\n",
       "       [2.02625688e-05, 1.38985712e-10],\n",
       "       [4.29350555e-01, 8.71550217e-02],\n",
       "       [4.51757103e-01, 9.85287353e-02],\n",
       "       [5.44080436e-01, 1.56550780e-01],\n",
       "       [5.00039756e-01, 1.26476243e-01],\n",
       "       [1.05095478e-05, 3.73892237e-11],\n",
       "       [4.61662710e-01, 1.03867605e-01],\n",
       "       [4.14361566e-05, 5.81227455e-10],\n",
       "       [4.66682047e-01, 1.06648237e-01],\n",
       "       [5.36569834e-01, 1.51085809e-01],\n",
       "       [4.51034486e-01, 9.81468782e-02],\n",
       "       [8.80913064e-03, 2.64228438e-05],\n",
       "       [4.57726061e-01, 1.01722419e-01],\n",
       "       [1.26845247e-04, 5.44703482e-09],\n",
       "       [9.99980092e-01, 9.99921322e-01],\n",
       "       [8.29103101e-06, 2.32699172e-11],\n",
       "       [4.97290939e-01, 1.24750569e-01],\n",
       "       [5.02274275e-01, 1.27891600e-01],\n",
       "       [2.69771990e-05, 2.46363763e-10],\n",
       "       [9.63014713e-07, 3.13936241e-13],\n",
       "       [4.12728339e-01, 7.93191716e-02],\n",
       "       [9.99983430e-01, 9.99934554e-01],\n",
       "       [1.20784371e-05, 4.93855928e-11],\n",
       "       [9.99675274e-01, 9.98716950e-01],\n",
       "       [3.75121817e-05, 4.76355067e-10],\n",
       "       [9.99999404e-01, 9.99997735e-01],\n",
       "       [4.32237923e-01, 8.85674432e-02],\n",
       "       [4.52515930e-01, 9.89308506e-02],\n",
       "       [4.11904424e-01, 7.89436176e-02],\n",
       "       [3.67574543e-01, 6.04301952e-02],\n",
       "       [4.41245317e-01, 9.30738151e-02],\n",
       "       [4.49523658e-01, 9.73518044e-02],\n",
       "       [5.55429161e-01, 1.65085837e-01],\n",
       "       [2.95081172e-05, 2.94758801e-10],\n",
       "       [6.86845124e-06, 1.59696336e-11],\n",
       "       [7.34590692e-03, 1.83561515e-05],\n",
       "       [4.16776538e-01, 8.11818242e-02],\n",
       "       [4.42866027e-01, 9.39009637e-02],\n",
       "       [2.96718781e-06, 2.98034340e-12],\n",
       "       [4.82330769e-01, 1.15652144e-01],\n",
       "       [4.36797380e-01, 9.08294395e-02],\n",
       "       [1.60872114e-05, 8.76075393e-11],\n",
       "       [4.12786118e-04, 5.76957575e-08],\n",
       "       [5.29818280e-05, 9.50264312e-10],\n",
       "       [9.99995112e-01, 9.99980688e-01],\n",
       "       [4.81362283e-01, 1.15079872e-01],\n",
       "       [6.71417092e-06, 1.52602635e-11],\n",
       "       [7.70486949e-05, 2.00968531e-09],\n",
       "       [9.07220354e-04, 2.78779822e-07],\n",
       "       [3.72858584e-01, 6.24685995e-02],\n",
       "       [9.45978343e-07, 3.02927036e-13],\n",
       "       [6.96902589e-06, 1.64407446e-11],\n",
       "       [3.99472956e-05, 5.40208767e-10],\n",
       "       [5.55338693e-06, 1.04398148e-11],\n",
       "       [4.86215889e-01, 1.17967993e-01],\n",
       "       [7.35584308e-06, 1.83164924e-11],\n",
       "       [5.65932540e-04, 1.08459375e-07],\n",
       "       [9.99424815e-01, 9.97728467e-01],\n",
       "       [2.32072502e-01, 2.15378571e-02],\n",
       "       [4.83633399e-01, 1.16424970e-01],\n",
       "       [3.86381924e-01, 6.78882822e-02],\n",
       "       [9.99927640e-01, 9.99713838e-01],\n",
       "       [4.60805893e-01, 1.03398040e-01],\n",
       "       [1.45680615e-05, 7.18427748e-11],\n",
       "       [1.73202261e-05, 1.01551753e-10],\n",
       "       [4.58718538e-01, 1.02260329e-01],\n",
       "       [4.60894495e-01, 1.03446543e-01],\n",
       "       [4.26496148e-01, 8.57738182e-02],\n",
       "       [1.00000000e+00, 1.00000000e+00],\n",
       "       [4.81837511e-01, 1.15360424e-01],\n",
       "       [9.99988198e-01, 9.99953270e-01],\n",
       "       [4.65773046e-01, 1.06140845e-01],\n",
       "       [1.80485398e-02, 1.11602953e-04],\n",
       "       [4.54041839e-01, 9.97428522e-02],\n",
       "       [4.32218224e-01, 8.85577500e-02],\n",
       "       [9.99923825e-01, 9.99699056e-01],\n",
       "       [4.27154124e-01, 8.60908777e-02],\n",
       "       [8.75208378e-02, 2.75231781e-03],\n",
       "       [1.48805080e-03, 7.50306242e-07],\n",
       "       [4.43171531e-01, 9.40574408e-02],\n",
       "       [3.76842848e-07, 4.80724232e-14],\n",
       "       [5.10834992e-01, 1.33419722e-01],\n",
       "       [9.99877214e-01, 9.99514520e-01],\n",
       "       [4.09363389e-01, 7.77928829e-02],\n",
       "       [4.81095165e-01, 1.14922412e-01],\n",
       "       [1.40054199e-05, 6.64005448e-11],\n",
       "       [9.71825830e-06, 3.19709086e-11],\n",
       "       [5.04552736e-06, 8.61767168e-12],\n",
       "       [4.88651454e-01, 1.19436443e-01],\n",
       "       [9.99910951e-01, 9.99647796e-01],\n",
       "       [6.85395644e-05, 1.59029512e-09],\n",
       "       [1.02688114e-06, 3.56957058e-13],\n",
       "       [4.40234840e-01, 9.25606415e-02],\n",
       "       [3.99694383e-01, 7.35165998e-02],\n",
       "       [2.65797571e-04, 2.39195934e-08],\n",
       "       [1.20310506e-04, 4.90023577e-09],\n",
       "       [4.20688897e-01, 8.30097049e-02],\n",
       "       [4.87746183e-06, 8.05312501e-12],\n",
       "       [9.99493599e-01, 9.98000085e-01],\n",
       "       [4.69450444e-01, 1.08203888e-01],\n",
       "       [5.23690104e-01, 1.42043531e-01],\n",
       "       [1.06348110e-04, 3.82882437e-09],\n",
       "       [2.35436950e-02, 1.90608131e-04],\n",
       "       [4.91722226e-01, 1.21306375e-01],\n",
       "       [5.07333696e-01, 1.31138310e-01],\n",
       "       [9.99997258e-01, 9.99989033e-01],\n",
       "       [9.99850631e-01, 9.99409795e-01]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67942887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40af0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.94      0.57       160\n",
      "           1       0.36      0.04      0.08       189\n",
      "           2       0.66      0.45      0.54       122\n",
      "\n",
      "    accuracy                           0.45       471\n",
      "   macro avg       0.48      0.48      0.40       471\n",
      "weighted avg       0.46      0.45      0.36       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6773)\n",
      "tensor(0.9406)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f16cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca61759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.7, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca7af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       342\n",
      "           1       0.20      0.02      0.03        62\n",
      "           2       0.33      0.78      0.46        67\n",
      "\n",
      "    accuracy                           0.69       471\n",
      "   macro avg       0.47      0.53      0.45       471\n",
      "weighted avg       0.72      0.69      0.68       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e469c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4735)\n",
      "tensor(0.8089)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9ad4c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66073d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[9.95555747e-05, 3.75124291e-05],\n",
       "       [1.90776882e-05, 7.18809815e-06],\n",
       "       [4.26126033e-01, 2.18610957e-01],\n",
       "       [1.54090267e-05, 5.80580036e-06],\n",
       "       [4.43542629e-01, 2.30959401e-01],\n",
       "       [4.85832632e-01, 2.62543648e-01],\n",
       "       [5.36891021e-05, 2.02294377e-05],\n",
       "       [5.09416386e-05, 1.91941908e-05],\n",
       "       [1.41160726e-05, 5.31863770e-06],\n",
       "       [7.37917617e-06, 2.78030598e-06],\n",
       "       [4.76031780e-01, 2.55013168e-01],\n",
       "       [6.24308495e-06, 2.35225093e-06],\n",
       "       [1.23269429e-05, 4.64452569e-06],\n",
       "       [4.51042235e-01, 2.36391559e-01],\n",
       "       [4.45150799e-05, 1.67726739e-05],\n",
       "       [6.73745490e-06, 2.53851863e-06],\n",
       "       [4.78512853e-01, 2.56907135e-01],\n",
       "       [2.71430588e-04, 1.02285703e-04],\n",
       "       [5.93937980e-03, 2.24612933e-03],\n",
       "       [4.83804179e-05, 1.82291060e-05],\n",
       "       [1.14722243e-05, 4.32248407e-06],\n",
       "       [1.10954734e-05, 4.18053560e-06],\n",
       "       [9.99904394e-01, 9.99746144e-01],\n",
       "       [2.32294424e-05, 8.75241130e-06],\n",
       "       [1.62869003e-02, 6.19943859e-03],\n",
       "       [9.62229296e-06, 3.62546984e-06],\n",
       "       [2.35431045e-01, 1.03958115e-01],\n",
       "       [5.51715136e-01, 3.16803277e-01],\n",
       "       [1.23942518e-05, 4.66988649e-06],\n",
       "       [4.07451615e-02, 1.57517772e-02],\n",
       "       [4.42693412e-01, 2.30348736e-01],\n",
       "       [1.08170963e-03, 4.07836837e-04],\n",
       "       [5.47421814e-06, 2.06256050e-06],\n",
       "       [1.22197368e-03, 4.60761104e-04],\n",
       "       [6.39658756e-05, 2.41017369e-05],\n",
       "       [1.25678371e-05, 4.73529508e-06],\n",
       "       [9.99880314e-01, 9.99682546e-01],\n",
       "       [2.72748340e-03, 1.02939981e-03],\n",
       "       [1.43525367e-05, 5.40773362e-06],\n",
       "       [1.15586072e-05, 4.35503125e-06],\n",
       "       [1.08809509e-04, 4.09995409e-05],\n",
       "       [6.10807474e-05, 2.30146288e-05],\n",
       "       [4.35249239e-01, 2.25033447e-01],\n",
       "       [4.56413036e-05, 1.71970332e-05],\n",
       "       [4.11365569e-01, 2.08427861e-01],\n",
       "       [5.58990041e-06, 2.10614508e-06],\n",
       "       [5.60627460e-01, 3.24669152e-01],\n",
       "       [8.30146484e-03, 3.14405677e-03],\n",
       "       [4.26402294e-05, 1.60662366e-05],\n",
       "       [9.99932528e-01, 9.99821126e-01],\n",
       "       [4.13400710e-01, 2.09816873e-01],\n",
       "       [1.49963613e-04, 5.65078990e-05],\n",
       "       [4.62326898e-05, 1.74198467e-05],\n",
       "       [5.48559474e-04, 2.06754572e-04],\n",
       "       [1.25929089e-02, 4.78223432e-03],\n",
       "       [4.35033172e-01, 2.24880219e-01],\n",
       "       [8.14615305e-06, 3.06928678e-06],\n",
       "       [2.38494843e-01, 1.05547160e-01],\n",
       "       [2.89829586e-06, 1.09200880e-06],\n",
       "       [7.68991777e-06, 2.89738682e-06],\n",
       "       [6.98136455e-06, 2.63041875e-06],\n",
       "       [2.86067370e-05, 1.07785208e-05],\n",
       "       [6.92954700e-06, 2.61089735e-06],\n",
       "       [1.26335712e-03, 4.76377405e-04],\n",
       "       [8.63575190e-03, 3.27134808e-03],\n",
       "       [4.16346711e-06, 1.56869805e-06],\n",
       "       [1.24288752e-04, 4.68326325e-05],\n",
       "       [9.99955416e-01, 9.99881625e-01],\n",
       "       [1.85868657e-06, 7.00308362e-07],\n",
       "       [4.55023535e-03, 1.71929458e-03],\n",
       "       [5.89149931e-06, 2.21978098e-06],\n",
       "       [2.18142050e-05, 8.21917092e-06],\n",
       "       [5.62247078e-06, 2.11841689e-06],\n",
       "       [2.36396445e-04, 8.90816082e-05],\n",
       "       [2.09166064e-05, 7.88096804e-06],\n",
       "       [9.74311115e-06, 3.67098778e-06],\n",
       "       [2.73951940e-04, 1.03236111e-04],\n",
       "       [4.69005406e-01, 2.49694422e-01],\n",
       "       [4.44144547e-01, 2.31392816e-01],\n",
       "       [4.79001194e-01, 2.57280916e-01],\n",
       "       [1.16968840e-05, 4.40713166e-06],\n",
       "       [1.46506381e-05, 5.52005758e-06],\n",
       "       [9.99852896e-01, 9.99609649e-01],\n",
       "       [5.59670552e-05, 2.10877515e-05],\n",
       "       [4.17964548e-01, 2.12949127e-01],\n",
       "       [6.23270898e-05, 2.34842355e-05],\n",
       "       [8.17416367e-05, 3.07998198e-05],\n",
       "       [1.17286050e-04, 4.41937445e-05],\n",
       "       [1.90553412e-01, 8.14712346e-02],\n",
       "       [4.39977258e-01, 2.28401452e-01],\n",
       "       [5.87610248e-06, 2.21398182e-06],\n",
       "       [3.51609639e-03, 1.32768916e-03],\n",
       "       [4.90597904e-01, 2.66252875e-01],\n",
       "       [4.56508279e-01, 2.40395457e-01],\n",
       "       [9.99904156e-01, 9.99745548e-01],\n",
       "       [2.35799421e-02, 9.01686121e-03],\n",
       "       [9.99666929e-01, 9.99116480e-01],\n",
       "       [9.99932051e-01, 9.99819577e-01],\n",
       "       [4.93578821e-01, 2.68589437e-01],\n",
       "       [7.99197033e-02, 3.16902325e-02],\n",
       "       [4.90796089e-01, 2.66407877e-01],\n",
       "       [4.46780503e-01, 2.33296096e-01],\n",
       "       [2.04736298e-05, 7.71406758e-06],\n",
       "       [5.04351192e-06, 1.90027947e-06],\n",
       "       [1.44684709e-05, 5.45141575e-06],\n",
       "       [3.80845159e-01, 1.88151300e-01],\n",
       "       [4.23969150e-01, 2.17107043e-01],\n",
       "       [8.40778754e-04, 3.16951075e-04],\n",
       "       [8.01080932e-06, 3.01829505e-06],\n",
       "       [4.46523100e-01, 2.33109817e-01],\n",
       "       [7.26158714e-06, 2.73600358e-06],\n",
       "       [8.10644488e-05, 3.05446410e-05],\n",
       "       [4.33213741e-01, 2.23591849e-01],\n",
       "       [4.47263181e-01, 2.33645529e-01],\n",
       "       [2.88464618e-03, 1.08882203e-03],\n",
       "       [7.66853409e-05, 2.88945412e-05],\n",
       "       [2.03749169e-05, 7.67687470e-06],\n",
       "       [5.34789870e-05, 2.01502644e-05],\n",
       "       [9.99627948e-01, 9.99013186e-01],\n",
       "       [4.26836967e-01, 2.19107822e-01],\n",
       "       [6.13161319e-06, 2.31025069e-06],\n",
       "       [1.30784510e-05, 4.92768004e-06],\n",
       "       [3.37689635e-05, 1.27235990e-05],\n",
       "       [4.92303483e-02, 1.91359222e-02],\n",
       "       [5.00303795e-05, 1.88508275e-05],\n",
       "       [7.17336161e-06, 2.70276178e-06],\n",
       "       [2.94557842e-03, 1.11186411e-03],\n",
       "       [4.77178007e-01, 2.55887091e-01],\n",
       "       [9.99875307e-01, 9.99669313e-01],\n",
       "       [1.48718445e-05, 5.60340368e-06],\n",
       "       [4.46479635e-06, 1.68223062e-06],\n",
       "       [4.65939229e-06, 1.75555169e-06],\n",
       "       [4.56940174e-01, 2.40713462e-01],\n",
       "       [1.59534993e-05, 6.01094780e-06],\n",
       "       [9.99155521e-01, 9.97761607e-01],\n",
       "       [2.34522730e-01, 1.03488356e-01],\n",
       "       [1.23228519e-05, 4.64298455e-06],\n",
       "       [9.16825593e-06, 3.45439730e-06],\n",
       "       [4.44926977e-01, 2.31956840e-01],\n",
       "       [2.01039352e-02, 7.67078716e-03],\n",
       "       [2.53462046e-01, 1.13413587e-01],\n",
       "       [4.88387614e-01, 2.64528453e-01],\n",
       "       [1.81589930e-05, 6.84194811e-06],\n",
       "       [8.02587419e-06, 3.02396825e-06],\n",
       "       [4.85387981e-01, 2.62199134e-01],\n",
       "       [2.34264135e-05, 8.82662789e-06],\n",
       "       [2.82479188e-04, 1.06449974e-04],\n",
       "       [9.99610126e-01, 9.98965979e-01],\n",
       "       [3.97473620e-03, 1.50130375e-03],\n",
       "       [9.99874353e-01, 9.99666572e-01],\n",
       "       [8.63913228e-05, 3.25518922e-05],\n",
       "       [1.69948973e-02, 6.47181505e-03],\n",
       "       [6.05471314e-06, 2.28127851e-06],\n",
       "       [8.73041154e-06, 3.28942679e-06],\n",
       "       [1.64233115e-05, 6.18797185e-06],\n",
       "       [1.11245050e-03, 4.19435120e-04],\n",
       "       [3.84281611e-06, 1.44788260e-06],\n",
       "       [1.15572839e-05, 4.35453694e-06],\n",
       "       [3.74511146e-04, 1.41139637e-04],\n",
       "       [1.81649157e-05, 6.84418046e-06],\n",
       "       [1.04740575e-05, 3.94639846e-06],\n",
       "       [9.00261330e-06, 3.39198687e-06],\n",
       "       [1.09051998e-05, 4.10884422e-06],\n",
       "       [1.87738871e-04, 7.07437575e-05],\n",
       "       [2.37020049e-05, 8.93047672e-06],\n",
       "       [3.84515588e-05, 1.44879541e-05],\n",
       "       [2.50320300e-05, 9.43160376e-06],\n",
       "       [9.40493483e-05, 3.54376025e-05],\n",
       "       [5.05993128e-01, 2.78456390e-01],\n",
       "       [1.00122215e-05, 3.77238371e-06],\n",
       "       [9.99510646e-01, 9.98702407e-01],\n",
       "       [1.21861658e-05, 4.59148850e-06],\n",
       "       [5.51818403e-06, 2.07912376e-06],\n",
       "       [4.81466830e-01, 2.59172916e-01],\n",
       "       [9.99898434e-01, 9.99730408e-01],\n",
       "       [9.99840736e-01, 9.99577582e-01],\n",
       "       [3.86242900e-05, 1.45530366e-05],\n",
       "       [6.04028310e-06, 2.27583951e-06],\n",
       "       [4.42402035e-01, 2.30139434e-01],\n",
       "       [4.43094581e-01, 2.30637103e-01],\n",
       "       [3.87175942e-06, 1.45878766e-06],\n",
       "       [1.75603400e-05, 6.61637887e-06],\n",
       "       [6.76825039e-06, 2.55012424e-06],\n",
       "       [1.10772044e-05, 4.17364799e-06],\n",
       "       [4.53029573e-01, 2.37842903e-01],\n",
       "       [6.78134074e-06, 2.55505392e-06],\n",
       "       [9.99773204e-01, 9.99398112e-01],\n",
       "       [4.26965833e-01, 2.19197974e-01],\n",
       "       [2.19033379e-03, 8.26393021e-04],\n",
       "       [8.99168117e-06, 3.38786822e-06],\n",
       "       [2.49658274e-06, 9.40652683e-07],\n",
       "       [1.34003949e-05, 5.04898298e-06],\n",
       "       [9.09069877e-06, 3.42517228e-06],\n",
       "       [1.48316476e-05, 5.58825377e-06],\n",
       "       [4.51687664e-01, 2.36862376e-01],\n",
       "       [4.84608572e-05, 1.82594322e-05],\n",
       "       [4.95284348e-06, 1.86611771e-06],\n",
       "       [2.32969847e-04, 8.77901766e-05],\n",
       "       [3.11311036e-01, 1.45529613e-01],\n",
       "       [3.00808279e-05, 1.13339320e-05],\n",
       "       [1.88158512e-01, 8.03112686e-02],\n",
       "       [9.99569356e-01, 9.98857975e-01],\n",
       "       [4.47332131e-05, 1.68548668e-05],\n",
       "       [1.42122532e-04, 5.35530344e-05],\n",
       "       [7.62034906e-05, 2.87129715e-05],\n",
       "       [4.77325375e-06, 1.79845222e-06],\n",
       "       [9.59324825e-05, 3.61471757e-05],\n",
       "       [5.28969646e-01, 2.97319174e-01],\n",
       "       [7.92217907e-06, 2.98490090e-06],\n",
       "       [5.80064661e-05, 2.18562272e-05],\n",
       "       [9.72013877e-05, 3.66253553e-05],\n",
       "       [4.32151645e-01, 2.22841620e-01],\n",
       "       [4.17175740e-01, 2.12406024e-01],\n",
       "       [5.03750741e-01, 2.76657641e-01],\n",
       "       [2.01995172e-05, 7.61077990e-06],\n",
       "       [9.98906255e-01, 9.97102320e-01],\n",
       "       [5.06621838e-01, 2.78962016e-01],\n",
       "       [1.04845343e-02, 3.97629989e-03],\n",
       "       [9.99799907e-01, 9.99468982e-01],\n",
       "       [4.12210829e-05, 1.55315083e-05],\n",
       "       [9.79238093e-01, 9.46725607e-01],\n",
       "       [4.35808241e-01, 2.25430265e-01],\n",
       "       [4.02578086e-01, 2.02484250e-01],\n",
       "       [5.05249845e-05, 1.90371957e-05],\n",
       "       [4.48649943e-01, 2.34651163e-01],\n",
       "       [1.83155723e-02, 6.98054349e-03],\n",
       "       [2.17883417e-06, 8.20932542e-07],\n",
       "       [5.96250356e-06, 2.24653400e-06],\n",
       "       [7.02923853e-06, 2.64845676e-06],\n",
       "       [3.58897728e-06, 1.35224184e-06],\n",
       "       [4.49245036e-01, 2.35083371e-01],\n",
       "       [9.99685407e-01, 9.99165535e-01],\n",
       "       [9.96917606e-06, 3.75616878e-06],\n",
       "       [4.44307357e-01, 2.31510118e-01],\n",
       "       [4.74798024e-01, 2.54074454e-01],\n",
       "       [1.70775002e-05, 6.43445856e-06],\n",
       "       [2.44206720e-04, 9.20251259e-05],\n",
       "       [3.24626424e-04, 1.22336045e-04],\n",
       "       [4.41232532e-06, 1.66246082e-06],\n",
       "       [1.05697654e-05, 3.98245902e-06],\n",
       "       [1.98477865e-05, 7.47825152e-06],\n",
       "       [9.99915719e-01, 9.99776304e-01],\n",
       "       [2.09256650e-05, 7.88438865e-06],\n",
       "       [4.76653039e-01, 2.55486637e-01],\n",
       "       [8.80113002e-05, 3.31623523e-05],\n",
       "       [1.37820651e-04, 5.19319547e-05],\n",
       "       [4.98802274e-01, 2.72714049e-01],\n",
       "       [1.30956232e-05, 4.93415519e-06],\n",
       "       [1.82513803e-01, 7.75927231e-02],\n",
       "       [4.51584190e-01, 2.36786857e-01],\n",
       "       [1.03958072e-02, 3.94243235e-03],\n",
       "       [7.04002650e-06, 2.65252129e-06],\n",
       "       [4.55495030e-01, 2.39650413e-01],\n",
       "       [9.07540198e-06, 3.41941177e-06],\n",
       "       [9.99759614e-01, 9.99362171e-01],\n",
       "       [8.47363408e-05, 3.19282663e-05],\n",
       "       [6.92015556e-06, 2.60735646e-06],\n",
       "       [4.95867462e-05, 1.86836478e-05],\n",
       "       [9.10567451e-06, 3.43081820e-06],\n",
       "       [4.98675287e-01, 2.72613347e-01],\n",
       "       [5.94186440e-06, 2.23875759e-06],\n",
       "       [4.12962527e-06, 1.55594728e-06],\n",
       "       [1.42827666e-05, 5.38144423e-06],\n",
       "       [2.60966754e-05, 9.83274731e-06],\n",
       "       [4.83293265e-01, 2.60579854e-01],\n",
       "       [3.16446930e-01, 1.48520336e-01],\n",
       "       [1.15873681e-05, 4.36586788e-06],\n",
       "       [1.33570458e-04, 5.03303236e-05],\n",
       "       [7.55344672e-06, 2.84597013e-06],\n",
       "       [3.02182976e-04, 1.13876595e-04],\n",
       "       [4.52095363e-03, 1.70819834e-03],\n",
       "       [9.99402165e-01, 9.98414874e-01],\n",
       "       [3.17680569e-05, 1.19696742e-05],\n",
       "       [4.33615409e-03, 1.63818453e-03],\n",
       "       [6.49848243e-06, 2.44848138e-06],\n",
       "       [5.21041193e-06, 1.96316205e-06],\n",
       "       [5.64852147e-04, 2.12897488e-04],\n",
       "       [1.80353527e-05, 6.79536242e-06],\n",
       "       [4.92035210e-01, 2.67377973e-01],\n",
       "       [4.04609746e-04, 1.52485562e-04],\n",
       "       [9.99697089e-01, 9.99196470e-01],\n",
       "       [2.04202230e-03, 7.70365121e-04],\n",
       "       [4.88770101e-03, 1.84719474e-03],\n",
       "       [1.32356927e-05, 4.98692589e-06],\n",
       "       [5.49828587e-03, 2.07874458e-03],\n",
       "       [4.25537701e-06, 1.60332615e-06],\n",
       "       [4.14942592e-01, 2.10872427e-01],\n",
       "       [2.75894708e-05, 1.03952152e-05],\n",
       "       [4.12197232e-01, 2.08994925e-01],\n",
       "       [4.73411322e-01, 2.53021866e-01],\n",
       "       [4.19007629e-01, 2.13668361e-01],\n",
       "       [6.46684784e-04, 2.43753340e-04],\n",
       "       [5.08865778e-05, 1.91734453e-05],\n",
       "       [3.14653444e-05, 1.18556136e-05],\n",
       "       [3.55263725e-02, 1.36885503e-02],\n",
       "       [4.31377500e-01, 2.22295627e-01],\n",
       "       [7.92217068e-03, 2.99969339e-03],\n",
       "       [9.99601662e-01, 9.98943388e-01],\n",
       "       [3.92121039e-02, 1.51442643e-02],\n",
       "       [2.70396049e-05, 1.01880332e-05],\n",
       "       [2.73834430e-05, 1.03175862e-05],\n",
       "       [1.65132515e-04, 6.22242951e-05],\n",
       "       [3.79352772e-04, 1.42964695e-04],\n",
       "       [7.99469126e-06, 3.01221894e-06],\n",
       "       [4.30064261e-01, 2.21371144e-01],\n",
       "       [1.76807553e-05, 6.66175583e-06],\n",
       "       [7.31364298e-06, 2.75561683e-06],\n",
       "       [2.89646996e-05, 1.09133871e-05],\n",
       "       [1.87918831e-05, 7.08040488e-06],\n",
       "       [4.47151572e-01, 2.33564675e-01],\n",
       "       [9.99901652e-01, 9.99739110e-01],\n",
       "       [5.00606402e-05, 1.88622271e-05],\n",
       "       [8.49946446e-06, 3.20241020e-06],\n",
       "       [6.65064681e-06, 2.50581388e-06],\n",
       "       [9.99926448e-01, 9.99804676e-01],\n",
       "       [1.30952485e-05, 4.93401421e-06],\n",
       "       [3.45106363e-01, 1.65656999e-01],\n",
       "       [7.52144524e-06, 2.83391228e-06],\n",
       "       [8.85684040e-06, 3.33706225e-06],\n",
       "       [9.97171223e-01, 9.92526889e-01],\n",
       "       [4.43696231e-01, 2.31069997e-01],\n",
       "       [9.99859929e-01, 9.99628425e-01],\n",
       "       [1.57554809e-03, 5.94212033e-04],\n",
       "       [2.61020556e-04, 9.83622376e-05],\n",
       "       [1.24126498e-04, 4.67714854e-05],\n",
       "       [9.36284050e-06, 3.52770985e-06],\n",
       "       [2.45945557e-05, 9.26677785e-06],\n",
       "       [9.99832630e-01, 9.99556005e-01],\n",
       "       [9.99888778e-01, 9.99704897e-01],\n",
       "       [1.09567911e-04, 4.12853660e-05],\n",
       "       [4.35420066e-01, 2.25154743e-01],\n",
       "       [1.89224756e-05, 7.12961082e-06],\n",
       "       [1.27393575e-02, 4.83829621e-03],\n",
       "       [4.32241112e-01, 2.22904772e-01],\n",
       "       [3.19364494e-06, 1.20328957e-06],\n",
       "       [3.30468616e-03, 1.24769576e-03],\n",
       "       [4.70909953e-01, 2.51129597e-01],\n",
       "       [4.37065244e-01, 2.26323888e-01],\n",
       "       [9.99592006e-01, 9.98917937e-01],\n",
       "       [4.20527458e-01, 2.14718655e-01],\n",
       "       [6.54848525e-04, 2.46831769e-04],\n",
       "       [5.04983564e-06, 1.90266223e-06],\n",
       "       [9.99854445e-01, 9.99613822e-01],\n",
       "       [4.31347847e-01, 2.22274750e-01],\n",
       "       [4.70690995e-01, 2.50964433e-01],\n",
       "       [2.18867240e-06, 8.24639301e-07],\n",
       "       [1.05990166e-05, 3.99347709e-06],\n",
       "       [6.46496665e-06, 2.43585328e-06],\n",
       "       [4.35084194e-01, 2.24916443e-01],\n",
       "       [1.23340906e-05, 4.64721961e-06],\n",
       "       [2.11869883e-05, 7.98284418e-06],\n",
       "       [4.99647737e-01, 2.73385346e-01],\n",
       "       [4.70259517e-01, 2.50638932e-01],\n",
       "       [1.70012554e-05, 6.40573126e-06],\n",
       "       [6.66575725e-05, 2.51159854e-05],\n",
       "       [4.43330828e-05, 1.67040962e-05],\n",
       "       [2.92552413e-05, 1.10228593e-05],\n",
       "       [1.51793693e-05, 5.71926921e-06],\n",
       "       [5.18126860e-02, 2.01731753e-02],\n",
       "       [4.11996573e-01, 2.08858043e-01],\n",
       "       [3.13292571e-06, 1.18041203e-06],\n",
       "       [7.06535684e-06, 2.66206484e-06],\n",
       "       [9.99661803e-01, 9.99102831e-01],\n",
       "       [2.16686912e-03, 8.17527645e-04],\n",
       "       [2.47707176e-05, 9.33315368e-06],\n",
       "       [9.99608099e-01, 9.98960376e-01],\n",
       "       [4.18366402e-01, 2.13226050e-01],\n",
       "       [7.00685719e-04, 2.64116708e-04],\n",
       "       [4.34297532e-01, 2.24358827e-01],\n",
       "       [3.43251327e-06, 1.29329101e-06],\n",
       "       [4.03717240e-06, 1.52111147e-06],\n",
       "       [1.96777492e-05, 7.41418489e-06],\n",
       "       [9.99902248e-01, 9.99740779e-01],\n",
       "       [4.56937879e-01, 2.40711778e-01],\n",
       "       [1.44196820e-05, 5.43303713e-06],\n",
       "       [1.66893855e-03, 6.29470509e-04],\n",
       "       [2.76128994e-03, 1.04218046e-03],\n",
       "       [9.11987536e-06, 3.43616853e-06],\n",
       "       [9.99904871e-01, 9.99747574e-01],\n",
       "       [2.50957037e-05, 9.45559532e-06],\n",
       "       [1.39137998e-01, 5.74013330e-02],\n",
       "       [6.66884996e-04, 2.51370540e-04],\n",
       "       [1.42152348e-04, 5.35643230e-05],\n",
       "       [8.99790939e-06, 3.39021449e-06],\n",
       "       [3.35542828e-01, 1.59852520e-01],\n",
       "       [9.97528136e-01, 9.93466079e-01],\n",
       "       [1.78008086e-05, 6.70699046e-06],\n",
       "       [4.68545586e-01, 2.49348670e-01],\n",
       "       [1.33059330e-05, 5.01339082e-06],\n",
       "       [1.35352011e-05, 5.09977599e-06],\n",
       "       [1.00241647e-04, 3.77709584e-05],\n",
       "       [6.36448618e-04, 2.39893547e-04],\n",
       "       [5.57501480e-05, 2.10060425e-05],\n",
       "       [9.30609986e-06, 3.50633059e-06],\n",
       "       [4.47702587e-01, 2.33963922e-01],\n",
       "       [9.98819768e-01, 9.96873736e-01],\n",
       "       [4.76782531e-01, 2.55585372e-01],\n",
       "       [2.36872274e-05, 8.92490061e-06],\n",
       "       [3.59894443e-06, 1.35599726e-06],\n",
       "       [2.40319350e-04, 9.05600900e-05],\n",
       "       [9.99907017e-01, 9.99753296e-01],\n",
       "       [1.08165586e-05, 4.07544621e-06],\n",
       "       [1.99859078e-05, 7.53029417e-06],\n",
       "       [5.88899411e-06, 2.21883920e-06],\n",
       "       [4.20734286e-01, 2.14861810e-01],\n",
       "       [1.07592541e-05, 4.05385481e-06],\n",
       "       [1.25353508e-05, 4.72305464e-06],\n",
       "       [8.80197331e-06, 3.31638626e-06],\n",
       "       [4.82287288e-01, 2.59804398e-01],\n",
       "       [3.05375773e-02, 1.17290476e-02],\n",
       "       [6.37490666e-06, 2.40191844e-06],\n",
       "       [3.79149133e-05, 1.42857498e-05],\n",
       "       [1.06561383e-05, 4.01499938e-06],\n",
       "       [6.69913692e-03, 2.53465539e-03],\n",
       "       [1.25146616e-05, 4.71525482e-06],\n",
       "       [3.94831374e-02, 1.52515853e-02],\n",
       "       [3.22933101e-06, 1.21673656e-06],\n",
       "       [1.41549499e-05, 5.33328557e-06],\n",
       "       [9.97589469e-01, 9.93627667e-01],\n",
       "       [6.31203966e-06, 2.37823156e-06],\n",
       "       [2.44471885e-05, 9.21124229e-06],\n",
       "       [4.40120935e-01, 2.28504255e-01],\n",
       "       [7.09942105e-05, 2.67500654e-05],\n",
       "       [3.82274069e-04, 1.44065911e-04],\n",
       "       [4.15257424e-01, 2.11088285e-01],\n",
       "       [3.50612514e-02, 1.35053387e-02],\n",
       "       [3.86371084e-06, 1.45575518e-06],\n",
       "       [5.86496162e-06, 2.20978200e-06],\n",
       "       [1.95117755e-05, 7.35165668e-06],\n",
       "       [1.93635114e-02, 7.38482317e-03],\n",
       "       [2.19750655e-05, 8.27977965e-06],\n",
       "       [4.59332079e-01, 2.42478907e-01],\n",
       "       [9.99952435e-01, 9.99873638e-01],\n",
       "       [2.36670421e-05, 8.91730269e-06],\n",
       "       [9.99744236e-01, 9.99321342e-01],\n",
       "       [4.65245508e-02, 1.80527698e-02],\n",
       "       [4.16859329e-01, 2.12188363e-01],\n",
       "       [2.42160779e-04, 9.12541218e-05],\n",
       "       [1.52099878e-04, 5.73129400e-05],\n",
       "       [1.36554163e-05, 5.14507519e-06],\n",
       "       [4.81839836e-01, 2.59459943e-01],\n",
       "       [4.20167208e-01, 2.14469478e-01],\n",
       "       [9.84069266e-06, 3.70775524e-06],\n",
       "       [4.51892167e-01, 2.37011641e-01],\n",
       "       [4.77418189e-06, 1.79880203e-06],\n",
       "       [1.16660751e-01, 4.74012978e-02],\n",
       "       [4.57245409e-01, 2.40938321e-01],\n",
       "       [2.88387400e-05, 1.08659369e-05],\n",
       "       [9.99966860e-01, 9.99912024e-01],\n",
       "       [3.64116636e-06, 1.37190546e-06],\n",
       "       [5.11126200e-06, 1.92580455e-06],\n",
       "       [6.02546288e-06, 2.27025544e-06],\n",
       "       [4.35276330e-01, 2.25052699e-01],\n",
       "       [9.99565065e-01, 9.98846292e-01],\n",
       "       [1.74375818e-05, 6.57012561e-06],\n",
       "       [8.35686296e-06, 3.14867771e-06],\n",
       "       [4.40176904e-01, 2.28544325e-01],\n",
       "       [1.02985970e-04, 3.88051194e-05],\n",
       "       [4.42075288e-05, 1.66567897e-05],\n",
       "       [7.91530783e-06, 2.98231157e-06],\n",
       "       [5.14678955e-01, 2.85493582e-01],\n",
       "       [2.40563841e-05, 9.06399328e-06],\n",
       "       [5.76123653e-04, 2.17147375e-04],\n",
       "       [4.95266577e-04, 1.86662015e-04],\n",
       "       [7.16244131e-02, 2.82472502e-02],\n",
       "       [1.96877718e-05, 7.41796930e-06],\n",
       "       [7.29956446e-05, 2.75042239e-05],\n",
       "       [1.09981757e-03, 4.14668757e-04],\n",
       "       [4.15842295e-01, 2.11489603e-01],\n",
       "       [9.99716103e-01, 9.99247074e-01],\n",
       "       [9.99935627e-01, 9.99829054e-01]], dtype=float32), label_ids=array([0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 1, 2, 2], dtype=int64), metrics={'test_loss': 0.7081089615821838, 'test_accuracy': 0.7261146496815286, 'test_f1': 0.2804428044280443, 'test_precision': 0.24203821656050953, 'test_recall': 0.3333333333333333, 'test_runtime': 0.5675, 'test_samples_per_second': 829.938, 'test_steps_per_second': 26.431})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51f5d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.071624', '0.028247']\n"
     ]
    }
   ],
   "source": [
    "item = [7.16244131e-02, 2.82472502e-02]\n",
    "print([format(x, 'f') for x in item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e3a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
