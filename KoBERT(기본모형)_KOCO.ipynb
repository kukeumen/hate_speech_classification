{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6026f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a1cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python36\\site-packages\\mxnet\\optimizer\\optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f6cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfad38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ef82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133147d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cae028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183a8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\.cache\\kobert_v1.zip\n",
      "using cached model. C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "kobert_get_tokenizer = get_tokenizer()\n",
    "kobert_model, kobert_vocab = get_pytorch_kobert_model()\n",
    "kobert_tokenizer = nlp.data.BERTSPTokenizer(kobert_get_tokenizer, kobert_vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1fbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_dataset = nlp.data.TSVDataset(data_path+\"koco_hate_train.txt\", num_discard_samples=1)\n",
    "koco_test_dataset = nlp.data.TSVDataset(data_path+\"koco_hate_test.txt\", num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11641e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenizer(tokens):\n",
    "    decode_tokens = list()\n",
    "    for idx in tokens:\n",
    "        token = kobert_vocab.idx_to_token[idx]\n",
    "        if token == '[PAD]':\n",
    "            break\n",
    "        decode_tokens.append(token)\n",
    "    return decode_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621ba786",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = nlp.data.BERTSentenceTransform(\n",
    "            kobert_tokenizer, max_seq_length=max_len, pad=True, pair=False)\n",
    "token_list = [transform([i[0]]) for i in koco_test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40012d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "짠돌이보단 낫다\n",
      "['[CLS]', '▁', '짠', '돌', '이', '보', '단', '▁', '낫', '다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "idx = 70\n",
    "detoken_list = detokenizer(token_list[idx][0])\n",
    "print(koco_test_dataset[idx][0])\n",
    "print(detoken_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de87db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8ea4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "koco_train_BERTDataset = BERTDataset(koco_train_dataset, 0, 1, kobert_tokenizer, max_len, True, False)\n",
    "koco_test_BERTDataset = BERTDataset(koco_test_dataset, 0, 1, kobert_tokenizer, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b67dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2,  517,   54,  517,   54,  517,   54,  517,   54, 4958, 7206,\n",
       "        2149, 7119, 7095, 1678, 2468,  517,   54,  517,   54,  517,   54,\n",
       "        1458, 5655,  517, 5450, 5439, 6797, 6117, 5785, 6213, 6699,  517,\n",
       "          54,  517,   54,  517,   54, 1185, 6213, 6699, 5916, 7095, 2948,\n",
       "        7766, 7088, 2149, 7416, 3166, 7318, 6224, 7864, 5703,    0,    3,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " array(55),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "koco_train_BERTDataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfdd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "koco_train_dataloader = torch.utils.data.DataLoader(koco_train_BERTDataset, batch_size=batch_size, num_workers=0)\n",
    "koco_test_dataloader = torch.utils.data.DataLoader(koco_test_BERTDataset, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915df2f9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d32ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=3,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a29fef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(kobert_model,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6763bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be3769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46886f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(koco_train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe77fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a71f8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c946441",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af7f83ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a04bb27dcf4fdabe2c317b5d4c4cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.1539857387542725 train acc 0.1875\n",
      "epoch 1 train acc 0.4440524193548387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc190bd860e84ab69c0174833aa47580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.9480105042457581 train acc 0.5\n",
      "epoch 2 train acc 0.5767389112903226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a232d1e2c34c8c9e8ccedfc4ca1ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.7797214984893799 train acc 0.65625\n",
      "epoch 3 train acc 0.6788474462365591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0830a4835edf4649b2f65e7b436c1425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.5610581040382385 train acc 0.75\n",
      "epoch 4 train acc 0.7589465725806451\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa763edf3df49e1bf038eccc3955596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.37405136227607727 train acc 0.8125\n",
      "epoch 5 train acc 0.8131300403225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a1a4f8bbd04525a98a01328ca04bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.6775139570236206 train acc 0.75\n",
      "epoch 6 train acc 0.8736139112903226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aef9ea4530a43ab898f51a8bd115521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.2687787711620331 train acc 0.890625\n",
      "epoch 7 train acc 0.9332157258064516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491ccefc12f740e285ebb4141135cb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.19055968523025513 train acc 0.921875\n",
      "epoch 8 train acc 0.9523689516129032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db3c6d03fa4f12b1d046846480914d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.09088266640901566 train acc 0.953125\n",
      "epoch 9 train acc 0.9732862903225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5292162c59fe4316bf71dfcca86e3a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.020452937111258507 train acc 1.0\n",
      "epoch 10 train acc 0.9819808467741935\n",
      "train_run_time:  272.11071705818176\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(koco_train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label) #cross_entropy loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "        \n",
    "        del loss, label, token_ids, valid_length, segment_ids, out\n",
    "        torch.cuda.empty_cache()\n",
    "       \n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "end_time = time.time()\n",
    "print(\"train_run_time: \", float(end_time) - float(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1427ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'koco_kobert_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aabfec",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e66394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c3fa6572d24c2796ac6f83c1d0f2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_torch_list=[] #predict 값 list 생성\n",
    "test_acc=0\n",
    "#model_path = 'C:/Users/USER/Desktop/2022/koco_kobert_model.pt'\n",
    "#model_path = 'koco_kobert_model.pt'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(koco_test_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        preds_torch_list.append(out)\n",
    "        \n",
    "        del label, token_ids, valid_length, segment_ids, out\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ade8a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "preds_list = list()\n",
    "for temp_list in preds_torch_list:\n",
    "    max_vals, max_indices = torch.max(torch.tensor(temp_list), axis=1)\n",
    "    max_list = max_indices.tolist()\n",
    "    preds_list.extend(max_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311d479",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e92a7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = koco_test_BERTDataset.labels\n",
    "preds_list = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb5f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       160\n",
      "           1       0.53      0.49      0.51       189\n",
      "           2       0.73      0.48      0.58       122\n",
      "\n",
      "    accuracy                           0.60       471\n",
      "   macro avg       0.62      0.60      0.59       471\n",
      "weighted avg       0.61      0.60      0.59       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d03d4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "044310c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4225)\n",
      "tensor(0.4650)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d6fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10",
   "language": "python",
   "name": "badtext10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
