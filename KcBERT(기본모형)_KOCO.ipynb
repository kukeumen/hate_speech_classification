{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME= \"beomi/kcbert-base\"\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  bias\n",
       "0  (ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...     1\n",
       "1  ....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...     0\n",
       "2  ...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...     0\n",
       "3                 1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞     0\n",
       "4  1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...     2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_gender_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_gender_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e04cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df):\n",
    "    pattern = re.compile(f'[^ .,?!/@$%~ÔºÖ¬∑‚àº()\\x00-\\x7F„Ñ±-Ìû£]+')\n",
    "    url_pattern = re.compile(\n",
    "        r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "    def clean(x):\n",
    "        x = pattern.sub(' ', x)\n",
    "        x = url_pattern.sub('', x)\n",
    "        x = x.strip()\n",
    "        x = repeat_normalize(x, num_repeats=2)\n",
    "        return x\n",
    "    for i in range(len(df)):\n",
    "        df['comments'][i] == clean(str(df['comments'][i]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33dbe13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "koco_prep_train_df = preprocess_dataframe(koco_train_df)\n",
    "koco_prep_test_df = preprocess_dataframe(koco_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_prep_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_prep_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"bias\"].values\n",
    "test_label =  koco_test_df[\"bias\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d6efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2,\n",
      "        0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0,\n",
      "        0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0,\n",
      "        0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0,\n",
      "        0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0,\n",
      "        0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2,\n",
      "        0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
      "        1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
      "        0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
      "        2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0,\n",
      "        2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(koco_test_df[\"bias\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/', # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    num_train_epochs=10,                # ÌïôÏäµ epoch ÏÑ§Ï†ï\n",
    "    per_device_train_batch_size=4,      # train batch_size ÏÑ§Ï†ï\n",
    "    per_device_eval_batch_size=32,      # test batch_size ÏÑ§Ï†ï\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/logs/',# ÌïôÏäµlog Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    logging_steps=500,                  # ÌïôÏäµlog Í∏∞Î°ù Îã®ÏúÑ\n",
    "    save_total_limit=2,                 # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû• ÏµúÎåÄÍ∞ØÏàò \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # ÌïôÏäµÌïòÍ≥†ÏûêÌïòÎäî ü§ó Transformers model\n",
    "    args=training_args,                  # ÏúÑÏóêÏÑú Ï†ïÏùòÌïú Training Arguments\n",
    "    train_dataset=train_dataset,         # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    eval_dataset=test_dataset,           # ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    compute_metrics=compute_metrics,     # ÌèâÍ∞ÄÏßÄÌëú\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30264903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 22:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.769600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.738600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.671800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.577700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.584500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.575200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.470100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.614400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.570600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.555600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.511400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.395900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.374800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.561070341904475, metrics={'train_runtime': 1357.0644, 'train_samples_per_second': 58.184, 'train_steps_per_second': 14.546, 'total_flos': 2596929432975360.0, 'train_loss': 0.561070341904475, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1776981353759766,\n",
       " 'eval_accuracy': 0.7876857749469215,\n",
       " 'eval_f1': 0.6984227275991982,\n",
       " 'eval_precision': 0.7000759744738222,\n",
       " 'eval_recall': 0.7128838921784212,\n",
       " 'eval_runtime': 0.4129,\n",
       " 'eval_samples_per_second': 1140.742,\n",
       " 'eval_steps_per_second': 36.329,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87       342\n",
      "           1       0.41      0.61      0.49        62\n",
      "           2       0.79      0.69      0.74        67\n",
      "\n",
      "    accuracy                           0.79       471\n",
      "   macro avg       0.70      0.71      0.70       471\n",
      "weighted avg       0.82      0.79      0.80       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predictions[0].argmax(-1)\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2590)\n",
      "tensor(0.3524)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
