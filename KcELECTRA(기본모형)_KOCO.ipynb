{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc5b8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\677715b0ed32dce9db3091c12047d5d22f03a62eb3aff4b98c408b3d6a3c9211.787019e3fc5c69b1be216b1bd5b640f6cc9d7116635dfd067308d34c42fd1eed\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 54343\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/vocab.txt from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\c9524664323df853eb0852560187189bd7345f041c59a9715761344e2d25d5ce.311b3e9dda9cac38b71564aaa14b6068934be7c0316a5fe1b2c5dba54816ac69\n",
      "loading file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/special_tokens_map.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\3496630ba016f3774c6a821ec4f55bd962ca3d69127a19106d6b622165472ba7.31b83c6ab34462cefd974ed0df8dd4189e7b7b81b47315b7a10627f7ae120002\n",
      "loading file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/tokenizer_config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\cf67088645f62eac018096cdb506bb59fef86716f6a7a6a56400cb25d9a29503.3cf6a609d624dad9e48921ddd3d07764cb2f8f3fc2a84d956416cf643eb1be18\n",
      "loading configuration file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\677715b0ed32dce9db3091c12047d5d22f03a62eb3aff4b98c408b3d6a3c9211.787019e3fc5c69b1be216b1bd5b640f6cc9d7116635dfd067308d34c42fd1eed\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 54343\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\677715b0ed32dce9db3091c12047d5d22f03a62eb3aff4b98c408b3d6a3c9211.787019e3fc5c69b1be216b1bd5b640f6cc9d7116635dfd067308d34c42fd1eed\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 54343\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "MODEL_NAME= \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a39b0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='beomi/KcELECTRA-base-v2022', vocab_size=54343, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21abbfd",
   "metadata": {},
   "source": [
    "# Load Koco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  hate\n",
       "0  (ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...     2\n",
       "1  ....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...     0\n",
       "2  ...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...     2\n",
       "3                 1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞     0\n",
       "4  1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...     2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_hate_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_hate_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"hate\"].values\n",
    "test_label =  koco_test_df[\"hate\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c08e8e",
   "metadata": {},
   "source": [
    "# Î™®Îç∏ ÌäúÎãù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2987f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.losses import CoralLoss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3c0a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\677715b0ed32dce9db3091c12047d5d22f03a62eb3aff4b98c408b3d6a3c9211.787019e3fc5c69b1be216b1bd5b640f6cc9d7116635dfd067308d34c42fd1eed\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 54343\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/pytorch_model.bin from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\c02b8c8bb92b81e96c2a5e1b3f50a6ac58b750312693e2c8fcb8614993094ae0.787de38142ccb76d414b9cb15cc1dcefdeeff8aa6b0acb4165fd73567d62cd22\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/', # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    num_train_epochs=10,                # ÌïôÏäµ epoch ÏÑ§Ï†ï\n",
    "    per_device_train_batch_size=4,      # train batch_size ÏÑ§Ï†ï\n",
    "    per_device_eval_batch_size=32,      # test batch_size ÏÑ§Ï†ï\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/logs/',# ÌïôÏäµlog Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    logging_steps=500,                  # ÌïôÏäµlog Í∏∞Î°ù Îã®ÏúÑ\n",
    "    save_total_limit=2,                 # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû• ÏµúÎåÄÍ∞ØÏàò \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # ÌïôÏäµÌïòÍ≥†ÏûêÌïòÎäî ü§ó Transformers model\n",
    "    args=training_args,                  # ÏúÑÏóêÏÑú Ï†ïÏùòÌïú Training Arguments\n",
    "    train_dataset=train_dataset,         # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    eval_dataset=test_dataset,           # ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    compute_metrics=compute_metrics,     # ÌèâÍ∞ÄÏßÄÌëú\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30264903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 21:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.706800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.714700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.287200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.177600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.071300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-5500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-16000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcELECTRA_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.3319643473311157, metrics={'train_runtime': 1266.122, 'train_samples_per_second': 62.364, 'train_steps_per_second': 15.591, 'total_flos': 2596929432975360.0, 'train_loss': 0.3319643473311157, 'epoch': 10.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.9913086891174316,\n",
       " 'eval_accuracy': 0.6836518046709129,\n",
       " 'eval_f1': 0.6821137679143275,\n",
       " 'eval_precision': 0.6965664956058092,\n",
       " 'eval_recall': 0.686256216208402,\n",
       " 'eval_runtime': 0.4019,\n",
       " 'eval_samples_per_second': 1171.862,\n",
       " 'eval_steps_per_second': 37.32,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcELECTRA_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdabcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77       160\n",
      "           1       0.64      0.55      0.59       189\n",
      "           2       0.77      0.61      0.68       122\n",
      "\n",
      "    accuracy                           0.68       471\n",
      "   macro avg       0.70      0.69      0.68       471\n",
      "weighted avg       0.69      0.68      0.68       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = torch.tensor(predictions.predictions).argmax(-1)\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3291)\n",
      "tensor(0.3546)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f16cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca61759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.3, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca7af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.01      0.01       160\n",
      "           1       0.45      0.89      0.60       189\n",
      "           2       0.00      0.00      0.00       122\n",
      "\n",
      "    accuracy                           0.36       471\n",
      "   macro avg       0.15      0.30      0.20       471\n",
      "weighted avg       0.19      0.36      0.24       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e469c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8025)\n",
      "tensor(1.1295)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66073d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 7.538086 , -3.685877 , -4.024938 ],\n",
       "       [-3.9417264,  7.1240644, -3.1867533],\n",
       "       [-3.8662367,  7.1641326, -3.2961547],\n",
       "       ...,\n",
       "       [-2.6590989,  6.3261714, -3.6829114],\n",
       "       [-2.8966217, -3.6234658,  5.982377 ],\n",
       "       [-3.5727093,  6.4556785, -2.8588383]], dtype=float32), label_ids=array([0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0,\n",
       "       1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1,\n",
       "       1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 2, 0, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 2, 0], dtype=int64), metrics={'test_loss': 2.7592666149139404, 'test_accuracy': 0.70276008492569, 'test_f1': 0.7018058839331301, 'test_precision': 0.7231000677809188, 'test_recall': 0.6979448564489547, 'test_runtime': 0.398, 'test_samples_per_second': 1183.438, 'test_steps_per_second': 37.689})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "51f5d543",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-e31358d7d4fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m54343\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-b9e4a792da84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         )\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\electra\\modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary\n",
    "summary(model, (4, 54343))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dbf156bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54343, 768])\n",
      "electra.embeddings.word_embeddings.weight\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, param in model.named_parameters():\n",
    "    count+=1\n",
    "    if count==1:\n",
    "        print(param.size())\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014a37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
