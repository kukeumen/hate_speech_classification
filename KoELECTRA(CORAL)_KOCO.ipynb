{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5b8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "MODEL_NAME= \"monologg/koelectra-base-v3-hate-speech\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39b0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='monologg/koelectra-base-v3-hate-speech', vocab_size=35000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21abbfd",
   "metadata": {},
   "source": [
    "# Load Koco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  hate\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...     2\n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...     0\n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...     2\n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데     0\n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...     2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_hate_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_hate_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"hate\"].values\n",
    "test_label =  koco_test_df[\"hate\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c08e8e",
   "metadata": {},
   "source": [
    "# 모델 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cc2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.losses import CoralLoss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label\n",
    "from typing import Optional, Union, Tuple\n",
    "from transformers.activations import get_activation\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38c4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        classifier_dropout = 0.2\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        #self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.coral_layer = CoralLayer(config.hidden_size, config.num_labels)\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = get_activation(\"gelu\")(x)  # although BERT uses tanh here, it seems Electra authors used gelu here\n",
    "        x = self.dropout(x)\n",
    "        x = self.coral_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76842350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraPreTrainedModel, ElectraModel\n",
    "class ElectraForSequenceClassification(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "        self.electra = ElectraModel(config)\n",
    "        self.classifier = ElectraClassificationHead(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        discriminator_hidden_states = self.electra(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = discriminator_hidden_states[0]\n",
    "        logits = self.classifier(sequence_output) #coral layer\n",
    "        probas = torch.sigmoid(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == 'CORAL':\n",
    "                iw = torch.tensor([0.7, 0.3]).to(device)\n",
    "                loss_fct = CoralLoss()\n",
    "                levels = levels_from_labelbatch(labels.view(-1) , num_classes=3).to(device)\n",
    "                loss = loss_fct(logits, levels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + discriminator_hidden_states[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=probas,\n",
    "            hidden_states=discriminator_hidden_states.hidden_states,\n",
    "            attentions=discriminator_hidden_states.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c0a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-hate-speech were not used when initializing ElectraForSequenceClassification: ['classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-hate-speech and are newly initialized: ['classifier.coral_layer.coral_weights.weight', 'classifier.coral_layer.coral_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (coral_layer): CoralLayer(\n",
       "      (coral_weights): Linear(in_features=768, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, problem_type='CORAL')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/', # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size=4,      # train batch_size 설정\n",
    "    per_device_eval_batch_size=32,      # test batch_size 설정\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/logs/',# 학습log 저장경로\n",
    "    logging_steps=500,                  # 학습log 기록 단위\n",
    "    save_total_limit=2,                 # 학습결과 저장 최대갯수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 학습하고자하는 🤗 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 Training Arguments\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30264903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 22:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.899700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.873400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.865800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.744700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.598800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.629300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.631100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.526900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.471700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.426100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.324700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.306600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.304700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-10500\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-15500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_CORAL_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.4943261619034509, metrics={'train_runtime': 1348.8363, 'train_samples_per_second': 58.539, 'train_steps_per_second': 14.635, 'total_flos': 2596882830151680.0, 'train_loss': 0.4943261619034509, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.16312837600708,\n",
       " 'eval_accuracy': 0.33970276008492567,\n",
       " 'eval_f1': 0.16904384574749076,\n",
       " 'eval_precision': 0.11323425336164189,\n",
       " 'eval_recall': 0.3333333333333333,\n",
       " 'eval_runtime': 0.4668,\n",
       " 'eval_samples_per_second': 1008.936,\n",
       " 'eval_steps_per_second': 32.132,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       160\n",
      "           1       0.60      0.54      0.57       189\n",
      "           2       0.82      0.52      0.64       122\n",
      "\n",
      "    accuracy                           0.66       471\n",
      "   macro avg       0.69      0.65      0.65       471\n",
      "weighted avg       0.67      0.66      0.65       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = proba_to_label(torch.tensor(predictions.predictions))\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3567)\n",
      "tensor(0.3822)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93224d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608d084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2f16cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ca61759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.3, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca7af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       160\n",
      "           1       0.59      0.57      0.58       189\n",
      "           2       0.83      0.49      0.62       122\n",
      "\n",
      "    accuracy                           0.66       471\n",
      "   macro avg       0.69      0.65      0.65       471\n",
      "weighted avg       0.67      0.66      0.65       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e469c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3588)\n",
      "tensor(0.3885)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "66073d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[5.69937765e-05, 1.82821022e-05],\n",
       "       [6.44961536e-01, 3.68165821e-01],\n",
       "       [6.45221770e-01, 3.68430197e-01],\n",
       "       [6.44225836e-01, 3.67419124e-01],\n",
       "       [6.37250245e-01, 3.60404462e-01],\n",
       "       [9.99988914e-01, 9.99965549e-01],\n",
       "       [5.50662153e-05, 1.76637677e-05],\n",
       "       [5.47278214e-05, 1.75552159e-05],\n",
       "       [5.36926891e-05, 1.72231612e-05],\n",
       "       [5.35714753e-05, 1.71842767e-05],\n",
       "       [5.88091862e-05, 1.88644590e-05],\n",
       "       [3.39006633e-02, 1.11303125e-02],\n",
       "       [5.58009451e-05, 1.78994578e-05],\n",
       "       [6.44258678e-01, 3.67452353e-01],\n",
       "       [6.42345846e-01, 3.65516961e-01],\n",
       "       [6.44089997e-01, 3.67281348e-01],\n",
       "       [6.43820822e-01, 3.67008597e-01],\n",
       "       [9.99988914e-01, 9.99965549e-01],\n",
       "       [6.43325984e-01, 3.66507530e-01],\n",
       "       [4.63045895e-01, 2.16675729e-01],\n",
       "       [5.58557804e-05, 1.79170493e-05],\n",
       "       [6.56940877e-01, 3.80513966e-01],\n",
       "       [6.38715744e-01, 3.61868411e-01],\n",
       "       [6.77559257e-01, 4.02639210e-01],\n",
       "       [5.38819622e-05, 1.72838754e-05],\n",
       "       [5.51315279e-05, 1.76847188e-05],\n",
       "       [6.44553721e-01, 3.67751688e-01],\n",
       "       [9.99983668e-01, 9.99949217e-01],\n",
       "       [6.41531706e-01, 3.64695966e-01],\n",
       "       [6.42787397e-01, 3.65962923e-01],\n",
       "       [6.42653823e-01, 3.65827978e-01],\n",
       "       [6.38863266e-01, 3.62016082e-01],\n",
       "       [5.41162590e-05, 1.73590361e-05],\n",
       "       [5.82622524e-05, 1.86890120e-05],\n",
       "       [5.52896345e-05, 1.77354377e-05],\n",
       "       [6.29715979e-01, 3.52958560e-01],\n",
       "       [6.41413927e-01, 3.64577234e-01],\n",
       "       [6.42461300e-01, 3.65633488e-01],\n",
       "       [6.39923453e-01, 3.63078684e-01],\n",
       "       [5.37515043e-05, 1.72420278e-05],\n",
       "       [9.99944210e-01, 9.99826252e-01],\n",
       "       [6.51671112e-01, 3.75037611e-01],\n",
       "       [9.99988556e-01, 9.99964356e-01],\n",
       "       [9.99967575e-01, 9.99898791e-01],\n",
       "       [6.38589501e-01, 3.61742109e-01],\n",
       "       [6.41572237e-01, 3.64736676e-01],\n",
       "       [9.99989271e-01, 9.99966383e-01],\n",
       "       [6.37105703e-01, 3.60260367e-01],\n",
       "       [6.24194799e-04, 2.00302413e-04],\n",
       "       [1.83504149e-01, 6.72423095e-02],\n",
       "       [6.47557855e-01, 3.70811582e-01],\n",
       "       [1.20063421e-04, 3.85148305e-05],\n",
       "       [6.40170872e-01, 3.63327086e-01],\n",
       "       [6.58652127e-01, 3.82307649e-01],\n",
       "       [7.46243022e-05, 2.39377950e-05],\n",
       "       [6.43052042e-01, 3.66230458e-01],\n",
       "       [5.61807319e-05, 1.80212901e-05],\n",
       "       [6.43706203e-01, 3.66892427e-01],\n",
       "       [5.46412521e-05, 1.75274454e-05],\n",
       "       [5.53867321e-05, 1.77665861e-05],\n",
       "       [5.39568791e-05, 1.73079079e-05],\n",
       "       [6.39725387e-01, 3.62880021e-01],\n",
       "       [5.53224418e-05, 1.77459606e-05],\n",
       "       [1.09524881e-04, 3.51339477e-05],\n",
       "       [9.99989152e-01, 9.99966264e-01],\n",
       "       [5.44138638e-05, 1.74545021e-05],\n",
       "       [6.41461432e-01, 3.64625126e-01],\n",
       "       [6.39598191e-01, 3.62752438e-01],\n",
       "       [5.50505720e-05, 1.76587473e-05],\n",
       "       [9.99989152e-01, 9.99966383e-01],\n",
       "       [6.09783201e-05, 1.95602897e-05],\n",
       "       [5.44604300e-05, 1.74694414e-05],\n",
       "       [5.60576482e-05, 1.79818016e-05],\n",
       "       [9.99988794e-01, 9.99964952e-01],\n",
       "       [5.37481756e-05, 1.72409582e-05],\n",
       "       [5.47337695e-05, 1.75571240e-05],\n",
       "       [6.41952336e-01, 3.65119845e-01],\n",
       "       [9.99827087e-01, 9.99460995e-01],\n",
       "       [3.76992626e-04, 1.20955592e-04],\n",
       "       [6.53289855e-01, 3.76712292e-01],\n",
       "       [5.56183477e-05, 1.78408845e-05],\n",
       "       [6.40530944e-01, 3.63688886e-01],\n",
       "       [9.99987602e-01, 9.99961257e-01],\n",
       "       [2.86446360e-04, 9.18987644e-05],\n",
       "       [7.43080163e-05, 2.38363336e-05],\n",
       "       [6.40834808e-01, 3.63994390e-01],\n",
       "       [6.84225452e-05, 2.19483190e-05],\n",
       "       [5.39709763e-05, 1.73124317e-05],\n",
       "       [8.17687833e-05, 2.62297090e-05],\n",
       "       [6.37400150e-01, 3.60554010e-01],\n",
       "       [5.59232576e-05, 1.79386934e-05],\n",
       "       [5.41540503e-05, 1.73711596e-05],\n",
       "       [6.40766919e-01, 3.63926142e-01],\n",
       "       [9.99778688e-01, 9.99310374e-01],\n",
       "       [9.99986291e-01, 9.99957323e-01],\n",
       "       [6.44237220e-01, 3.67430657e-01],\n",
       "       [6.42847300e-01, 3.66023421e-01],\n",
       "       [9.99989033e-01, 9.99965906e-01],\n",
       "       [6.44211888e-01, 3.67404968e-01],\n",
       "       [6.42179668e-01, 3.65349263e-01],\n",
       "       [6.46822751e-01, 3.70060742e-01],\n",
       "       [6.42836809e-01, 3.66012871e-01],\n",
       "       [6.47347629e-01, 3.70596796e-01],\n",
       "       [6.41051650e-01, 3.64212513e-01],\n",
       "       [6.41260386e-01, 3.64422619e-01],\n",
       "       [9.99791324e-01, 9.99349535e-01],\n",
       "       [9.94951010e-01, 9.84425902e-01],\n",
       "       [3.55850061e-04, 1.14170500e-04],\n",
       "       [5.50793957e-05, 1.76679969e-05],\n",
       "       [6.39655352e-01, 3.62809807e-01],\n",
       "       [5.40658621e-05, 1.73428689e-05],\n",
       "       [6.36236668e-01, 3.59394968e-01],\n",
       "       [9.99986887e-01, 9.99959230e-01],\n",
       "       [6.44340932e-01, 3.67535800e-01],\n",
       "       [6.38594687e-01, 3.61747324e-01],\n",
       "       [6.34935200e-01, 3.58102351e-01],\n",
       "       [5.95452220e-05, 1.91005711e-05],\n",
       "       [4.05794970e-04, 1.30199202e-04],\n",
       "       [9.99901891e-01, 9.99694228e-01],\n",
       "       [9.99969602e-01, 9.99905348e-01],\n",
       "       [5.37956512e-05, 1.72561904e-05],\n",
       "       [6.69681103e-05, 2.14817501e-05],\n",
       "       [6.42459631e-01, 3.65631849e-01],\n",
       "       [5.41711997e-05, 1.73766584e-05],\n",
       "       [6.29830029e-05, 2.02033698e-05],\n",
       "       [5.60026092e-05, 1.79641502e-05],\n",
       "       [5.39124885e-05, 1.72936707e-05],\n",
       "       [7.23256767e-01, 4.56017911e-01],\n",
       "       [9.99986291e-01, 9.99957085e-01],\n",
       "       [1.82086928e-03, 5.84787573e-04],\n",
       "       [5.44648974e-05, 1.74708730e-05],\n",
       "       [5.47923628e-05, 1.75759196e-05],\n",
       "       [6.43710434e-01, 3.66896778e-01],\n",
       "       [6.31702900e-01, 3.54909182e-01],\n",
       "       [6.41145885e-01, 3.64307374e-01],\n",
       "       [5.69939402e-05, 1.82821532e-05],\n",
       "       [5.56164414e-05, 1.78402715e-05],\n",
       "       [5.51568701e-05, 1.76928497e-05],\n",
       "       [6.45981669e-01, 3.69203359e-01],\n",
       "       [6.42225504e-01, 3.65395457e-01],\n",
       "       [6.73705188e-04, 2.16197455e-04],\n",
       "       [6.43943369e-01, 3.67132723e-01],\n",
       "       [5.78921790e-05, 1.85702993e-05],\n",
       "       [5.73101570e-05, 1.83835909e-05],\n",
       "       [6.42068386e-01, 3.65236908e-01],\n",
       "       [5.64074326e-05, 1.80940115e-05],\n",
       "       [8.68565476e-05, 2.78618591e-05],\n",
       "       [6.52900875e-01, 3.76309276e-01],\n",
       "       [5.45897456e-05, 1.75109217e-05],\n",
       "       [6.41738415e-01, 3.64904225e-01],\n",
       "       [6.38329268e-01, 3.61481845e-01],\n",
       "       [9.99984384e-01, 9.99951363e-01],\n",
       "       [5.46636111e-05, 1.75346177e-05],\n",
       "       [6.43885553e-01, 3.67074162e-01],\n",
       "       [6.40141070e-01, 3.63297135e-01],\n",
       "       [9.99988794e-01, 9.99965072e-01],\n",
       "       [6.41620576e-01, 3.64785433e-01],\n",
       "       [1.67555059e-03, 5.38064050e-04],\n",
       "       [2.20131725e-02, 7.16815144e-03],\n",
       "       [6.38299823e-01, 3.61452460e-01],\n",
       "       [5.67541028e-05, 1.82052190e-05],\n",
       "       [5.68739488e-05, 1.82436634e-05],\n",
       "       [8.98357976e-05, 2.88175997e-05],\n",
       "       [6.39759541e-01, 3.62914264e-01],\n",
       "       [5.56803898e-05, 1.78607861e-05],\n",
       "       [5.70388511e-05, 1.82965614e-05],\n",
       "       [5.69785589e-05, 1.82772201e-05],\n",
       "       [6.67429267e-05, 2.14095144e-05],\n",
       "       [3.32970056e-04, 1.06828054e-04],\n",
       "       [5.38619206e-05, 1.72774489e-05],\n",
       "       [9.99925971e-01, 9.99769270e-01],\n",
       "       [7.97792163e-05, 2.55914674e-05],\n",
       "       [5.50228615e-05, 1.76498579e-05],\n",
       "       [6.43654168e-01, 3.66839737e-01],\n",
       "       [6.44949436e-01, 3.68153483e-01],\n",
       "       [9.99986053e-01, 9.99956608e-01],\n",
       "       [6.68066059e-05, 2.14299434e-05],\n",
       "       [5.67706738e-05, 1.82105323e-05],\n",
       "       [6.12053482e-05, 1.96331184e-05],\n",
       "       [6.42421126e-01, 3.65592986e-01],\n",
       "       [5.43850219e-05, 1.74452507e-05],\n",
       "       [6.39721334e-01, 3.62875909e-01],\n",
       "       [5.42269154e-05, 1.73945318e-05],\n",
       "       [5.55244442e-05, 1.78107603e-05],\n",
       "       [6.39565349e-01, 3.62719506e-01],\n",
       "       [5.68131873e-05, 1.82241693e-05],\n",
       "       [9.99987721e-01, 9.99961734e-01],\n",
       "       [6.42064333e-01, 3.65232855e-01],\n",
       "       [6.42550945e-01, 3.65724057e-01],\n",
       "       [5.53626523e-05, 1.77588608e-05],\n",
       "       [5.43311144e-05, 1.74279558e-05],\n",
       "       [6.41912043e-01, 3.65079224e-01],\n",
       "       [6.40136302e-01, 3.63292426e-01],\n",
       "       [2.21493669e-04, 7.10572713e-05],\n",
       "       [9.99964476e-01, 9.99889374e-01],\n",
       "       [8.17962282e-05, 2.62385165e-05],\n",
       "       [6.43020332e-01, 3.66198421e-01],\n",
       "       [2.43711611e-03, 7.83028605e-04],\n",
       "       [6.40864551e-01, 3.64024222e-01],\n",
       "       [6.41656101e-01, 3.64821255e-01],\n",
       "       [5.40629735e-05, 1.73419430e-05],\n",
       "       [6.44386768e-01, 3.67582321e-01],\n",
       "       [5.54707294e-05, 1.77935290e-05],\n",
       "       [6.43764615e-01, 3.66951555e-01],\n",
       "       [6.42970562e-01, 3.66148025e-01],\n",
       "       [5.46092160e-05, 1.75171681e-05],\n",
       "       [5.76267485e-05, 1.84851506e-05],\n",
       "       [9.99986768e-01, 9.99958873e-01],\n",
       "       [5.43076458e-05, 1.74204288e-05],\n",
       "       [5.37868291e-05, 1.72533601e-05],\n",
       "       [9.99306560e-01, 9.97841358e-01],\n",
       "       [6.44881427e-01, 3.68084401e-01],\n",
       "       [1.24244907e-04, 3.98563134e-05],\n",
       "       [9.99988556e-01, 9.99964476e-01],\n",
       "       [5.58704814e-05, 1.79217641e-05],\n",
       "       [9.99946952e-01, 9.99834776e-01],\n",
       "       [1.24708764e-04, 4.00051285e-05],\n",
       "       [6.31114542e-01, 3.54330659e-01],\n",
       "       [6.44884527e-01, 3.68087620e-01],\n",
       "       [6.41652286e-01, 3.64817381e-01],\n",
       "       [5.93664169e-01, 3.19097072e-01],\n",
       "       [1.81210111e-04, 5.81323329e-05],\n",
       "       [6.40224695e-01, 3.63381207e-01],\n",
       "       [6.41055822e-01, 3.64216775e-01],\n",
       "       [6.56030059e-01, 3.79562438e-01],\n",
       "       [9.99708116e-01, 9.99090791e-01],\n",
       "       [5.83008332e-05, 1.87013866e-05],\n",
       "       [5.57872227e-05, 1.78950540e-05],\n",
       "       [5.41273548e-05, 1.73625958e-05],\n",
       "       [6.04459674e-05, 1.93895175e-05],\n",
       "       [6.42947376e-01, 3.66124630e-01],\n",
       "       [9.99989390e-01, 9.99966860e-01],\n",
       "       [9.41128601e-05, 3.01896871e-05],\n",
       "       [5.45187831e-05, 1.74881588e-05],\n",
       "       [6.06384456e-05, 1.94512650e-05],\n",
       "       [8.92750759e-05, 2.86377181e-05],\n",
       "       [5.65493538e-05, 1.81395371e-05],\n",
       "       [9.26020657e-05, 2.97050228e-05],\n",
       "       [5.51740777e-05, 1.76983667e-05],\n",
       "       [5.49821561e-05, 1.76368030e-05],\n",
       "       [5.35428262e-05, 1.71750853e-05],\n",
       "       [9.99988556e-01, 9.99964237e-01],\n",
       "       [6.43212974e-01, 3.66393209e-01],\n",
       "       [6.42708659e-01, 3.65883440e-01],\n",
       "       [6.52376038e-05, 2.09266218e-05],\n",
       "       [6.43375993e-01, 3.66558135e-01],\n",
       "       [6.42922699e-01, 3.66099715e-01],\n",
       "       [5.48927273e-05, 1.76081157e-05],\n",
       "       [6.34888232e-01, 3.58055741e-01],\n",
       "       [9.99809682e-01, 9.99406934e-01],\n",
       "       [8.63843248e-04, 2.77250074e-04],\n",
       "       [5.46392730e-05, 1.75268106e-05],\n",
       "       [7.28558662e-05, 2.33704941e-05],\n",
       "       [5.65503215e-05, 1.81398500e-05],\n",
       "       [6.42891228e-01, 3.66067886e-01],\n",
       "       [5.36417610e-05, 1.72068249e-05],\n",
       "       [5.71135279e-05, 1.83205175e-05],\n",
       "       [5.51261692e-05, 1.76829999e-05],\n",
       "       [5.71913421e-01, 2.99979389e-01],\n",
       "       [1.14374045e-04, 3.66896093e-05],\n",
       "       [6.39245918e-05, 2.05054221e-05],\n",
       "       [5.52679703e-05, 1.77284874e-05],\n",
       "       [5.88220828e-05, 1.88685972e-05],\n",
       "       [6.37886763e-01, 3.61039698e-01],\n",
       "       [9.99980688e-01, 9.99939799e-01],\n",
       "       [5.48638927e-05, 1.75988644e-05],\n",
       "       [6.18049453e-05, 1.98254638e-05],\n",
       "       [6.40292585e-01, 3.63449454e-01],\n",
       "       [5.43045353e-05, 1.74194320e-05],\n",
       "       [9.99867439e-01, 9.99586761e-01],\n",
       "       [6.35982096e-01, 3.59141827e-01],\n",
       "       [6.42114401e-01, 3.65283340e-01],\n",
       "       [6.39553249e-01, 3.62707317e-01],\n",
       "       [9.99856710e-01, 9.99553502e-01],\n",
       "       [5.52554811e-05, 1.77244801e-05],\n",
       "       [5.46542287e-05, 1.75316090e-05],\n",
       "       [5.48061616e-05, 1.75803452e-05],\n",
       "       [5.35710169e-05, 1.71841293e-05],\n",
       "       [6.40351534e-01, 3.63508612e-01],\n",
       "       [9.99985695e-01, 9.99955416e-01],\n",
       "       [6.42562211e-01, 3.65735471e-01],\n",
       "       [5.21553010e-02, 1.73438191e-02],\n",
       "       [6.42094731e-01, 3.65263492e-01],\n",
       "       [6.45679474e-01, 3.68895710e-01],\n",
       "       [6.38568521e-01, 3.61721158e-01],\n",
       "       [6.42725706e-01, 3.65900606e-01],\n",
       "       [9.99987841e-01, 9.99962211e-01],\n",
       "       [5.56326740e-05, 1.78454793e-05],\n",
       "       [1.21630699e-04, 3.90176392e-05],\n",
       "       [6.42907441e-01, 3.66084248e-01],\n",
       "       [6.32362962e-01, 3.55559230e-01],\n",
       "       [6.44038796e-01, 3.67229432e-01],\n",
       "       [3.65043234e-04, 1.17120755e-04],\n",
       "       [8.63656242e-05, 2.77043691e-05],\n",
       "       [5.43784299e-05, 1.74431370e-05],\n",
       "       [6.42958820e-01, 3.66136193e-01],\n",
       "       [6.73133400e-05, 2.15924974e-05],\n",
       "       [4.99867834e-03, 1.60884485e-03],\n",
       "       [6.60544669e-04, 2.11972234e-04],\n",
       "       [6.39517367e-01, 3.62671316e-01],\n",
       "       [5.44788709e-05, 1.74753550e-05],\n",
       "       [9.99971271e-01, 9.99910355e-01],\n",
       "       [6.45106256e-01, 3.68312836e-01],\n",
       "       [1.02304737e-04, 3.28176720e-05],\n",
       "       [6.40948832e-01, 3.64109039e-01],\n",
       "       [5.53324608e-05, 1.77491765e-05],\n",
       "       [5.56050909e-05, 1.78366317e-05],\n",
       "       [6.03257775e-01, 3.27833444e-01],\n",
       "       [6.41620398e-01, 3.64785284e-01],\n",
       "       [6.44628108e-01, 3.67827177e-01],\n",
       "       [6.41913414e-01, 3.65080684e-01],\n",
       "       [5.60036278e-05, 1.79644740e-05],\n",
       "       [4.61744875e-01, 2.15788797e-01],\n",
       "       [5.39175817e-05, 1.72953005e-05],\n",
       "       [9.99986410e-01, 9.99957681e-01],\n",
       "       [5.34990286e-05, 1.71610391e-05],\n",
       "       [6.42448604e-01, 3.65620732e-01],\n",
       "       [5.61439956e-05, 1.80095030e-05],\n",
       "       [5.58027023e-05, 1.79000217e-05],\n",
       "       [9.99988317e-01, 9.99963641e-01],\n",
       "       [9.99989033e-01, 9.99965787e-01],\n",
       "       [9.99988914e-01, 9.99965429e-01],\n",
       "       [6.43521130e-01, 3.66705030e-01],\n",
       "       [3.91334936e-04, 1.25558465e-04],\n",
       "       [6.39905572e-01, 3.63060772e-01],\n",
       "       [6.33885503e-01, 3.57062638e-01],\n",
       "       [4.20971334e-01, 1.89103574e-01],\n",
       "       [9.99986649e-01, 9.99958396e-01],\n",
       "       [9.99987125e-01, 9.99960065e-01],\n",
       "       [6.43462062e-01, 3.66645217e-01],\n",
       "       [9.99988914e-01, 9.99965549e-01],\n",
       "       [6.41425848e-01, 3.64589244e-01],\n",
       "       [5.41358240e-05, 1.73653116e-05],\n",
       "       [1.28393396e-04, 4.11872134e-05],\n",
       "       [5.52404636e-05, 1.77196653e-05],\n",
       "       [6.42267942e-01, 3.65438312e-01],\n",
       "       [9.99988317e-01, 9.99963641e-01],\n",
       "       [1.13825256e-04, 3.65135529e-05],\n",
       "       [6.35838223e-05, 2.03961063e-05],\n",
       "       [6.43510878e-01, 3.66694719e-01],\n",
       "       [9.99987245e-01, 9.99960303e-01],\n",
       "       [6.42785192e-01, 3.65960747e-01],\n",
       "       [9.99983430e-01, 9.99948144e-01],\n",
       "       [9.99979258e-01, 9.99935389e-01],\n",
       "       [6.35624349e-01, 3.58786315e-01],\n",
       "       [6.41804516e-01, 3.64970803e-01],\n",
       "       [5.53441241e-05, 1.77529182e-05],\n",
       "       [9.99989033e-01, 9.99965787e-01],\n",
       "       [6.38085902e-01, 3.61238658e-01],\n",
       "       [5.39347056e-05, 1.73007957e-05],\n",
       "       [5.92180877e-05, 1.89956299e-05],\n",
       "       [9.99988914e-01, 9.99965429e-01],\n",
       "       [6.44110978e-01, 3.67302656e-01],\n",
       "       [1.01750760e-04, 3.26399531e-05],\n",
       "       [6.45109236e-01, 3.68315876e-01],\n",
       "       [8.55855324e-05, 2.74541198e-05],\n",
       "       [6.38068497e-01, 3.61221224e-01],\n",
       "       [5.47123745e-05, 1.75502610e-05],\n",
       "       [6.83651451e-05, 2.19299072e-05],\n",
       "       [6.39795482e-01, 3.62950295e-01],\n",
       "       [6.62296297e-05, 2.12448540e-05],\n",
       "       [6.40635014e-01, 3.63793433e-01],\n",
       "       [9.99984860e-01, 9.99952674e-01],\n",
       "       [6.37390316e-01, 3.60544175e-01],\n",
       "       [5.67170428e-05, 1.81933301e-05],\n",
       "       [6.16167426e-01, 3.39898616e-01],\n",
       "       [1.88405262e-04, 6.04408342e-05],\n",
       "       [6.69469082e-05, 2.14749507e-05],\n",
       "       [6.44294858e-01, 3.67489010e-01],\n",
       "       [5.67133175e-05, 1.81921332e-05],\n",
       "       [3.23886663e-04, 1.03913153e-04],\n",
       "       [5.40126312e-05, 1.73257940e-05],\n",
       "       [9.99477208e-01, 9.98372018e-01],\n",
       "       [6.20275915e-01, 3.43815029e-01],\n",
       "       [6.39446437e-01, 3.62600267e-01],\n",
       "       [8.08481273e-05, 2.59343688e-05],\n",
       "       [6.44708335e-01, 3.67908686e-01],\n",
       "       [5.51552948e-05, 1.76923440e-05],\n",
       "       [9.99989390e-01, 9.99966860e-01],\n",
       "       [5.62981841e-05, 1.80589668e-05],\n",
       "       [6.41564846e-01, 3.64729255e-01],\n",
       "       [6.43254876e-01, 3.66435528e-01],\n",
       "       [5.43021051e-05, 1.74186516e-05],\n",
       "       [5.55409169e-05, 1.78160444e-05],\n",
       "       [6.39560223e-01, 3.62714350e-01],\n",
       "       [5.67649331e-05, 1.82086915e-05],\n",
       "       [2.67596071e-04, 8.58500498e-05],\n",
       "       [9.99989152e-01, 9.99966383e-01],\n",
       "       [1.53033834e-04, 4.90924285e-05],\n",
       "       [9.99988914e-01, 9.99965549e-01],\n",
       "       [6.43628776e-01, 3.66814017e-01],\n",
       "       [9.99854565e-01, 9.99546587e-01],\n",
       "       [5.36501539e-05, 1.72095170e-05],\n",
       "       [1.22341560e-03, 3.92750691e-04],\n",
       "       [8.53203019e-05, 2.73690330e-05],\n",
       "       [9.99985933e-01, 9.99956369e-01],\n",
       "       [6.42634273e-01, 3.65808249e-01],\n",
       "       [8.85446643e-05, 2.84034013e-05],\n",
       "       [1.09157038e-04, 3.50159389e-05],\n",
       "       [8.06473108e-05, 2.58699474e-05],\n",
       "       [6.41826212e-01, 3.64992768e-01],\n",
       "       [4.83104110e-01, 2.30645955e-01],\n",
       "       [5.71254022e-05, 1.83243264e-05],\n",
       "       [9.99988794e-01, 9.99965191e-01],\n",
       "       [6.42411172e-01, 3.65582854e-01],\n",
       "       [6.40419304e-01, 3.63576740e-01],\n",
       "       [5.56178711e-05, 1.78407317e-05],\n",
       "       [5.49214747e-05, 1.76173344e-05],\n",
       "       [9.99985456e-01, 9.99954581e-01],\n",
       "       [1.83338241e-04, 5.88151306e-05],\n",
       "       [5.47964373e-05, 1.75772275e-05],\n",
       "       [5.57905150e-05, 1.78961127e-05],\n",
       "       [5.92888900e-05, 1.90183418e-05],\n",
       "       [3.08672097e-02, 1.01130353e-02],\n",
       "       [5.39018001e-05, 1.72902401e-05],\n",
       "       [6.42003059e-01, 3.65171075e-01],\n",
       "       [5.46588199e-05, 1.75330806e-05],\n",
       "       [7.11888832e-04, 2.28456789e-04],\n",
       "       [9.99921441e-01, 9.99754965e-01],\n",
       "       [5.45054791e-05, 1.74838897e-05],\n",
       "       [5.91668367e-01, 3.17303538e-01],\n",
       "       [5.45950534e-05, 1.75126261e-05],\n",
       "       [6.38702154e-01, 3.61854821e-01],\n",
       "       [6.42156124e-01, 3.65325481e-01],\n",
       "       [2.16476750e-04, 6.94475602e-05],\n",
       "       [9.99873996e-01, 9.99607384e-01],\n",
       "       [6.41817987e-01, 3.64984423e-01],\n",
       "       [5.95940828e-01, 3.21152985e-01],\n",
       "       [6.41968906e-01, 3.65136564e-01],\n",
       "       [6.47611976e-01, 3.70866925e-01],\n",
       "       [6.40676200e-01, 3.63834858e-01],\n",
       "       [8.03450239e-05, 2.57729753e-05],\n",
       "       [9.99982953e-01, 9.99946713e-01],\n",
       "       [6.44984603e-01, 3.68189216e-01],\n",
       "       [6.43060148e-01, 3.66238594e-01],\n",
       "       [6.42080486e-01, 3.65249127e-01],\n",
       "       [5.65206210e-05, 1.81303185e-05],\n",
       "       [3.87306616e-04, 1.24265644e-04],\n",
       "       [7.51002444e-05, 2.40904756e-05],\n",
       "       [9.99984026e-01, 9.99950171e-01],\n",
       "       [6.42706037e-01, 3.65880698e-01],\n",
       "       [6.06393151e-05, 1.94515433e-05],\n",
       "       [1.04268001e-04, 3.34475008e-05],\n",
       "       [4.98255074e-04, 1.59875039e-04],\n",
       "       [5.47049676e-05, 1.75478835e-05],\n",
       "       [9.99982953e-01, 9.99947071e-01],\n",
       "       [9.99934793e-01, 9.99796689e-01],\n",
       "       [6.51008886e-05, 2.08827641e-05],\n",
       "       [9.99988914e-01, 9.99965549e-01],\n",
       "       [5.39006651e-05, 1.72898763e-05],\n",
       "       [5.52176061e-05, 1.77123311e-05],\n",
       "       [5.55071856e-05, 1.78052233e-05],\n",
       "       [6.58487552e-05, 2.11226743e-05],\n",
       "       [9.99989271e-01, 9.99966621e-01],\n",
       "       [5.56340019e-05, 1.78459031e-05],\n",
       "       [5.39370703e-05, 1.73015542e-05],\n",
       "       [6.05801288e-05, 1.94325567e-05],\n",
       "       [6.40767097e-01, 3.63926262e-01],\n",
       "       [6.41223490e-01, 3.64385486e-01],\n",
       "       [6.18440317e-05, 1.98380021e-05],\n",
       "       [6.52300119e-01, 3.75687510e-01],\n",
       "       [5.38560671e-05, 1.72755699e-05],\n",
       "       [6.44481540e-01, 3.67678463e-01],\n",
       "       [6.43406749e-01, 3.66589278e-01],\n",
       "       [6.41729176e-01, 3.64894897e-01],\n",
       "       [5.56962113e-05, 1.78658611e-05],\n",
       "       [5.80961459e-05, 1.86357265e-05],\n",
       "       [6.42601550e-01, 3.65775198e-01],\n",
       "       [6.36481643e-01, 3.59638751e-01],\n",
       "       [9.99986887e-01, 9.99958992e-01],\n",
       "       [6.89027727e-01, 4.15449888e-01]], dtype=float32), label_ids=array([0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0,\n",
       "       1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1,\n",
       "       1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 2, 0, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 2, 0], dtype=int64), metrics={'test_loss': 2.2533841133117676, 'test_accuracy': 0.33970276008492567, 'test_f1': 0.16904384574749076, 'test_precision': 0.11323425336164189, 'test_recall': 0.3333333333333333, 'test_runtime': 0.452, 'test_samples_per_second': 1042.033, 'test_steps_per_second': 33.186})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5d543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b458244c",
   "metadata": {},
   "source": [
    "# Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58d89f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_hate_df = pd.read_csv(data_path+\"kaggle_hate_test.txt\", sep='\\t')\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(kaggle_hate_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1aa9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label =  kaggle_hate_df[\"hate\"].values\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f58812e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd9ddd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_CORAL_outputs/output/pytorch_model.bin'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 학습하고자하는 🤗 Transformers model                # 위에서 정의한 Training Arguments\n",
    "    eval_dataset=test_dataset           # 평가 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "081933e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 974\n",
      "  Batch size = 8\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122/122 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "979588cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = proba_to_label(torch.tensor(predictions.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b232044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>장현승 얘도 참 이젠 짠하다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>난 조보아 이뻐서 보는데 백종원 관심무</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  label\n",
       "0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ      0\n",
       "1                                        둘다 넘 좋다~행복하세요      0\n",
       "2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데      0\n",
       "3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요      0\n",
       "4                                   장현승 얘도 참 이젠 짠하다...      0\n",
       "..                                                 ...    ...\n",
       "969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹      0\n",
       "970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...      2\n",
       "971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...      0\n",
       "972                               입에 손가릭이 10개 있으니 징그럽다      2\n",
       "973                              난 조보아 이뻐서 보는데 백종원 관심무      0\n",
       "\n",
       "[974 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(preds_list)\n",
    "kaggle_df = pd.concat([kaggle_hate_df['comments'], pred_df[0]], axis=1)\n",
    "kaggle_df.columns = ['comments', 'label']\n",
    "kaggle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddf6320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv(\"kaggle_hate_KoELECTRA_CORAL2.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e8fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbca676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
