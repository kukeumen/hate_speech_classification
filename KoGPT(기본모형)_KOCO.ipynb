{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "MODEL_NAME= \"skt/kogpt2-base-v2\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME,\n",
    "                                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                                                    pad_token='<pad>', mask_token='<mask>') \n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39b0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='left', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21abbfd",
   "metadata": {},
   "source": [
    "# Load Koco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  hate\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...     2\n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...     0\n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...     2\n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데     0\n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...     2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_hate_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_hate_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"hate\"].values\n",
    "test_label =  koco_test_df[\"hate\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c0a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\13bb826cf24517d7849a701e02452715a67c5e560142be3d4735442b2a545809.6b384eec6effdd44287f67715cd55bd0dff2cf846d843b932b43ba7b632b8b1e\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/pytorch_model.bin from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\495b405e3742953dbcc56685d1560fa02a2d86fc50b891868990a4471b06c934.4ebf112d34c2c8fc657866680005d92d21859c52c0ef5e941fa640129b2f8f88\n",
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/', # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size=4,      # train batch_size 설정\n",
    "    per_device_eval_batch_size=32,      # test batch_size 설정\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/logs/',# 학습log 저장경로\n",
    "    logging_steps=500,                  # 학습log 기록 단위\n",
    "    save_total_limit=2,                 # 학습결과 저장 최대갯수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 학습하고자하는 🤗 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 Training Arguments\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30264903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 19:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.790600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.806600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.830500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.636700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.684900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.650300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.565700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.495600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.377400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.333100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.257400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.258200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.213200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.163800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoGPT2_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.500188995639604, metrics={'train_runtime': 1171.678, 'train_samples_per_second': 67.391, 'train_steps_per_second': 16.848, 'total_flos': 2579022214594560.0, 'train_loss': 0.500188995639604, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.444675326347351,\n",
       " 'eval_accuracy': 0.33970276008492567,\n",
       " 'eval_f1': 0.16904384574749076,\n",
       " 'eval_precision': 0.11323425336164189,\n",
       " 'eval_recall': 0.3333333333333333,\n",
       " 'eval_runtime': 0.5823,\n",
       " 'eval_samples_per_second': 808.919,\n",
       " 'eval_steps_per_second': 25.762,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoGPT2_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d8cdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.11067298e-05, 2.13789335e-05],\n",
       "       [6.87212408e-01, 4.34592992e-01],\n",
       "       [7.94084609e-01, 5.74312747e-01],\n",
       "       [7.96839297e-01, 5.78446805e-01],\n",
       "       [7.40468740e-01, 4.99537766e-01],\n",
       "       [9.99584854e-01, 9.98814225e-01],\n",
       "       [2.23854495e-05, 7.83162432e-06],\n",
       "       [7.06994615e-06, 2.47341973e-06],\n",
       "       [7.66569495e-01, 5.34640849e-01],\n",
       "       [7.54419088e-05, 2.63945167e-05],\n",
       "       [7.60500014e-01, 5.26267707e-01],\n",
       "       [7.69766688e-01, 5.39104760e-01],\n",
       "       [1.23281998e-05, 4.31303397e-06],\n",
       "       [7.76764095e-01, 5.49005330e-01],\n",
       "       [8.56163442e-01, 6.75579071e-01],\n",
       "       [1.08754230e-05, 3.80477468e-06],\n",
       "       [7.77717710e-01, 5.50368667e-01],\n",
       "       [9.99887824e-01, 9.99679565e-01],\n",
       "       [7.59631932e-01, 5.25080860e-01],\n",
       "       [3.04929999e-04, 1.06700390e-04],\n",
       "       [7.83443213e-01, 5.58626771e-01],\n",
       "       [1.06616353e-03, 3.73254356e-04],\n",
       "       [7.89253771e-01, 5.67136526e-01],\n",
       "       [6.75392091e-01, 4.21265692e-01],\n",
       "       [1.72750801e-02, 6.11230964e-03],\n",
       "       [2.46087293e-05, 8.60945784e-06],\n",
       "       [7.88091898e-01, 5.65424562e-01],\n",
       "       [9.99621630e-01, 9.98919368e-01],\n",
       "       [5.67115821e-05, 1.98411799e-05],\n",
       "       [7.72747934e-01, 5.43300807e-01],\n",
       "       [9.92245734e-01, 9.78150070e-01],\n",
       "       [1.05095631e-03, 3.67926812e-04],\n",
       "       [2.31516151e-05, 8.09967423e-06],\n",
       "       [1.01905047e-04, 3.56536693e-05],\n",
       "       [1.00377576e-04, 3.51192102e-05],\n",
       "       [7.60824561e-01, 5.26712179e-01],\n",
       "       [7.49608636e-01, 5.11565685e-01],\n",
       "       [1.18707176e-05, 4.15298200e-06],\n",
       "       [7.80505836e-01, 5.54374516e-01],\n",
       "       [1.29708962e-04, 4.53822868e-05],\n",
       "       [9.99407887e-01, 9.98309374e-01],\n",
       "       [9.99837399e-01, 9.99535561e-01],\n",
       "       [9.99832392e-01, 9.99521017e-01],\n",
       "       [1.39314964e-01, 5.35934009e-02],\n",
       "       [7.62993515e-01, 5.29691756e-01],\n",
       "       [6.83933729e-04, 2.39379471e-04],\n",
       "       [9.99678850e-01, 9.99082327e-01],\n",
       "       [6.55320327e-05, 2.29272446e-05],\n",
       "       [7.83004105e-01, 5.57989001e-01],\n",
       "       [7.78479934e-01, 5.51460862e-01],\n",
       "       [9.98778045e-01, 9.96515155e-01],\n",
       "       [7.68074751e-01, 5.36737859e-01],\n",
       "       [7.70010173e-01, 5.39446294e-01],\n",
       "       [7.68369377e-01, 5.37149251e-01],\n",
       "       [7.62165308e-01, 5.28552115e-01],\n",
       "       [7.91132808e-01, 5.69916904e-01],\n",
       "       [6.99770535e-05, 2.44824660e-05],\n",
       "       [7.60197937e-01, 5.25854409e-01],\n",
       "       [7.69074082e-01, 5.38134575e-01],\n",
       "       [5.63491903e-06, 1.97137388e-06],\n",
       "       [4.78592528e-06, 1.67435280e-06],\n",
       "       [8.07300270e-01, 5.94429553e-01],\n",
       "       [1.31289362e-05, 4.59317425e-06],\n",
       "       [7.88614810e-01, 5.66194355e-01],\n",
       "       [9.99820530e-01, 9.99487042e-01],\n",
       "       [2.17110573e-06, 7.59558645e-07],\n",
       "       [8.00267577e-01, 5.83634675e-01],\n",
       "       [7.53386378e-01, 5.16618907e-01],\n",
       "       [4.36603023e-06, 1.52745258e-06],\n",
       "       [9.99846458e-01, 9.99561489e-01],\n",
       "       [1.07092173e-05, 3.74662727e-06],\n",
       "       [4.42256260e-06, 1.54723011e-06],\n",
       "       [5.49002289e-06, 1.92068183e-06],\n",
       "       [9.55770135e-01, 8.83176684e-01],\n",
       "       [1.13103815e-05, 3.95694678e-06],\n",
       "       [5.01668728e-05, 1.75513633e-05],\n",
       "       [7.69563079e-01, 5.38819432e-01],\n",
       "       [8.48948002e-01, 6.62871957e-01],\n",
       "       [4.40566509e-06, 1.54131874e-06],\n",
       "       [7.82021105e-01, 5.56563854e-01],\n",
       "       [1.68204551e-05, 5.88467174e-06],\n",
       "       [6.90959215e-01, 4.38895047e-01],\n",
       "       [9.99656439e-01, 9.99018431e-01],\n",
       "       [7.54262149e-01, 5.17797470e-01],\n",
       "       [7.57773578e-01, 5.22548854e-01],\n",
       "       [7.60132849e-01, 5.25765419e-01],\n",
       "       [3.87591126e-06, 1.35598441e-06],\n",
       "       [9.74907744e-06, 3.41071927e-06],\n",
       "       [7.37965763e-01, 4.96291876e-01],\n",
       "       [7.97870815e-01, 5.80002725e-01],\n",
       "       [3.26482987e-05, 1.14221921e-05],\n",
       "       [2.66820338e-04, 9.33628253e-05],\n",
       "       [7.55366266e-01, 5.19286692e-01],\n",
       "       [9.99223709e-01, 9.97784436e-01],\n",
       "       [9.99436677e-01, 9.98391688e-01],\n",
       "       [1.26833504e-04, 4.43761419e-05],\n",
       "       [9.99891758e-01, 9.99690771e-01],\n",
       "       [9.99853134e-01, 9.99580204e-01],\n",
       "       [9.99881029e-01, 9.99660254e-01],\n",
       "       [9.46448982e-01, 8.60785007e-01],\n",
       "       [9.98614550e-01, 9.96050060e-01],\n",
       "       [8.16369474e-01, 6.08660698e-01],\n",
       "       [7.55946338e-01, 5.20070910e-01],\n",
       "       [7.56087661e-01, 5.20262241e-01],\n",
       "       [5.36458552e-01, 2.88196027e-01],\n",
       "       [9.90493953e-01, 9.73299801e-01],\n",
       "       [9.99804795e-01, 9.99442160e-01],\n",
       "       [8.52588928e-05, 2.98293271e-05],\n",
       "       [4.40532342e-04, 1.54163616e-04],\n",
       "       [3.28977621e-05, 1.15094708e-05],\n",
       "       [1.41103255e-05, 4.93651805e-06],\n",
       "       [9.90318251e-04, 3.46684508e-04],\n",
       "       [9.99835730e-01, 9.99530792e-01],\n",
       "       [7.35218525e-01, 4.92752463e-01],\n",
       "       [9.99420047e-01, 9.98343945e-01],\n",
       "       [7.52427220e-01, 5.15331328e-01],\n",
       "       [7.19533920e-01, 4.73000228e-01],\n",
       "       [7.76870310e-01, 5.49156904e-01],\n",
       "       [9.98192966e-01, 9.94852006e-01],\n",
       "       [9.84713376e-01, 9.57512081e-01],\n",
       "       [7.84285367e-05, 2.74394879e-05],\n",
       "       [6.96617007e-01, 4.45464045e-01],\n",
       "       [7.22860423e-05, 2.52903355e-05],\n",
       "       [9.98033345e-01, 9.94398892e-01],\n",
       "       [3.83919105e-05, 1.34316770e-05],\n",
       "       [6.41519455e-06, 2.24435394e-06],\n",
       "       [7.24376559e-01, 4.79017496e-01],\n",
       "       [9.99703348e-01, 9.99152780e-01],\n",
       "       [9.99626517e-01, 9.98933256e-01],\n",
       "       [6.56904936e-01, 4.01138574e-01],\n",
       "       [3.27872694e-05, 1.14708128e-05],\n",
       "       [1.47105320e-05, 5.14650310e-06],\n",
       "       [8.73261988e-01, 7.06792891e-01],\n",
       "       [7.61413872e-01, 5.27520120e-01],\n",
       "       [9.98554766e-01, 9.95880127e-01],\n",
       "       [1.10007750e-05, 3.84862915e-06],\n",
       "       [2.11471415e-04, 7.39930765e-05],\n",
       "       [2.15776745e-05, 7.54901794e-06],\n",
       "       [9.93165076e-01, 9.80708301e-01],\n",
       "       [7.57009864e-01, 5.21511793e-01],\n",
       "       [7.62856543e-01, 5.29503167e-01],\n",
       "       [7.62302876e-01, 5.28741241e-01],\n",
       "       [1.04555065e-05, 3.65786514e-06],\n",
       "       [5.29288718e-06, 1.85171382e-06],\n",
       "       [9.96882200e-01, 9.91139472e-01],\n",
       "       [1.20724608e-05, 4.22356243e-06],\n",
       "       [7.17809644e-06, 2.51125653e-06],\n",
       "       [8.97743046e-01, 7.54385412e-01],\n",
       "       [4.96769535e-05, 1.73799563e-05],\n",
       "       [7.95435786e-01, 5.76336741e-01],\n",
       "       [7.69254804e-01, 5.38387537e-01],\n",
       "       [9.98687804e-01, 9.96258497e-01],\n",
       "       [2.66421976e-05, 9.32088824e-06],\n",
       "       [8.51874113e-01, 6.67992830e-01],\n",
       "       [1.68828410e-05, 5.90649734e-06],\n",
       "       [9.99825656e-01, 9.99501705e-01],\n",
       "       [7.73298442e-01, 5.44079185e-01],\n",
       "       [2.95397931e-05, 1.03346429e-05],\n",
       "       [2.74031237e-03, 9.60405101e-04],\n",
       "       [7.67841756e-01, 5.36412716e-01],\n",
       "       [6.50632719e-05, 2.27632372e-05],\n",
       "       [4.16343119e-06, 1.45657316e-06],\n",
       "       [9.96273398e-01, 9.89421368e-01],\n",
       "       [7.90509522e-01, 5.68993092e-01],\n",
       "       [1.51925051e-04, 5.31559708e-05],\n",
       "       [3.34144424e-04, 1.16925250e-04],\n",
       "       [2.32473467e-05, 8.13316638e-06],\n",
       "       [7.55732238e-01, 5.19781411e-01],\n",
       "       [7.93609500e-01, 5.73602974e-01],\n",
       "       [7.69892573e-01, 5.39281368e-01],\n",
       "       [9.99859214e-01, 9.99597847e-01],\n",
       "       [1.06806683e-05, 3.73663943e-06],\n",
       "       [8.35700666e-06, 2.92370009e-06],\n",
       "       [7.82253742e-01, 5.56900799e-01],\n",
       "       [7.97178566e-01, 5.78958094e-01],\n",
       "       [9.99732077e-01, 9.99234676e-01],\n",
       "       [5.43639653e-05, 1.90198116e-05],\n",
       "       [1.40964057e-05, 4.93164816e-06],\n",
       "       [7.47630179e-01, 5.08938432e-01],\n",
       "       [9.75823164e-01, 9.33864832e-01],\n",
       "       [3.94918789e-06, 1.38162000e-06],\n",
       "       [7.62099147e-01, 5.28461099e-01],\n",
       "       [6.60122241e-05, 2.30952537e-05],\n",
       "       [5.67137977e-06, 1.98412977e-06],\n",
       "       [2.96749611e-04, 1.03837381e-04],\n",
       "       [1.18425060e-05, 4.14311216e-06],\n",
       "       [9.99585211e-01, 9.98815179e-01],\n",
       "       [9.70754147e-01, 9.20713544e-01],\n",
       "       [7.12241769e-01, 4.64072406e-01],\n",
       "       [7.13706640e-06, 2.49690174e-06],\n",
       "       [1.62541146e-05, 5.68653331e-06],\n",
       "       [5.14824816e-04, 1.80170871e-04],\n",
       "       [3.37210819e-02, 1.20617095e-02],\n",
       "       [5.20485155e-05, 1.82096974e-05],\n",
       "       [7.76170254e-01, 5.48157990e-01],\n",
       "       [2.17647303e-05, 7.61445972e-06],\n",
       "       [1.49006648e-02, 5.26397210e-03],\n",
       "       [4.06920211e-03, 1.42738025e-03],\n",
       "       [9.94911492e-01, 9.85591292e-01],\n",
       "       [9.97072697e-01, 9.91678119e-01],\n",
       "       [1.03267717e-04, 3.61304556e-05],\n",
       "       [7.59060204e-01, 5.24300516e-01],\n",
       "       [7.55082786e-01, 5.18903971e-01],\n",
       "       [1.69925042e-04, 5.94545527e-05],\n",
       "       [3.05803114e-04, 1.07005966e-04],\n",
       "       [7.34930218e-05, 2.57126321e-05],\n",
       "       [1.86976773e-04, 6.54214527e-05],\n",
       "       [9.99781787e-01, 9.99376476e-01],\n",
       "       [2.00511113e-06, 7.01485476e-07],\n",
       "       [7.45402038e-01, 5.05995452e-01],\n",
       "       [9.98097599e-01, 9.94581401e-01],\n",
       "       [7.92578518e-01, 5.72065473e-01],\n",
       "       [3.58496443e-04, 1.25448598e-04],\n",
       "       [9.87999856e-01, 9.66447175e-01],\n",
       "       [2.85589813e-05, 9.99149506e-06],\n",
       "       [9.99811709e-01, 9.99461949e-01],\n",
       "       [7.47411072e-01, 5.08648396e-01],\n",
       "       [9.87357497e-01, 9.64692473e-01],\n",
       "       [9.97936964e-01, 9.94125366e-01],\n",
       "       [7.89358914e-01, 5.67291796e-01],\n",
       "       [9.99080300e-01, 9.97375727e-01],\n",
       "       [8.13061059e-01, 6.03428006e-01],\n",
       "       [7.88112938e-01, 5.65455317e-01],\n",
       "       [7.85751343e-01, 5.61991394e-01],\n",
       "       [7.76894331e-01, 5.49191236e-01],\n",
       "       [7.77620196e-01, 5.50229073e-01],\n",
       "       [1.98704147e-04, 6.95252893e-05],\n",
       "       [2.23067273e-05, 7.80408300e-06],\n",
       "       [3.01190048e-05, 1.05372874e-05],\n",
       "       [5.47627568e-01, 2.97513723e-01],\n",
       "       [7.47260638e-04, 2.61554873e-04],\n",
       "       [9.99960899e-01, 9.99888301e-01],\n",
       "       [7.65370369e-01, 5.32976151e-01],\n",
       "       [2.53987557e-04, 8.88717841e-05],\n",
       "       [2.93880343e-01, 1.27097756e-01],\n",
       "       [8.22636939e-05, 2.87813455e-05],\n",
       "       [6.80251804e-04, 2.38090230e-04],\n",
       "       [7.77384222e-01, 5.49891472e-01],\n",
       "       [4.44101752e-05, 1.55372727e-05],\n",
       "       [2.64557784e-05, 9.25566746e-06],\n",
       "       [2.86303148e-05, 1.00164525e-05],\n",
       "       [9.99820769e-01, 9.99487877e-01],\n",
       "       [7.54507065e-01, 5.18127382e-01],\n",
       "       [9.99837160e-01, 9.99534726e-01],\n",
       "       [1.03010338e-04, 3.60403974e-05],\n",
       "       [7.39796669e-05, 2.58829023e-05],\n",
       "       [7.78911114e-01, 5.52079678e-01],\n",
       "       [7.66100566e-05, 2.68032327e-05],\n",
       "       [7.52367854e-01, 5.15251696e-01],\n",
       "       [8.11181486e-01, 6.00476384e-01],\n",
       "       [7.74017215e-01, 5.45097053e-01],\n",
       "       [1.46087832e-05, 5.11090639e-06],\n",
       "       [7.75439203e-01, 5.47116816e-01],\n",
       "       [5.33411958e-06, 1.86613909e-06],\n",
       "       [7.44518518e-01, 5.04833043e-01],\n",
       "       [6.68350086e-02, 2.44443044e-02],\n",
       "       [1.40603925e-06, 4.91900835e-07],\n",
       "       [3.06284259e-04, 1.07174346e-04],\n",
       "       [2.98785977e-04, 1.04550061e-04],\n",
       "       [5.26394724e-05, 1.84164583e-05],\n",
       "       [2.59885892e-05, 9.09221581e-06],\n",
       "       [1.42166400e-05, 4.97371275e-06],\n",
       "       [2.58760920e-05, 9.05285833e-06],\n",
       "       [4.52925706e-05, 1.58459934e-05],\n",
       "       [9.99503374e-01, 9.98581767e-01],\n",
       "       [4.41055447e-01, 2.16338173e-01],\n",
       "       [7.47420881e-06, 2.61485184e-06],\n",
       "       [7.51180778e-05, 2.62812136e-05],\n",
       "       [2.91459419e-05, 1.01968490e-05],\n",
       "       [7.68923819e-01, 5.37924409e-01],\n",
       "       [7.59230614e-01, 5.24533033e-01],\n",
       "       [8.61307263e-01, 6.84803426e-01],\n",
       "       [8.34248931e-05, 2.91876331e-05],\n",
       "       [9.99151111e-01, 9.97577608e-01],\n",
       "       [9.06394962e-06, 3.17102536e-06],\n",
       "       [3.86887632e-06, 1.35352309e-06],\n",
       "       [9.77965444e-03, 3.44329025e-03],\n",
       "       [7.45383877e-05, 2.60783891e-05],\n",
       "       [9.99802172e-01, 9.99434769e-01],\n",
       "       [9.98584032e-01, 9.95963216e-01],\n",
       "       [8.02647650e-01, 5.87264955e-01],\n",
       "       [1.92192838e-05, 6.72391661e-06],\n",
       "       [7.66169310e-01, 5.34084737e-01],\n",
       "       [7.87646055e-01, 5.64768910e-01],\n",
       "       [9.81036186e-01, 9.47639465e-01],\n",
       "       [8.94908862e-06, 3.13084092e-06],\n",
       "       [9.99752939e-01, 9.99294162e-01],\n",
       "       [2.30121304e-06, 8.05076468e-07],\n",
       "       [7.36572027e-01, 4.94493186e-01],\n",
       "       [7.72742629e-01, 5.43293297e-01],\n",
       "       [7.66195416e-01, 5.34121096e-01],\n",
       "       [1.20598376e-01, 4.57806997e-02],\n",
       "       [5.57466328e-01, 3.05897444e-01],\n",
       "       [7.75309741e-01, 5.46932578e-01],\n",
       "       [1.02687953e-03, 3.59492202e-04],\n",
       "       [7.77840734e-01, 5.50544918e-01],\n",
       "       [1.47461242e-05, 5.15895499e-06],\n",
       "       [7.69329011e-01, 5.38491428e-01],\n",
       "       [7.67738139e-03, 2.69939401e-03],\n",
       "       [7.69909024e-01, 5.39304376e-01],\n",
       "       [7.19941090e-06, 2.51871325e-06],\n",
       "       [9.99881744e-01, 9.99662042e-01],\n",
       "       [7.82515168e-01, 5.57279706e-01],\n",
       "       [1.35804730e-04, 4.75152447e-05],\n",
       "       [7.72372901e-01, 5.42771220e-01],\n",
       "       [2.42820848e-03, 8.50848155e-04],\n",
       "       [1.28197396e-04, 4.48533756e-05],\n",
       "       [5.04761636e-02, 1.82581916e-02],\n",
       "       [7.66724586e-01, 5.34856558e-01],\n",
       "       [7.68679142e-01, 5.37582219e-01],\n",
       "       [7.56807685e-01, 5.21237671e-01],\n",
       "       [4.02312689e-05, 1.40752063e-05],\n",
       "       [3.85708445e-05, 1.34942820e-05],\n",
       "       [1.26902369e-05, 4.43969429e-06],\n",
       "       [9.99582112e-01, 9.98806357e-01],\n",
       "       [1.26990501e-03, 4.44641395e-04],\n",
       "       [7.52716422e-01, 5.15719175e-01],\n",
       "       [4.33309360e-05, 1.51596796e-05],\n",
       "       [1.72843702e-05, 6.04697470e-06],\n",
       "       [9.99933243e-01, 9.99809444e-01],\n",
       "       [9.92903650e-01, 9.79980111e-01],\n",
       "       [9.99895692e-01, 9.99701917e-01],\n",
       "       [3.83203775e-01, 1.78546414e-01],\n",
       "       [1.64455894e-04, 5.75407539e-05],\n",
       "       [9.95437086e-01, 9.87067163e-01],\n",
       "       [7.49221325e-01, 5.11050344e-01],\n",
       "       [7.74673402e-01, 5.46028137e-01],\n",
       "       [9.99641418e-01, 9.98975754e-01],\n",
       "       [9.78597224e-01, 9.41163063e-01],\n",
       "       [7.73843110e-01, 5.44850409e-01],\n",
       "       [9.99585211e-01, 9.98815298e-01],\n",
       "       [7.92343497e-01, 5.71715772e-01],\n",
       "       [1.07623746e-04, 3.76546122e-05],\n",
       "       [7.65604377e-01, 5.33300698e-01],\n",
       "       [3.32789978e-06, 1.16426247e-06],\n",
       "       [7.96030819e-01, 5.77230394e-01],\n",
       "       [9.99866128e-01, 9.99617457e-01],\n",
       "       [7.67739475e-01, 5.36270082e-01],\n",
       "       [7.59449124e-01, 5.24831295e-01],\n",
       "       [7.58326709e-01, 5.23301244e-01],\n",
       "       [9.98454332e-01, 9.95594680e-01],\n",
       "       [7.53374636e-01, 5.16603053e-01],\n",
       "       [9.99747455e-01, 9.99278605e-01],\n",
       "       [7.60238826e-01, 5.25910318e-01],\n",
       "       [7.19516456e-01, 4.72978681e-01],\n",
       "       [1.95604938e-04, 6.84407496e-05],\n",
       "       [1.50716230e-02, 5.32496441e-03],\n",
       "       [9.99361455e-01, 9.98177052e-01],\n",
       "       [7.80607760e-01, 5.54521501e-01],\n",
       "       [9.83765312e-06, 3.44170758e-06],\n",
       "       [3.77645105e-04, 1.32150933e-04],\n",
       "       [9.99274194e-01, 9.97928143e-01],\n",
       "       [7.38990545e-01, 4.97618288e-01],\n",
       "       [7.87962112e-04, 2.75808474e-04],\n",
       "       [9.99579370e-01, 9.98798490e-01],\n",
       "       [2.95735692e-04, 1.03482518e-04],\n",
       "       [7.61117518e-01, 5.27113557e-01],\n",
       "       [1.03074402e-04, 3.60628183e-05],\n",
       "       [7.57240832e-01, 5.21825254e-01],\n",
       "       [7.72366166e-01, 5.42761624e-01],\n",
       "       [3.46877678e-05, 1.21357289e-05],\n",
       "       [7.89139628e-01, 5.66968262e-01],\n",
       "       [9.99801219e-01, 9.99431789e-01],\n",
       "       [7.67450929e-01, 5.35867810e-01],\n",
       "       [9.27829115e-06, 3.24601365e-06],\n",
       "       [4.95597837e-04, 1.73439912e-04],\n",
       "       [7.65445948e-01, 5.33080995e-01],\n",
       "       [7.71478355e-01, 5.41509926e-01],\n",
       "       [9.99879122e-01, 9.99654531e-01],\n",
       "       [6.19732646e-06, 2.16813260e-06],\n",
       "       [7.64400661e-01, 5.31633735e-01],\n",
       "       [4.25153339e-05, 1.48743256e-05],\n",
       "       [9.95958149e-01, 9.88533139e-01],\n",
       "       [8.19776237e-01, 6.14099383e-01],\n",
       "       [7.72939205e-01, 5.43571055e-01],\n",
       "       [1.40912918e-04, 4.93026528e-05],\n",
       "       [7.79982924e-01, 5.53620934e-01],\n",
       "       [1.22127065e-04, 4.27293344e-05],\n",
       "       [9.99879241e-01, 9.99654770e-01],\n",
       "       [3.64820153e-05, 1.27634721e-05],\n",
       "       [7.86939025e-01, 5.63730776e-01],\n",
       "       [9.83905852e-01, 9.55332637e-01],\n",
       "       [4.96328248e-05, 1.73645167e-05],\n",
       "       [5.34221954e-06, 1.86897284e-06],\n",
       "       [7.78591394e-01, 5.51620722e-01],\n",
       "       [7.70697057e-01, 5.40410757e-01],\n",
       "       [4.03258382e-05, 1.41082928e-05],\n",
       "       [9.11957860e-01, 7.83727646e-01],\n",
       "       [7.66633093e-01, 5.34729242e-01],\n",
       "       [9.99551833e-01, 9.98720288e-01],\n",
       "       [9.91414487e-01, 9.75844800e-01],\n",
       "       [6.47085399e-05, 2.26391221e-05],\n",
       "       [7.87757635e-01, 5.64932823e-01],\n",
       "       [7.87115335e-01, 5.63989460e-01],\n",
       "       [7.81825364e-01, 5.56280613e-01],\n",
       "       [7.81463563e-01, 5.55757284e-01],\n",
       "       [7.75684536e-01, 5.47465920e-01],\n",
       "       [8.38046617e-05, 2.93205121e-05],\n",
       "       [8.84674319e-06, 3.09503548e-06],\n",
       "       [7.63241291e-01, 5.30033171e-01],\n",
       "       [7.64701962e-01, 5.32050610e-01],\n",
       "       [7.61652827e-01, 5.27848005e-01],\n",
       "       [4.32386923e-06, 1.51270240e-06],\n",
       "       [9.97651279e-01, 9.93315637e-01],\n",
       "       [7.69876778e-01, 5.39259136e-01],\n",
       "       [2.06157929e-05, 7.21249535e-06],\n",
       "       [1.58640600e-04, 5.55058614e-05],\n",
       "       [1.70581134e-05, 5.96781729e-06],\n",
       "       [9.99701798e-01, 9.99148250e-01],\n",
       "       [3.42059345e-03, 1.19935710e-03],\n",
       "       [2.69151642e-05, 9.41638791e-06],\n",
       "       [3.35092220e-04, 1.17256975e-04],\n",
       "       [3.90153021e-01, 1.82884708e-01],\n",
       "       [7.62548625e-01, 5.29079139e-01],\n",
       "       [1.11186819e-05, 3.88987928e-06],\n",
       "       [7.48686254e-01, 5.10339200e-01],\n",
       "       [1.15655748e-05, 4.04622642e-06],\n",
       "       [2.46259824e-05, 8.61549506e-06],\n",
       "       [7.71399319e-01, 5.41398466e-01],\n",
       "       [7.63443750e-05, 2.67102732e-05],\n",
       "       [3.44158652e-05, 1.20405994e-05],\n",
       "       [9.99783099e-01, 9.99380112e-01],\n",
       "       [4.08745800e-05, 1.43002799e-05],\n",
       "       [7.57245600e-01, 5.21831751e-01],\n",
       "       [1.49198878e-03, 5.22477028e-04],\n",
       "       [7.67790437e-01, 5.36341131e-01],\n",
       "       [7.84627497e-01, 5.60350537e-01],\n",
       "       [4.74942817e-06, 1.66158418e-06],\n",
       "       [1.42912628e-04, 5.00023816e-05],\n",
       "       [8.48312557e-01, 6.61765456e-01],\n",
       "       [9.78923261e-01, 9.42025483e-01],\n",
       "       [2.45581788e-04, 8.59300708e-05],\n",
       "       [9.99772012e-01, 9.99348462e-01],\n",
       "       [7.63599992e-01, 5.30527949e-01],\n",
       "       [7.81207681e-01, 5.55387497e-01],\n",
       "       [7.72913933e-01, 5.43535352e-01],\n",
       "       [7.72375405e-01, 5.42774677e-01],\n",
       "       [7.65823126e-01, 5.33604085e-01],\n",
       "       [7.78190672e-01, 5.51046133e-01],\n",
       "       [9.88747597e-01, 9.68495131e-01],\n",
       "       [9.99547422e-01, 9.98707533e-01],\n",
       "       [1.71536740e-05, 6.00125031e-06],\n",
       "       [2.86919152e-04, 1.00396901e-04],\n",
       "       [7.82128751e-01, 5.56719840e-01],\n",
       "       [2.27028358e-05, 7.94266543e-06],\n",
       "       [7.58816183e-01, 5.23967803e-01],\n",
       "       [9.99600828e-01, 9.98859763e-01],\n",
       "       [2.02060747e-03, 7.07836181e-04],\n",
       "       [9.97059226e-01, 9.91639674e-01],\n",
       "       [1.24828011e-05, 4.36712162e-06],\n",
       "       [2.15432607e-04, 7.53792774e-05],\n",
       "       [3.09855886e-06, 1.08402764e-06],\n",
       "       [7.83908725e-01, 5.59303701e-01],\n",
       "       [9.99410272e-01, 9.98316288e-01],\n",
       "       [1.88880967e-05, 6.60804835e-06],\n",
       "       [1.79048693e-05, 6.26406063e-06],\n",
       "       [7.73761153e-01, 5.44734359e-01],\n",
       "       [7.45018423e-01, 5.05490363e-01],\n",
       "       [2.09228671e-03, 7.32980610e-04],\n",
       "       [8.48135387e-05, 2.96735088e-05],\n",
       "       [7.44796813e-01, 5.05198956e-01],\n",
       "       [4.48574747e-06, 1.56933550e-06],\n",
       "       [7.71082938e-01, 5.40953219e-01],\n",
       "       [9.86060381e-01, 9.61161375e-01],\n",
       "       [8.91045034e-01, 7.41006196e-01],\n",
       "       [1.71948031e-05, 6.01563852e-06],\n",
       "       [3.35761324e-05, 1.17468080e-05],\n",
       "       [7.71980882e-01, 5.42217970e-01],\n",
       "       [7.61335254e-01, 5.27412176e-01],\n",
       "       [9.99717176e-01, 9.99192178e-01],\n",
       "       [9.99423146e-01, 9.98352885e-01]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67       160\n",
      "           1       0.47      0.04      0.08       189\n",
      "           2       0.42      0.88      0.57       122\n",
      "\n",
      "    accuracy                           0.50       471\n",
      "   macro avg       0.50      0.56      0.44       471\n",
      "weighted avg       0.50      0.50      0.41       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEKCAYAAAAyx7/DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcJ0lEQVR4nO3deZwU5bn28d89g2wim+w7RhCRaFTEhUCICCIuqFEPxg23UY+CiB4xQWNyDIkefROXnIgEUVwOuB9xed0hEJRNxA1cUEBBEJAdBoaZuc8fXYwDzgw9TffUPO319VMfuquqq+6ZmIvHu56qNndHRETCkRN3ASIiUjkKbhGRwCi4RUQCo+AWEQmMgltEJDAKbhGRwCi4RUTSzMzGm9kqM/uo1Lo7zewTM/vAzJ4zs4altv3GzBaZ2admduKejq/gFhFJv4eBAbutex3o5u6HAp8BvwEws67AYOCQ6DN/N7Pcig6u4BYRSTN3nwas3W3da+5eGL2dCbSJXg8CJrn7dndfDCwCelR0/Bpprjdt6hx+jW7pzLAVb98TdwlZ78OvN8Zdwo9Cr86NbG+PUZnM2Tb/v68A8kqtGuvuYytxukuAJ6LXrUkE+U7LonXlqrbBLSJSXUUhXZmgLmFmo4BC4PFUz6/gFhEBsMx3js1sCHAK0Ne/f1DUcqBtqd3aROvKpR63iAhATm7ySwrMbABwI3Cau28ttWkyMNjMaplZR6ATMLuiY2nELSICYHvdJi91KJsI9AGamNky4FYSs0hqAa9b4lwz3f1Kd//YzJ4EFpBooVzt7kUVHV/BLSICaW2VuPu5Zax+sIL9RwOjkz2+gltEBNI64s40BbeICFTJxcl0UXCLiIBG3CIiwUlxtkgcFNwiIqBWiYhIcNQqEREJjEbcIiKBUXCLiAQmVxcnRUTCoh63iEhg1CoREQmMRtwiIoHRiFtEJDAacYuIBEa3vIuIBEatEhGRwKhVIiISGI24RUQCo+AWEQmMLk6KiARGPW4RkcCoVSIiEhiNuEVEwmIKbhGRsCi4RUQCYzkK7qwz5tbzOKl3N1av3UT3s/8EwJ+Gn87A3t0o2FHE4mVryLv1MTZszgfghkv6M2TQsRQVF3P9fz3NG+8sjLP84C1dsphRN44oeb98+TLyrhrKuedfGGNV4dtRsJ07brqKwh0FFBcVcWTP4xl03uU8fO9olny+EMdp0aodFw+/hdp16sZdbkaFNOI2d4+7hjLVOfyaalVYzyN+wpat2xl324Ulwd33mC5MnfMZRUXF/HHYIABuvvd5uhzQggl/HkKv8++iZdMGvDzmGn56+n9SXFytfiRWvH1P3CWkpKioiFP692H8o5No2ap13OVU6MOvN8ZdQoXcne3b8qldpy6FhYXcMTKPwZePoFW7jtSpuy8AT4y7m/0aNGbg2dX3L8lenRvtderWH/xI0v8H3TjpwlhTPpz5LzGbMe8L1m7Yusu6N2d+QlFRMQCzP1xM6+YNATilz6E89eo8CnYUsvSb7/ji6zUc1a1DFVecvebMmkmbNu2qfWiHwMxKRtJFhYUUFRZiRklouzsFBdtDmnCRMjNLekniWOPNbJWZfVRqXWMze93MPo/+bBStNzO718wWmdkHZnbEno6v4E6TCwcdy6szFgDQumkDlq1cV7Jt+ap1tGrWIK7Sss7rr75M/5MGxl1G1iguKuIPwy5gxAUn0fXwHhxwUDcAxt99GyMuHMjKZUs5/pRzYq6yClgllj17GBiw27qbgDfdvRPwZvQe4CSgU7TkAffv6eAZC24z62JmI6O/Se6NXh+cqfPF6cZLT6SoqJhJL8+Ju5Sst2NHAdP/OYXj+50YdylZIyc3l1vvfZQ7H5rM4s8WsHzpFwBcMvwW/t/DL9KyTQfm/OuNmKvMvHSOuN19GrB2t9WDgAnR6wnA6aXWP+IJM4GGZtayouNnJLjNbCQwicTfTbOjxYCJZnZTBZ/LM7O5Zja3cM3HmSgt7c4/9WgG9u7GkFEPl6xbvnoDbVo0Knnfulkjvlm1IYbqss/b/5rOQV26sv/+TeIuJevUrbcfXX56JB+9O7NkXU5uLj1692PejCkxVlY1cnJykl5KZ1W05CVxiubuviJ6vRJoHr1uDXxdar9l0brya630T5ecS4Gj3P12d38sWm4HekTbyuTuY929u7t3r9HkkAyVlj79jjuYEUNO4KzhD5C/bUfJ+pemfsDZJx5BzX1q0L7V/hzYrilzPloSX6FZ5LVXXqb/ALVJ0mXThnVs3bwJgILt21gwfzbN27Tj228SOeLuzJ81nRZt2sdZZpWozIi7dFZFy9jKnMsTs0JSnq2QqemAxUArYOlu61tG24Iz4c9D6HVkJ5o0rMeiV27jtjEv8x8X96dWzRq8eP81AMz+cAnDRk9i4Zcreea193jvmVEUFhUz/PYnq92MkhDl529l9sy3+c3Nv4+7lKyxfu0axt99G8XFRXixc9TP+3Jo957ccdMVbNu6FXenbccDOf/fR8ZdauZl/gLst2bW0t1XRK2QVdH65UDbUvu1idaVKyPTAc1sAPA34HO+/0+AdsCBwDXu/sqejlHdpgNmo1CnA4akuk8HzBbpmA7YZMikpDNnzcOD93g+M+sAvOju3aL3dwLfufvtUcu4sbvfaGYnA9cAA4GjgXvdvUdFx87IiNvdXzGzziRaIzt7NcuBOe5elIlziojsjXTegGNmE4E+QBMzWwbcCtwOPGlml5LoRuycqvMyidBeBGwFLt7T8TN256S7FwMz97ijiEg1kM5b3t393HI29S1jXweurszxdcu7iAhh3fKu4BYRQcEtIhIcBbeISGAU3CIioQkntxXcIiKQuOU9FApuERHUKhERCU84ua3gFhEBjbhFRIKj4BYRCYyCW0QkMOl8VkmmKbhFRNCIW0QkOApuEZHABJTbCm4REdCIW0QkODm6OCkiEpaABtwKbhER0IhbRCQ4GnGLiARGFydFRAITUG4ruEVEQF+kICISHI24RUQCox63iEhgAsptBbeICGjELSISnIBym3Auo4qIZFBOjiW97ImZXWdmH5vZR2Y20cxqm1lHM5tlZovM7Akzq5lqrdV2xH3miMviLiHrFRfHXUH263/ZPXGX8KOQP+33e32MdLVKzKw1MAzo6u75ZvYkMBgYCPzV3SeZ2RjgUuD+VM6hEbeICIlWSbJLEmoAdcysBlAXWAEcDzwdbZ8AnJ5qrQpuERESI+5KLHlmNrfUkrfzOO6+HLgL+IpEYG8A3gXWu3thtNsyoHWqtVbbVomISFWqTKfE3ccCY8s+jjUCBgEdgfXAU8CAvS6wFAW3iAhpfazrCcBid18NYGbPAj2BhmZWIxp1twGWp3oCtUpERKhcq2QPvgKOMbO6lti5L7AAmAKcFe1zEfB8qrUquEVESF9wu/ssEhch5wEfksjZscBIYISZLQL2Bx5MtVa1SkRESO8NOO5+K3Drbqu/BHqk4/gKbhERdMu7iEhwAsptBbeICOjLgkVEgpMT0JBbwS0iglolIiLB0cVJEZHABNTiVnCLiIAuToqIBMdQcIuIBCWgAbeCW0QEdHFSRCQ4AeW2gltEBHQDjohIcDSrREQkMAENuBXcIiKgVomISHDCie0KgtvM7gO8vO3uPiwjFYmIxCBbpgPOrbIqRERiFtC1yfKD290nVGUhIiJxyqpZJWbWlMS3E3cFau9c7+7HZ7AuEZEqFVKrJCeJfR4HFgIdgT8AS4A5GaxJRKTK5VjyS9ySCe793f1BYIe7/9PdLwE02haRrGJmSS9xS2Y64I7ozxVmdjLwDdA4cyWJiFS9+OM4eckE9x/NrAFwPXAfUB+4LqNViYhUsdzq0ANJ0h6D291fjF5uAH6Z2XLCUXefXC4/ti1tGtbGgbFvf8VJBzelZf3E9du6NXPZWlDEb1/6NN5Cs8jExybwwv8+jZnxkwM7M+r3o6lVq1bcZQVnzMhBnHRcZ1av20L3IX8H4Mw+XRl1cR+6tG9Kryv+wbxPv9nlM22bNWDeI1cz+uGp3D3p7Riqzrzq0AJJVjKzSh6ijBtxol73j9YFR7Xm/W82cs+0JeTmGLVyc7hv+tKS7ecd2YqtBUUxVphdVq36lqcmPcb/PP0CtWvXZtTI63jj1Zc5+bQz4i4tOI++Mp8xz81m3G+//919vHgVg29+gr/dcGqZn7njmhN5bdbnVVViLALK7aRaJS+Wel0bOINEn/tHq84+OXRpvi8PvP0VAEXFztbiXUP66PYNGf36ojjKy1pFRUVs376NGjVqsC1/G02aNou7pCDNeH8p7Vo03GXdp0vXlLv/qT/vwpIV69iybUe5+2SDrHpWibs/U/q9mU0E/pWxigLQrF4tNm0r5Irj2tGuUW0Wf5fPo3OXs72wGIAuzfZlw7ZCvt1UEHOl2aNZs+b8+oKLOWNgX2rVqk2PY4/j6GN7xl1W1tu3Tk2u/3VPTr7+UYYPPi7ucjIqnbltZg2BcUA3Eh2LS4BPgSeADiSmVZ/j7utSOX4y0wF31wlIeahjZhdXsC3PzOaa2dxFU54pb7fY5Rh0aFyXNz5bw6iXPmN7YTGnHvL9r+TYDo14Z3FK/3tIOTZu3MD0qW/xzIuv88KrU9mWn88rL02Ou6ysd/PFfbjvqZlsyc/+QUiapwPeA7zi7l2Aw0jcC3MT8Ka7dwLejN6nJJke9yZ27XGvJHEnZar+ADxU1gZ3HwuMBTjv0fnlPuAqbmu37mDt1h18sWYrALO/Wl8S3DkGR7VrwM0vfxZniVlnzqx3aNm6NY0aJWai/uL4fnz4wXwGnHxazJVlt6MObs0Zv+jK6Cv70aBebYrd2VZQyJhnZ8ddWtrlpmnIHc3C6w0MAXD3AqDAzAYBfaLdJgBTSTFLk2mV7FfZg5rZB+VtAppX9njVzYZthXy3pYCW9WuxYuN2DmmxH8s3bAegW8v9+GbjdtZuze5+YFVr0aIlH3/4Ptvy86lVuzZzZ8/k4K6HxF1W1jth6PdjrFEX92FLfkFWhjZU7o5IM8sD8kqtGhsNPCFxl/lq4CEzOwx4F7gWaO7uK6J9VrIXWZjMiPtNd++7p3W7aQ6cCOzeLzAgK+YSPTJnOf/+8/bUyDFWbS4ouVCpNklmHPLTw/hl3/5cdN5Z1MjNpfNBBzPozHPiLitIE373K3od3oEmDeqy6OkR3PbQFNZtzOcv1w6kScO6PHvHr/lg0UpOu+GxuEutUpUJ7tLdgTLUAI4Ahrr7LDO7h93aIu7uZpZyV6Gi53HXBuoCTcysEd/fWFQfaL2H474I1HP3+WUcd2pKlVYzS9flc0sZ7ZCdAS7pd/lVQ7n8qqFxlxG8i/6z7OtHk6d/UuHnRj80NQPVVB9pnMe9DFjm7rOi90+TCO5vzaylu68ws5bAqlRPUNGI+wpgONCKxFB/50+1EfhbRQd190sr2PbrypUoIpJ56bpx0t1XmtnXZnaQu38K9AUWRMtFwO3Rn8+neo6Knsd9D3CPmQ119/tSPYGISAjSPI17KPC4mdUEvgQuJjGL70kzuxRYCqTc60vmBpxiM2vo7usBorbJue7+91RPKiJS3dRIY3JHbeLuZWyq6Npg0pKZx335ztCOCloHXJ6Ok4uIVBdmyS9xS2bEnWtm5u4OYGa5QM3MliUiUrWy6pZ34BXgCTN7IHp/BfD/M1eSiEjVCyi3kwrukSQmml8Zvf8AaJGxikREYhDQ47iTunOy2MxmAT8hcRW0CVB9HyQiIpKCrPgiBTPrDJwbLWtIPNUKd9eXKYhI1gkotysccX8CTAdOcfdFAGamrywTkaxkAX3rZEXTAc8EVgBTzOwfZtaXsL5PU0QkaTmW/BK3coPb3f/X3QcDXYApJG5/b2Zm95tZ/yqqT0SkSmRFcO/k7lvc/X/c/VSgDfAee/c8bhGRaifNX6SQUclMBywR3TVZ0eMMRUSClJvK94HFpFLBLSKSrbLtzkkRkaxXHXrXyVJwi4iQfbe8i4hkvZyAZjsruEVE0IhbRCQ4NQJqciu4RUTQiFtEJDiaDigiEpiAclvBLSICyX0Bb3Wh4BYRQa0SEZHgKLhFRAITTmwruEVEAF2cFBEJTnV4znayFNwiImhWiYhIcHRxMg3uPLVr3CVkvbq1cuMuIfs1bB53BZKkdLdKzCwXmAssd/dTzKwjMAnYH3gXuMDdC1I5dkj/dSAikjE5lViSdC2wsNT7O4C/uvuBwDrg0r2pVUTkRy+dXxZsZm2Ak4Fx0XsDjgeejnaZAJyeaq0KbhEREvO4k17M8sxsbqklb7fD3Q3cCBRH7/cH1rt7YfR+GdA61VqrbY9bRKQq5Vaix+3uY4GxZW0zs1OAVe7+rpn1SUtxu1Fwi4iQ1htwegKnmdlAoDZQH7gHaGhmNaJRdxtgeaonUKtERASwSvxTEXf/jbu3cfcOwGDgLXc/D5gCnBXtdhHwfKq1KrhFREiMuJNdUjQSGGFmi0j0vB9M9UBqlYiIkJlveXf3qcDU6PWXQI90HFfBLSKCHjIlIhIc3fIuIhKYnHByW8EtIgLscbZIdaLgFhFBPW4RkeBoxC0iEhj1uEVEAqNZJSIigQknthXcIiKARtwiIsEJJ7YV3CIiCQElt4JbRAS1SkREghNObCu4RUQSAkpuBbeICLpzUkQkOAG1uBXcIiIQVKdEwS0iAmABDbkV3CIiqFUiIhKcgHJbwS0iAgSV3ApuERE0HfBH4Y7bbmHmjGk0bNSYhyY+B8D4MfcxY/oUzHJo1KgxI3/3R5o0bRZzpdlh5YoVjPrNjaz97jsw46yzz+G8Cy6Ku6wgjRnWh5O6d2D1hny6D30CgEb1avHojf1o32w/lq7axPl3vMb6LQVcd8bP+LdfdAKgRm4OXdo0pO0FD7Nu8/Y4f4SMCKnHbe4edw1l+mZ9QfUsLPL+e3OpU6cuf/7DqJLg3rJ5M/vWqwfAM088ztLFXzDipt/FWWaFGterGXcJSVu9ehVrVq/m4K6HsGXLZgaf/Svuvve/+cmBB8ZdWoUanXl/3CX8QM9DWrIlfwfjrutbEtyjhxzDuk3bueuZ97jhV4fTsF4tbp4wc5fPDTyqPUMHHcZJN0+Oo+wK5U++aq9j96Plm5POnG6t68Ua8zlxnjxkhx3enfr1G+yybmdoA2zLzw9qelF117RpMw7ueggA++5bjwMOOIBVq76Nuaowzfh4BWt3GzGf0qMjj731KQCPvfUppx7d8QefO6d3J56c9nmV1BgHq8Q/cVOrJM3G3X8vr708mX3r7cdf//5g3OVkpeXLl/HJwoX89NDD4i4lazRrWIeV67YCsHLdVpo1rLPL9jo1a9DviLZc98D0OMqrEiGNszI24jazLmbW18zq7bZ+QKbOWR1cdtUwnnzhDU448WSee2pi3OVkna1btnD98GH8x02/pV69env+gKRk957ByT3a887ClVnZ297JKrFUeByztmY2xcwWmNnHZnZttL6xmb1uZp9HfzZKtdaMBLeZDQOeB4YCH5nZoFKb/1TB5/LMbK6ZzX3s4XGZKK3KnDDgZKZNeSPuMrLKjh07GDF8GANPPpUT+vWPu5yssmp9Pi0a1QWgRaO6rF6fv8v2s3sdyFPTFsVRWtVJV3JDIXC9u3cFjgGuNrOuwE3Am+7eCXgzep+STI24LweOdPfTgT7ALTv/1qGCH9vdx7p7d3fvfv6QyzJUWuYs+2ppyesZ096iXfsf9gklNe7O7383igMOOIALh1wcdzlZ56XZSzj/+IMAOP/4g3hx9uKSbfXr1uTn3VrxwqzF5X08K+SYJb1UxN1XuPu86PUmYCHQGhgETIh2mwCcnmqtmepx57j7ZgB3X2JmfYCnzaw9QU1zL99tN9/I/Hlz2LB+PWef0pcheVcza8Z0vv5qCTk5RvMWrbhu5C1xl5k13pv3Li9Ofp5OnTtzzpmJ/4AbOnwEvXr/IubKwjPhhhPo1a0VTerXZtH4C7ht4hzuemYej93Yn4v6deGrVZs5/79eK9n/tGM68uZ7X7N1e2GMVWdeJoLJzDoAhwOzgObuviLatBJonvJxMzEd0MzeAka4+/xS62oA44Hz3D13T8eo7tMBs0FI0wFDVR2nA2ajdEwH/OzbrUlnzkEt9r0CyCu1aqy7jy29T3R975/AaHd/1szWu3vDUtvXuXtKfe5MjbgvJNHnKeHuhcCFZvZAhs4pIpKyykzzi0J6bHnbzWwf4BngcXd/Nlr9rZm1dPcVZtYSWJVqrRnpcbv7MndfWc62GZk4p4jI3jBLfqn4OGbAg8BCd/9LqU2TgZ23+15EYgJHSjSPW0SEtPa4ewIXAB+a2fxo3W+B24EnzexSYClwTqonUHCLiJC+L1Jw939R/t8DfdNxDgW3iAhh3Tmp4BYRIax5ygpuEREIKrkV3CIi6IsURESCox63iEhgchTcIiKhCSe5FdwiIqhVIiISnIByW8EtIgIacYuIBCekL/dWcIuIoFaJiEhwAhpwK7hFREB3ToqIhCec3FZwi4hAULmt4BYRAcgJqMmt4BYRIayLkxn5smAREckcjbhFRAhrxK3gFhFB0wFFRIKjEbeISGAU3CIigVGrREQkMBpxi4gEJqDcVnCLiABBJbeCW0SEsG55N3ePu4asYWZ57j427jqymX7HmaffcfWnW97TKy/uAn4E9DvOPP2OqzkFt4hIYBTcIiKBUXCnl/qCmaffcebpd1zN6eKkiEhgNOIWEQmMgltEJDAK7jQwswFm9qmZLTKzm+KuJxuZ2XgzW2VmH8VdS7Yys7ZmNsXMFpjZx2Z2bdw1SdnU495LZpYLfAb0A5YBc4Bz3X1BrIVlGTPrDWwGHnH3bnHXk43MrCXQ0t3nmdl+wLvA6fp3ufrRiHvv9QAWufuX7l4ATAIGxVxT1nH3acDauOvIZu6+wt3nRa83AQuB1vFWJWVRcO+91sDXpd4vQ/+yS+DMrANwODAr5lKkDApuEdmFmdUDngGGu/vGuOuRH1Jw773lQNtS79tE60SCY2b7kAjtx9392bjrkbIpuPfeHKCTmXU0s5rAYGByzDWJVJqZGfAgsNDd/xJ3PVI+BfdecvdC4BrgVRIXc55094/jrSr7mNlE4B3gIDNbZmaXxl1TFuoJXAAcb2bzo2Vg3EXJD2k6oIhIYDTiFhEJjIJbRCQwCm4RkcAouEVEAqPgFhEJjIJbqpSZFUXTzD4ys6fMrO5eHOthMzsrej3OzLpWsG8fMzsu1XOJVCcKbqlq+e7+s+gJfwXAlaU3mlmNVA7q7pft4Sl2fQAFt2QFBbfEaTpwYDQanm5mk4EFZpZrZnea2Rwz+8DMroDEnX1m9rfo2edvAM12HsjMpppZ9+j1ADObZ2bvm9mb0QOTrgSui0b7var+RxVJn5RGNyJ7KxpZnwS8Eq06Aujm7ovNLA/Y4O5HmVktYIaZvUbiaXUHAV2B5sACYPxux20K/APoHR2rsbuvNbMxwGZ3v6tKfkCRDFJwS1WrY2bzo9fTSTwb4zhgtrsvjtb3Bw7d2b8GGgCdgN7ARHcvAr4xs7fKOP4xwLSdx3J3PcNbso6CW6pavrv/rPSKxLON2FJ6FTDU3V/dbT89N0ME9bilenoVuCp6xChm1tnM9gWmAf8W9cBbAr8s47Mzgd5m1jH6bONo/SZgv8yXLpJ5Cm6pjsaR6F/Pi74c+AES/3X4HPB5tO0REk8L3IW7rwbygGfN7H3giWjTC8AZujgp2UBPBxQRCYxG3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhKY/wP+AKXGBEe9HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = proba_to_label(torch.tensor(predictions.predictions))\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62fecc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a74356",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1,\n",
    "       1, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 2, 2, 1,\n",
    "       1, 0, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0,\n",
    "       1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 1, 0, 0,\n",
    "       1, 0, 0, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0,\n",
    "       0, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0,\n",
    "       1, 1, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 2, 1, 2, 1, 2, 0, 1,\n",
    "       0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2,\n",
    "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
    "       2, 1, 1, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1,\n",
    "       1, 1, 0, 1, 1, 1, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 1, 1, 0, 0, 0, 2,\n",
    "       1, 2, 0, 2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       2, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 2, 0,\n",
    "       2, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 2, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1,\n",
    "       2, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 2,\n",
    "       1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 1,\n",
    "       0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2,\n",
    "       0, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       2, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 2, 0, 2, 1, 1, 1, 1, 2,\n",
    "       1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0,\n",
    "       1, 1, 2, 0, 0, 1, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4820)\n",
      "tensor(0.5796)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f16cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca61759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.4, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ca7af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66       160\n",
      "           1       0.55      0.52      0.53       189\n",
      "           2       0.69      0.52      0.60       122\n",
      "\n",
      "    accuracy                           0.60       471\n",
      "   macro avg       0.61      0.60      0.60       471\n",
      "weighted avg       0.60      0.60      0.59       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e469c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6221)\n",
      "tensor(0.8386)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "66073d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[6.11067298e-05, 2.13789335e-05],\n",
       "       [6.87212408e-01, 4.34592992e-01],\n",
       "       [7.94084609e-01, 5.74312747e-01],\n",
       "       [7.96839297e-01, 5.78446805e-01],\n",
       "       [7.40468740e-01, 4.99537766e-01],\n",
       "       [9.99584854e-01, 9.98814225e-01],\n",
       "       [2.23854495e-05, 7.83162432e-06],\n",
       "       [7.06994615e-06, 2.47341973e-06],\n",
       "       [7.66569495e-01, 5.34640849e-01],\n",
       "       [7.54419088e-05, 2.63945167e-05],\n",
       "       [7.60500014e-01, 5.26267707e-01],\n",
       "       [7.69766688e-01, 5.39104760e-01],\n",
       "       [1.23281998e-05, 4.31303397e-06],\n",
       "       [7.76764095e-01, 5.49005330e-01],\n",
       "       [8.56163442e-01, 6.75579071e-01],\n",
       "       [1.08754230e-05, 3.80477468e-06],\n",
       "       [7.77717710e-01, 5.50368667e-01],\n",
       "       [9.99887824e-01, 9.99679565e-01],\n",
       "       [7.59631932e-01, 5.25080860e-01],\n",
       "       [3.04929999e-04, 1.06700390e-04],\n",
       "       [7.83443213e-01, 5.58626771e-01],\n",
       "       [1.06616353e-03, 3.73254356e-04],\n",
       "       [7.89253771e-01, 5.67136526e-01],\n",
       "       [6.75392091e-01, 4.21265692e-01],\n",
       "       [1.72750801e-02, 6.11230964e-03],\n",
       "       [2.46087293e-05, 8.60945784e-06],\n",
       "       [7.88091898e-01, 5.65424562e-01],\n",
       "       [9.99621630e-01, 9.98919368e-01],\n",
       "       [5.67115821e-05, 1.98411799e-05],\n",
       "       [7.72747934e-01, 5.43300807e-01],\n",
       "       [9.92245734e-01, 9.78150070e-01],\n",
       "       [1.05095631e-03, 3.67926812e-04],\n",
       "       [2.31516151e-05, 8.09967423e-06],\n",
       "       [1.01905047e-04, 3.56536693e-05],\n",
       "       [1.00377576e-04, 3.51192102e-05],\n",
       "       [7.60824561e-01, 5.26712179e-01],\n",
       "       [7.49608636e-01, 5.11565685e-01],\n",
       "       [1.18707176e-05, 4.15298200e-06],\n",
       "       [7.80505836e-01, 5.54374516e-01],\n",
       "       [1.29708962e-04, 4.53822868e-05],\n",
       "       [9.99407887e-01, 9.98309374e-01],\n",
       "       [9.99837399e-01, 9.99535561e-01],\n",
       "       [9.99832392e-01, 9.99521017e-01],\n",
       "       [1.39314964e-01, 5.35934009e-02],\n",
       "       [7.62993515e-01, 5.29691756e-01],\n",
       "       [6.83933729e-04, 2.39379471e-04],\n",
       "       [9.99678850e-01, 9.99082327e-01],\n",
       "       [6.55320327e-05, 2.29272446e-05],\n",
       "       [7.83004105e-01, 5.57989001e-01],\n",
       "       [7.78479934e-01, 5.51460862e-01],\n",
       "       [9.98778045e-01, 9.96515155e-01],\n",
       "       [7.68074751e-01, 5.36737859e-01],\n",
       "       [7.70010173e-01, 5.39446294e-01],\n",
       "       [7.68369377e-01, 5.37149251e-01],\n",
       "       [7.62165308e-01, 5.28552115e-01],\n",
       "       [7.91132808e-01, 5.69916904e-01],\n",
       "       [6.99770535e-05, 2.44824660e-05],\n",
       "       [7.60197937e-01, 5.25854409e-01],\n",
       "       [7.69074082e-01, 5.38134575e-01],\n",
       "       [5.63491903e-06, 1.97137388e-06],\n",
       "       [4.78592528e-06, 1.67435280e-06],\n",
       "       [8.07300270e-01, 5.94429553e-01],\n",
       "       [1.31289362e-05, 4.59317425e-06],\n",
       "       [7.88614810e-01, 5.66194355e-01],\n",
       "       [9.99820530e-01, 9.99487042e-01],\n",
       "       [2.17110573e-06, 7.59558645e-07],\n",
       "       [8.00267577e-01, 5.83634675e-01],\n",
       "       [7.53386378e-01, 5.16618907e-01],\n",
       "       [4.36603023e-06, 1.52745258e-06],\n",
       "       [9.99846458e-01, 9.99561489e-01],\n",
       "       [1.07092173e-05, 3.74662727e-06],\n",
       "       [4.42256260e-06, 1.54723011e-06],\n",
       "       [5.49002289e-06, 1.92068183e-06],\n",
       "       [9.55770135e-01, 8.83176684e-01],\n",
       "       [1.13103815e-05, 3.95694678e-06],\n",
       "       [5.01668728e-05, 1.75513633e-05],\n",
       "       [7.69563079e-01, 5.38819432e-01],\n",
       "       [8.48948002e-01, 6.62871957e-01],\n",
       "       [4.40566509e-06, 1.54131874e-06],\n",
       "       [7.82021105e-01, 5.56563854e-01],\n",
       "       [1.68204551e-05, 5.88467174e-06],\n",
       "       [6.90959215e-01, 4.38895047e-01],\n",
       "       [9.99656439e-01, 9.99018431e-01],\n",
       "       [7.54262149e-01, 5.17797470e-01],\n",
       "       [7.57773578e-01, 5.22548854e-01],\n",
       "       [7.60132849e-01, 5.25765419e-01],\n",
       "       [3.87591126e-06, 1.35598441e-06],\n",
       "       [9.74907744e-06, 3.41071927e-06],\n",
       "       [7.37965763e-01, 4.96291876e-01],\n",
       "       [7.97870815e-01, 5.80002725e-01],\n",
       "       [3.26482987e-05, 1.14221921e-05],\n",
       "       [2.66820338e-04, 9.33628253e-05],\n",
       "       [7.55366266e-01, 5.19286692e-01],\n",
       "       [9.99223709e-01, 9.97784436e-01],\n",
       "       [9.99436677e-01, 9.98391688e-01],\n",
       "       [1.26833504e-04, 4.43761419e-05],\n",
       "       [9.99891758e-01, 9.99690771e-01],\n",
       "       [9.99853134e-01, 9.99580204e-01],\n",
       "       [9.99881029e-01, 9.99660254e-01],\n",
       "       [9.46448982e-01, 8.60785007e-01],\n",
       "       [9.98614550e-01, 9.96050060e-01],\n",
       "       [8.16369474e-01, 6.08660698e-01],\n",
       "       [7.55946338e-01, 5.20070910e-01],\n",
       "       [7.56087661e-01, 5.20262241e-01],\n",
       "       [5.36458552e-01, 2.88196027e-01],\n",
       "       [9.90493953e-01, 9.73299801e-01],\n",
       "       [9.99804795e-01, 9.99442160e-01],\n",
       "       [8.52588928e-05, 2.98293271e-05],\n",
       "       [4.40532342e-04, 1.54163616e-04],\n",
       "       [3.28977621e-05, 1.15094708e-05],\n",
       "       [1.41103255e-05, 4.93651805e-06],\n",
       "       [9.90318251e-04, 3.46684508e-04],\n",
       "       [9.99835730e-01, 9.99530792e-01],\n",
       "       [7.35218525e-01, 4.92752463e-01],\n",
       "       [9.99420047e-01, 9.98343945e-01],\n",
       "       [7.52427220e-01, 5.15331328e-01],\n",
       "       [7.19533920e-01, 4.73000228e-01],\n",
       "       [7.76870310e-01, 5.49156904e-01],\n",
       "       [9.98192966e-01, 9.94852006e-01],\n",
       "       [9.84713376e-01, 9.57512081e-01],\n",
       "       [7.84285367e-05, 2.74394879e-05],\n",
       "       [6.96617007e-01, 4.45464045e-01],\n",
       "       [7.22860423e-05, 2.52903355e-05],\n",
       "       [9.98033345e-01, 9.94398892e-01],\n",
       "       [3.83919105e-05, 1.34316770e-05],\n",
       "       [6.41519455e-06, 2.24435394e-06],\n",
       "       [7.24376559e-01, 4.79017496e-01],\n",
       "       [9.99703348e-01, 9.99152780e-01],\n",
       "       [9.99626517e-01, 9.98933256e-01],\n",
       "       [6.56904936e-01, 4.01138574e-01],\n",
       "       [3.27872694e-05, 1.14708128e-05],\n",
       "       [1.47105320e-05, 5.14650310e-06],\n",
       "       [8.73261988e-01, 7.06792891e-01],\n",
       "       [7.61413872e-01, 5.27520120e-01],\n",
       "       [9.98554766e-01, 9.95880127e-01],\n",
       "       [1.10007750e-05, 3.84862915e-06],\n",
       "       [2.11471415e-04, 7.39930765e-05],\n",
       "       [2.15776745e-05, 7.54901794e-06],\n",
       "       [9.93165076e-01, 9.80708301e-01],\n",
       "       [7.57009864e-01, 5.21511793e-01],\n",
       "       [7.62856543e-01, 5.29503167e-01],\n",
       "       [7.62302876e-01, 5.28741241e-01],\n",
       "       [1.04555065e-05, 3.65786514e-06],\n",
       "       [5.29288718e-06, 1.85171382e-06],\n",
       "       [9.96882200e-01, 9.91139472e-01],\n",
       "       [1.20724608e-05, 4.22356243e-06],\n",
       "       [7.17809644e-06, 2.51125653e-06],\n",
       "       [8.97743046e-01, 7.54385412e-01],\n",
       "       [4.96769535e-05, 1.73799563e-05],\n",
       "       [7.95435786e-01, 5.76336741e-01],\n",
       "       [7.69254804e-01, 5.38387537e-01],\n",
       "       [9.98687804e-01, 9.96258497e-01],\n",
       "       [2.66421976e-05, 9.32088824e-06],\n",
       "       [8.51874113e-01, 6.67992830e-01],\n",
       "       [1.68828410e-05, 5.90649734e-06],\n",
       "       [9.99825656e-01, 9.99501705e-01],\n",
       "       [7.73298442e-01, 5.44079185e-01],\n",
       "       [2.95397931e-05, 1.03346429e-05],\n",
       "       [2.74031237e-03, 9.60405101e-04],\n",
       "       [7.67841756e-01, 5.36412716e-01],\n",
       "       [6.50632719e-05, 2.27632372e-05],\n",
       "       [4.16343119e-06, 1.45657316e-06],\n",
       "       [9.96273398e-01, 9.89421368e-01],\n",
       "       [7.90509522e-01, 5.68993092e-01],\n",
       "       [1.51925051e-04, 5.31559708e-05],\n",
       "       [3.34144424e-04, 1.16925250e-04],\n",
       "       [2.32473467e-05, 8.13316638e-06],\n",
       "       [7.55732238e-01, 5.19781411e-01],\n",
       "       [7.93609500e-01, 5.73602974e-01],\n",
       "       [7.69892573e-01, 5.39281368e-01],\n",
       "       [9.99859214e-01, 9.99597847e-01],\n",
       "       [1.06806683e-05, 3.73663943e-06],\n",
       "       [8.35700666e-06, 2.92370009e-06],\n",
       "       [7.82253742e-01, 5.56900799e-01],\n",
       "       [7.97178566e-01, 5.78958094e-01],\n",
       "       [9.99732077e-01, 9.99234676e-01],\n",
       "       [5.43639653e-05, 1.90198116e-05],\n",
       "       [1.40964057e-05, 4.93164816e-06],\n",
       "       [7.47630179e-01, 5.08938432e-01],\n",
       "       [9.75823164e-01, 9.33864832e-01],\n",
       "       [3.94918789e-06, 1.38162000e-06],\n",
       "       [7.62099147e-01, 5.28461099e-01],\n",
       "       [6.60122241e-05, 2.30952537e-05],\n",
       "       [5.67137977e-06, 1.98412977e-06],\n",
       "       [2.96749611e-04, 1.03837381e-04],\n",
       "       [1.18425060e-05, 4.14311216e-06],\n",
       "       [9.99585211e-01, 9.98815179e-01],\n",
       "       [9.70754147e-01, 9.20713544e-01],\n",
       "       [7.12241769e-01, 4.64072406e-01],\n",
       "       [7.13706640e-06, 2.49690174e-06],\n",
       "       [1.62541146e-05, 5.68653331e-06],\n",
       "       [5.14824816e-04, 1.80170871e-04],\n",
       "       [3.37210819e-02, 1.20617095e-02],\n",
       "       [5.20485155e-05, 1.82096974e-05],\n",
       "       [7.76170254e-01, 5.48157990e-01],\n",
       "       [2.17647303e-05, 7.61445972e-06],\n",
       "       [1.49006648e-02, 5.26397210e-03],\n",
       "       [4.06920211e-03, 1.42738025e-03],\n",
       "       [9.94911492e-01, 9.85591292e-01],\n",
       "       [9.97072697e-01, 9.91678119e-01],\n",
       "       [1.03267717e-04, 3.61304556e-05],\n",
       "       [7.59060204e-01, 5.24300516e-01],\n",
       "       [7.55082786e-01, 5.18903971e-01],\n",
       "       [1.69925042e-04, 5.94545527e-05],\n",
       "       [3.05803114e-04, 1.07005966e-04],\n",
       "       [7.34930218e-05, 2.57126321e-05],\n",
       "       [1.86976773e-04, 6.54214527e-05],\n",
       "       [9.99781787e-01, 9.99376476e-01],\n",
       "       [2.00511113e-06, 7.01485476e-07],\n",
       "       [7.45402038e-01, 5.05995452e-01],\n",
       "       [9.98097599e-01, 9.94581401e-01],\n",
       "       [7.92578518e-01, 5.72065473e-01],\n",
       "       [3.58496443e-04, 1.25448598e-04],\n",
       "       [9.87999856e-01, 9.66447175e-01],\n",
       "       [2.85589813e-05, 9.99149506e-06],\n",
       "       [9.99811709e-01, 9.99461949e-01],\n",
       "       [7.47411072e-01, 5.08648396e-01],\n",
       "       [9.87357497e-01, 9.64692473e-01],\n",
       "       [9.97936964e-01, 9.94125366e-01],\n",
       "       [7.89358914e-01, 5.67291796e-01],\n",
       "       [9.99080300e-01, 9.97375727e-01],\n",
       "       [8.13061059e-01, 6.03428006e-01],\n",
       "       [7.88112938e-01, 5.65455317e-01],\n",
       "       [7.85751343e-01, 5.61991394e-01],\n",
       "       [7.76894331e-01, 5.49191236e-01],\n",
       "       [7.77620196e-01, 5.50229073e-01],\n",
       "       [1.98704147e-04, 6.95252893e-05],\n",
       "       [2.23067273e-05, 7.80408300e-06],\n",
       "       [3.01190048e-05, 1.05372874e-05],\n",
       "       [5.47627568e-01, 2.97513723e-01],\n",
       "       [7.47260638e-04, 2.61554873e-04],\n",
       "       [9.99960899e-01, 9.99888301e-01],\n",
       "       [7.65370369e-01, 5.32976151e-01],\n",
       "       [2.53987557e-04, 8.88717841e-05],\n",
       "       [2.93880343e-01, 1.27097756e-01],\n",
       "       [8.22636939e-05, 2.87813455e-05],\n",
       "       [6.80251804e-04, 2.38090230e-04],\n",
       "       [7.77384222e-01, 5.49891472e-01],\n",
       "       [4.44101752e-05, 1.55372727e-05],\n",
       "       [2.64557784e-05, 9.25566746e-06],\n",
       "       [2.86303148e-05, 1.00164525e-05],\n",
       "       [9.99820769e-01, 9.99487877e-01],\n",
       "       [7.54507065e-01, 5.18127382e-01],\n",
       "       [9.99837160e-01, 9.99534726e-01],\n",
       "       [1.03010338e-04, 3.60403974e-05],\n",
       "       [7.39796669e-05, 2.58829023e-05],\n",
       "       [7.78911114e-01, 5.52079678e-01],\n",
       "       [7.66100566e-05, 2.68032327e-05],\n",
       "       [7.52367854e-01, 5.15251696e-01],\n",
       "       [8.11181486e-01, 6.00476384e-01],\n",
       "       [7.74017215e-01, 5.45097053e-01],\n",
       "       [1.46087832e-05, 5.11090639e-06],\n",
       "       [7.75439203e-01, 5.47116816e-01],\n",
       "       [5.33411958e-06, 1.86613909e-06],\n",
       "       [7.44518518e-01, 5.04833043e-01],\n",
       "       [6.68350086e-02, 2.44443044e-02],\n",
       "       [1.40603925e-06, 4.91900835e-07],\n",
       "       [3.06284259e-04, 1.07174346e-04],\n",
       "       [2.98785977e-04, 1.04550061e-04],\n",
       "       [5.26394724e-05, 1.84164583e-05],\n",
       "       [2.59885892e-05, 9.09221581e-06],\n",
       "       [1.42166400e-05, 4.97371275e-06],\n",
       "       [2.58760920e-05, 9.05285833e-06],\n",
       "       [4.52925706e-05, 1.58459934e-05],\n",
       "       [9.99503374e-01, 9.98581767e-01],\n",
       "       [4.41055447e-01, 2.16338173e-01],\n",
       "       [7.47420881e-06, 2.61485184e-06],\n",
       "       [7.51180778e-05, 2.62812136e-05],\n",
       "       [2.91459419e-05, 1.01968490e-05],\n",
       "       [7.68923819e-01, 5.37924409e-01],\n",
       "       [7.59230614e-01, 5.24533033e-01],\n",
       "       [8.61307263e-01, 6.84803426e-01],\n",
       "       [8.34248931e-05, 2.91876331e-05],\n",
       "       [9.99151111e-01, 9.97577608e-01],\n",
       "       [9.06394962e-06, 3.17102536e-06],\n",
       "       [3.86887632e-06, 1.35352309e-06],\n",
       "       [9.77965444e-03, 3.44329025e-03],\n",
       "       [7.45383877e-05, 2.60783891e-05],\n",
       "       [9.99802172e-01, 9.99434769e-01],\n",
       "       [9.98584032e-01, 9.95963216e-01],\n",
       "       [8.02647650e-01, 5.87264955e-01],\n",
       "       [1.92192838e-05, 6.72391661e-06],\n",
       "       [7.66169310e-01, 5.34084737e-01],\n",
       "       [7.87646055e-01, 5.64768910e-01],\n",
       "       [9.81036186e-01, 9.47639465e-01],\n",
       "       [8.94908862e-06, 3.13084092e-06],\n",
       "       [9.99752939e-01, 9.99294162e-01],\n",
       "       [2.30121304e-06, 8.05076468e-07],\n",
       "       [7.36572027e-01, 4.94493186e-01],\n",
       "       [7.72742629e-01, 5.43293297e-01],\n",
       "       [7.66195416e-01, 5.34121096e-01],\n",
       "       [1.20598376e-01, 4.57806997e-02],\n",
       "       [5.57466328e-01, 3.05897444e-01],\n",
       "       [7.75309741e-01, 5.46932578e-01],\n",
       "       [1.02687953e-03, 3.59492202e-04],\n",
       "       [7.77840734e-01, 5.50544918e-01],\n",
       "       [1.47461242e-05, 5.15895499e-06],\n",
       "       [7.69329011e-01, 5.38491428e-01],\n",
       "       [7.67738139e-03, 2.69939401e-03],\n",
       "       [7.69909024e-01, 5.39304376e-01],\n",
       "       [7.19941090e-06, 2.51871325e-06],\n",
       "       [9.99881744e-01, 9.99662042e-01],\n",
       "       [7.82515168e-01, 5.57279706e-01],\n",
       "       [1.35804730e-04, 4.75152447e-05],\n",
       "       [7.72372901e-01, 5.42771220e-01],\n",
       "       [2.42820848e-03, 8.50848155e-04],\n",
       "       [1.28197396e-04, 4.48533756e-05],\n",
       "       [5.04761636e-02, 1.82581916e-02],\n",
       "       [7.66724586e-01, 5.34856558e-01],\n",
       "       [7.68679142e-01, 5.37582219e-01],\n",
       "       [7.56807685e-01, 5.21237671e-01],\n",
       "       [4.02312689e-05, 1.40752063e-05],\n",
       "       [3.85708445e-05, 1.34942820e-05],\n",
       "       [1.26902369e-05, 4.43969429e-06],\n",
       "       [9.99582112e-01, 9.98806357e-01],\n",
       "       [1.26990501e-03, 4.44641395e-04],\n",
       "       [7.52716422e-01, 5.15719175e-01],\n",
       "       [4.33309360e-05, 1.51596796e-05],\n",
       "       [1.72843702e-05, 6.04697470e-06],\n",
       "       [9.99933243e-01, 9.99809444e-01],\n",
       "       [9.92903650e-01, 9.79980111e-01],\n",
       "       [9.99895692e-01, 9.99701917e-01],\n",
       "       [3.83203775e-01, 1.78546414e-01],\n",
       "       [1.64455894e-04, 5.75407539e-05],\n",
       "       [9.95437086e-01, 9.87067163e-01],\n",
       "       [7.49221325e-01, 5.11050344e-01],\n",
       "       [7.74673402e-01, 5.46028137e-01],\n",
       "       [9.99641418e-01, 9.98975754e-01],\n",
       "       [9.78597224e-01, 9.41163063e-01],\n",
       "       [7.73843110e-01, 5.44850409e-01],\n",
       "       [9.99585211e-01, 9.98815298e-01],\n",
       "       [7.92343497e-01, 5.71715772e-01],\n",
       "       [1.07623746e-04, 3.76546122e-05],\n",
       "       [7.65604377e-01, 5.33300698e-01],\n",
       "       [3.32789978e-06, 1.16426247e-06],\n",
       "       [7.96030819e-01, 5.77230394e-01],\n",
       "       [9.99866128e-01, 9.99617457e-01],\n",
       "       [7.67739475e-01, 5.36270082e-01],\n",
       "       [7.59449124e-01, 5.24831295e-01],\n",
       "       [7.58326709e-01, 5.23301244e-01],\n",
       "       [9.98454332e-01, 9.95594680e-01],\n",
       "       [7.53374636e-01, 5.16603053e-01],\n",
       "       [9.99747455e-01, 9.99278605e-01],\n",
       "       [7.60238826e-01, 5.25910318e-01],\n",
       "       [7.19516456e-01, 4.72978681e-01],\n",
       "       [1.95604938e-04, 6.84407496e-05],\n",
       "       [1.50716230e-02, 5.32496441e-03],\n",
       "       [9.99361455e-01, 9.98177052e-01],\n",
       "       [7.80607760e-01, 5.54521501e-01],\n",
       "       [9.83765312e-06, 3.44170758e-06],\n",
       "       [3.77645105e-04, 1.32150933e-04],\n",
       "       [9.99274194e-01, 9.97928143e-01],\n",
       "       [7.38990545e-01, 4.97618288e-01],\n",
       "       [7.87962112e-04, 2.75808474e-04],\n",
       "       [9.99579370e-01, 9.98798490e-01],\n",
       "       [2.95735692e-04, 1.03482518e-04],\n",
       "       [7.61117518e-01, 5.27113557e-01],\n",
       "       [1.03074402e-04, 3.60628183e-05],\n",
       "       [7.57240832e-01, 5.21825254e-01],\n",
       "       [7.72366166e-01, 5.42761624e-01],\n",
       "       [3.46877678e-05, 1.21357289e-05],\n",
       "       [7.89139628e-01, 5.66968262e-01],\n",
       "       [9.99801219e-01, 9.99431789e-01],\n",
       "       [7.67450929e-01, 5.35867810e-01],\n",
       "       [9.27829115e-06, 3.24601365e-06],\n",
       "       [4.95597837e-04, 1.73439912e-04],\n",
       "       [7.65445948e-01, 5.33080995e-01],\n",
       "       [7.71478355e-01, 5.41509926e-01],\n",
       "       [9.99879122e-01, 9.99654531e-01],\n",
       "       [6.19732646e-06, 2.16813260e-06],\n",
       "       [7.64400661e-01, 5.31633735e-01],\n",
       "       [4.25153339e-05, 1.48743256e-05],\n",
       "       [9.95958149e-01, 9.88533139e-01],\n",
       "       [8.19776237e-01, 6.14099383e-01],\n",
       "       [7.72939205e-01, 5.43571055e-01],\n",
       "       [1.40912918e-04, 4.93026528e-05],\n",
       "       [7.79982924e-01, 5.53620934e-01],\n",
       "       [1.22127065e-04, 4.27293344e-05],\n",
       "       [9.99879241e-01, 9.99654770e-01],\n",
       "       [3.64820153e-05, 1.27634721e-05],\n",
       "       [7.86939025e-01, 5.63730776e-01],\n",
       "       [9.83905852e-01, 9.55332637e-01],\n",
       "       [4.96328248e-05, 1.73645167e-05],\n",
       "       [5.34221954e-06, 1.86897284e-06],\n",
       "       [7.78591394e-01, 5.51620722e-01],\n",
       "       [7.70697057e-01, 5.40410757e-01],\n",
       "       [4.03258382e-05, 1.41082928e-05],\n",
       "       [9.11957860e-01, 7.83727646e-01],\n",
       "       [7.66633093e-01, 5.34729242e-01],\n",
       "       [9.99551833e-01, 9.98720288e-01],\n",
       "       [9.91414487e-01, 9.75844800e-01],\n",
       "       [6.47085399e-05, 2.26391221e-05],\n",
       "       [7.87757635e-01, 5.64932823e-01],\n",
       "       [7.87115335e-01, 5.63989460e-01],\n",
       "       [7.81825364e-01, 5.56280613e-01],\n",
       "       [7.81463563e-01, 5.55757284e-01],\n",
       "       [7.75684536e-01, 5.47465920e-01],\n",
       "       [8.38046617e-05, 2.93205121e-05],\n",
       "       [8.84674319e-06, 3.09503548e-06],\n",
       "       [7.63241291e-01, 5.30033171e-01],\n",
       "       [7.64701962e-01, 5.32050610e-01],\n",
       "       [7.61652827e-01, 5.27848005e-01],\n",
       "       [4.32386923e-06, 1.51270240e-06],\n",
       "       [9.97651279e-01, 9.93315637e-01],\n",
       "       [7.69876778e-01, 5.39259136e-01],\n",
       "       [2.06157929e-05, 7.21249535e-06],\n",
       "       [1.58640600e-04, 5.55058614e-05],\n",
       "       [1.70581134e-05, 5.96781729e-06],\n",
       "       [9.99701798e-01, 9.99148250e-01],\n",
       "       [3.42059345e-03, 1.19935710e-03],\n",
       "       [2.69151642e-05, 9.41638791e-06],\n",
       "       [3.35092220e-04, 1.17256975e-04],\n",
       "       [3.90153021e-01, 1.82884708e-01],\n",
       "       [7.62548625e-01, 5.29079139e-01],\n",
       "       [1.11186819e-05, 3.88987928e-06],\n",
       "       [7.48686254e-01, 5.10339200e-01],\n",
       "       [1.15655748e-05, 4.04622642e-06],\n",
       "       [2.46259824e-05, 8.61549506e-06],\n",
       "       [7.71399319e-01, 5.41398466e-01],\n",
       "       [7.63443750e-05, 2.67102732e-05],\n",
       "       [3.44158652e-05, 1.20405994e-05],\n",
       "       [9.99783099e-01, 9.99380112e-01],\n",
       "       [4.08745800e-05, 1.43002799e-05],\n",
       "       [7.57245600e-01, 5.21831751e-01],\n",
       "       [1.49198878e-03, 5.22477028e-04],\n",
       "       [7.67790437e-01, 5.36341131e-01],\n",
       "       [7.84627497e-01, 5.60350537e-01],\n",
       "       [4.74942817e-06, 1.66158418e-06],\n",
       "       [1.42912628e-04, 5.00023816e-05],\n",
       "       [8.48312557e-01, 6.61765456e-01],\n",
       "       [9.78923261e-01, 9.42025483e-01],\n",
       "       [2.45581788e-04, 8.59300708e-05],\n",
       "       [9.99772012e-01, 9.99348462e-01],\n",
       "       [7.63599992e-01, 5.30527949e-01],\n",
       "       [7.81207681e-01, 5.55387497e-01],\n",
       "       [7.72913933e-01, 5.43535352e-01],\n",
       "       [7.72375405e-01, 5.42774677e-01],\n",
       "       [7.65823126e-01, 5.33604085e-01],\n",
       "       [7.78190672e-01, 5.51046133e-01],\n",
       "       [9.88747597e-01, 9.68495131e-01],\n",
       "       [9.99547422e-01, 9.98707533e-01],\n",
       "       [1.71536740e-05, 6.00125031e-06],\n",
       "       [2.86919152e-04, 1.00396901e-04],\n",
       "       [7.82128751e-01, 5.56719840e-01],\n",
       "       [2.27028358e-05, 7.94266543e-06],\n",
       "       [7.58816183e-01, 5.23967803e-01],\n",
       "       [9.99600828e-01, 9.98859763e-01],\n",
       "       [2.02060747e-03, 7.07836181e-04],\n",
       "       [9.97059226e-01, 9.91639674e-01],\n",
       "       [1.24828011e-05, 4.36712162e-06],\n",
       "       [2.15432607e-04, 7.53792774e-05],\n",
       "       [3.09855886e-06, 1.08402764e-06],\n",
       "       [7.83908725e-01, 5.59303701e-01],\n",
       "       [9.99410272e-01, 9.98316288e-01],\n",
       "       [1.88880967e-05, 6.60804835e-06],\n",
       "       [1.79048693e-05, 6.26406063e-06],\n",
       "       [7.73761153e-01, 5.44734359e-01],\n",
       "       [7.45018423e-01, 5.05490363e-01],\n",
       "       [2.09228671e-03, 7.32980610e-04],\n",
       "       [8.48135387e-05, 2.96735088e-05],\n",
       "       [7.44796813e-01, 5.05198956e-01],\n",
       "       [4.48574747e-06, 1.56933550e-06],\n",
       "       [7.71082938e-01, 5.40953219e-01],\n",
       "       [9.86060381e-01, 9.61161375e-01],\n",
       "       [8.91045034e-01, 7.41006196e-01],\n",
       "       [1.71948031e-05, 6.01563852e-06],\n",
       "       [3.35761324e-05, 1.17468080e-05],\n",
       "       [7.71980882e-01, 5.42217970e-01],\n",
       "       [7.61335254e-01, 5.27412176e-01],\n",
       "       [9.99717176e-01, 9.99192178e-01],\n",
       "       [9.99423146e-01, 9.98352885e-01]], dtype=float32), label_ids=array([0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0,\n",
       "       1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1,\n",
       "       1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 2, 0, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 2, 0], dtype=int64), metrics={'test_loss': 1.444675326347351, 'test_accuracy': 0.33970276008492567, 'test_f1': 0.16904384574749076, 'test_precision': 0.11323425336164189, 'test_recall': 0.3333333333333333, 'test_runtime': 0.5902, 'test_samples_per_second': 798.077, 'test_steps_per_second': 25.416})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5d543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
