{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import ElectraForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5b8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f8f2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ada49dc7de4a688af5d967a5cdf5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf87868f10f405abb40cc83c3823395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/504 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a73bf838a59466bbab42a00a05404eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/450k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a8e8c75d0046ccb76f35054a1dd463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "MODEL_NAME= \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a39b0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='beomi/KcELECTRA-base-v2022', vocab_size=54343, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21abbfd",
   "metadata": {},
   "source": [
    "# Load Koco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5148118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  bias\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...     1\n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...     0\n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...     0\n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데     0\n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...     2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_gender_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_gender_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd61c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cabcb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "351849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"bias\"].values\n",
    "test_label =  koco_test_df[\"bias\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c08e8e",
   "metadata": {},
   "source": [
    "# 모델 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b4cc2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.losses import CoralLoss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label\n",
    "from typing import Optional, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "75cabef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.activations import get_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aeb42205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f38c4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        classifier_dropout = 0.2\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        #self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.coral_layer = CoralLayer(config.hidden_size, config.num_labels)\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = get_activation(\"gelu\")(x)  # although BERT uses tanh here, it seems Electra authors used gelu here\n",
    "        x = self.dropout(x)\n",
    "        x = self.coral_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76842350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraPreTrainedModel, ElectraModel\n",
    "class ElectraForSequenceClassification(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "        self.electra = ElectraModel(config)\n",
    "        self.classifier = ElectraClassificationHead(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        discriminator_hidden_states = self.electra(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = discriminator_hidden_states[0]\n",
    "        logits = self.classifier(sequence_output) #coral layer\n",
    "        probas = torch.sigmoid(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == 'CORAL':\n",
    "                iw = torch.tensor([0.3, 0.7]).to(device)\n",
    "                loss_fct = CoralLoss()\n",
    "                levels = levels_from_labelbatch(labels.view(-1) , num_classes=3).to(device)\n",
    "                loss = loss_fct(logits, levels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + discriminator_hidden_states[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=probas,\n",
    "            hidden_states=discriminator_hidden_states.hidden_states,\n",
    "            attentions=discriminator_hidden_states.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3c0a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/config.json from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\677715b0ed32dce9db3091c12047d5d22f03a62eb3aff4b98c408b3d6a3c9211.787019e3fc5c69b1be216b1bd5b640f6cc9d7116635dfd067308d34c42fd1eed\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"CORAL\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 54343\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/beomi/KcELECTRA-base-v2022/resolve/main/pytorch_model.bin from cache at C:\\Users\\USER/.cache\\huggingface\\transformers\\c02b8c8bb92b81e96c2a5e1b3f50a6ac58b750312693e2c8fcb8614993094ae0.787de38142ccb76d414b9cb15cc1dcefdeeff8aa6b0acb4165fd73567d62cd22\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.coral_layer.coral_weights.weight', 'classifier.coral_layer.coral_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (coral_layer): CoralLayer(\n",
       "      (coral_weights): Linear(in_features=768, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3, problem_type='CORAL')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1af1520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/', # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size=4,      # train batch_size 설정\n",
    "    per_device_eval_batch_size=32,      # test batch_size 설정\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/logs/',# 학습log 저장경로\n",
    "    logging_steps=500,                  # 학습log 기록 단위\n",
    "    save_total_limit=2,                 # 학습결과 저장 최대갯수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af98b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "540f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/pytorch_model.bin'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 학습하고자하는 🤗 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 Training Arguments\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "30264903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 22:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.919400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.882900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.850800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.786700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.839100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.760800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.733700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.662100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.623200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.677800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.645300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.550300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.540200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.554500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.456500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.405900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-5500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-16000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KoELECTRA_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.6439478142766363, metrics={'train_runtime': 1330.4802, 'train_samples_per_second': 59.347, 'train_steps_per_second': 14.837, 'total_flos': 2596882830151680.0, 'train_loss': 0.6439478142766363, 'epoch': 10.0})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9b06fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9564207196235657,\n",
       " 'eval_accuracy': 0.7261146496815286,\n",
       " 'eval_f1': 0.2804428044280443,\n",
       " 'eval_precision': 0.24203821656050953,\n",
       " 'eval_recall': 0.3333333333333333,\n",
       " 'eval_runtime': 0.4628,\n",
       " 'eval_samples_per_second': 1017.709,\n",
       " 'eval_steps_per_second': 32.411,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4de97f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KoELECTRA_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5d0e5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ed0b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       342\n",
      "           1       0.41      0.69      0.52        62\n",
      "           2       0.94      0.66      0.77        67\n",
      "\n",
      "    accuracy                           0.80       471\n",
      "   macro avg       0.75      0.73      0.72       471\n",
      "weighted avg       0.84      0.80      0.81       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = proba_to_label(torch.tensor(predictions.predictions))\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af9a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a747ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2378)\n",
      "tensor(0.3057)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2f16cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ca61759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.3, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ca7af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       342\n",
      "           1       0.40      0.69      0.51        62\n",
      "           2       0.93      0.64      0.76        67\n",
      "\n",
      "    accuracy                           0.79       471\n",
      "   macro avg       0.75      0.72      0.71       471\n",
      "weighted avg       0.84      0.79      0.80       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = predicts_threshold\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# 오차행렬 생성\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# 오차행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e469c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2442)\n",
      "tensor(0.3121)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66073d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[1.5806060e-03, 6.1864505e-04],\n",
       "       [1.5968235e-03, 6.2499876e-04],\n",
       "       [6.2034756e-01, 3.8984340e-01],\n",
       "       [1.5851936e-03, 6.2044238e-04],\n",
       "       [1.9405345e-03, 7.5968687e-04],\n",
       "       [6.0436153e-01, 3.7394661e-01],\n",
       "       [1.5815964e-03, 6.1903341e-04],\n",
       "       [1.5808393e-03, 6.1873643e-04],\n",
       "       [1.5922504e-03, 6.2320719e-04],\n",
       "       [1.5861721e-03, 6.2082568e-04],\n",
       "       [5.9172255e-01, 3.6172068e-01],\n",
       "       [1.5817184e-03, 6.1908120e-04],\n",
       "       [1.5830911e-03, 6.1961892e-04],\n",
       "       [1.7645326e-03, 6.9071096e-04],\n",
       "       [3.2261613e-01, 1.5699360e-01],\n",
       "       [1.5896707e-03, 6.2219671e-04],\n",
       "       [6.0212499e-01, 3.7176147e-01],\n",
       "       [6.1642289e-01, 3.8589466e-01],\n",
       "       [1.5963265e-03, 6.2480429e-04],\n",
       "       [1.5829629e-03, 6.1956840e-04],\n",
       "       [1.5890033e-03, 6.2193524e-04],\n",
       "       [6.3088417e-01, 4.0059581e-01],\n",
       "       [9.9745518e-01, 9.9351752e-01],\n",
       "       [1.5933607e-03, 6.2364241e-04],\n",
       "       [1.6007691e-03, 6.2654458e-04],\n",
       "       [1.5838752e-03, 6.1992614e-04],\n",
       "       [1.5952763e-03, 6.2439294e-04],\n",
       "       [6.1392510e-01, 3.8339731e-01],\n",
       "       [1.5810875e-03, 6.1883405e-04],\n",
       "       [6.2246126e-01, 3.9198253e-01],\n",
       "       [1.7209353e-03, 6.7362760e-04],\n",
       "       [1.5945536e-03, 6.2410970e-04],\n",
       "       [1.5846096e-03, 6.2021392e-04],\n",
       "       [5.8967257e-01, 3.5976541e-01],\n",
       "       [1.5908623e-03, 6.2266359e-04],\n",
       "       [1.5858505e-03, 6.2070001e-04],\n",
       "       [9.9745792e-01, 9.9352443e-01],\n",
       "       [1.7883792e-03, 7.0005597e-04],\n",
       "       [1.6138402e-03, 6.3166599e-04],\n",
       "       [1.5927539e-03, 6.2340469e-04],\n",
       "       [5.1787104e-03, 2.0313892e-03],\n",
       "       [1.5818074e-03, 6.1911601e-04],\n",
       "       [6.0050261e-01, 3.7018228e-01],\n",
       "       [5.6342393e-01, 3.3538586e-01],\n",
       "       [1.5851469e-03, 6.2042440e-04],\n",
       "       [1.5884391e-03, 6.2171422e-04],\n",
       "       [6.1423528e-01, 3.8370675e-01],\n",
       "       [6.7777950e-01, 4.5130277e-01],\n",
       "       [4.2012320e-03, 1.6469832e-03],\n",
       "       [9.9745768e-01, 9.9352396e-01],\n",
       "       [6.1488700e-01, 3.8435757e-01],\n",
       "       [1.6345420e-03, 6.3977652e-04],\n",
       "       [1.5849039e-03, 6.2032888e-04],\n",
       "       [5.7305735e-01, 3.4419423e-01],\n",
       "       [1.5847998e-03, 6.2028843e-04],\n",
       "       [1.5884074e-03, 6.2170177e-04],\n",
       "       [1.5819308e-03, 6.1916438e-04],\n",
       "       [5.9562403e-01, 3.6546311e-01],\n",
       "       [1.5808257e-03, 6.1873114e-04],\n",
       "       [1.5811222e-03, 6.1884755e-04],\n",
       "       [1.5879974e-03, 6.2154117e-04],\n",
       "       [5.8295041e-01, 3.5340679e-01],\n",
       "       [1.5823030e-03, 6.1930990e-04],\n",
       "       [1.6116643e-03, 6.3081319e-04],\n",
       "       [6.7586434e-01, 4.4913551e-01],\n",
       "       [1.5814791e-03, 6.1898743e-04],\n",
       "       [1.5959449e-03, 6.2465487e-04],\n",
       "       [9.9744272e-01, 9.9348611e-01],\n",
       "       [1.5813992e-03, 6.1895611e-04],\n",
       "       [5.9181315e-01, 3.6180723e-01],\n",
       "       [1.5873443e-03, 6.2128506e-04],\n",
       "       [1.5812984e-03, 6.1891659e-04],\n",
       "       [1.5813481e-03, 6.1893603e-04],\n",
       "       [1.5927554e-03, 6.2340498e-04],\n",
       "       [1.5815557e-03, 6.1901746e-04],\n",
       "       [1.5804629e-03, 6.1858899e-04],\n",
       "       [6.1095023e-01, 3.8043872e-01],\n",
       "       [6.7910224e-01, 4.5280454e-01],\n",
       "       [1.5868413e-03, 6.2108820e-04],\n",
       "       [6.0127044e-01, 3.7092906e-01],\n",
       "       [1.5804314e-03, 6.1857695e-04],\n",
       "       [1.5849717e-03, 6.2035554e-04],\n",
       "       [6.1331880e-01, 3.8279295e-01],\n",
       "       [1.5815619e-03, 6.1901956e-04],\n",
       "       [1.5867627e-03, 6.2105712e-04],\n",
       "       [1.6761953e-03, 6.5609702e-04],\n",
       "       [1.6004781e-03, 6.2643085e-04],\n",
       "       [1.5846367e-03, 6.2022422e-04],\n",
       "       [1.5838176e-03, 6.1990338e-04],\n",
       "       [1.6349683e-03, 6.3994358e-04],\n",
       "       [1.5802161e-03, 6.1849260e-04],\n",
       "       [1.5811416e-03, 6.1885500e-04],\n",
       "       [4.5639491e-03, 1.7895731e-03],\n",
       "       [1.5851455e-03, 6.2042382e-04],\n",
       "       [9.9745554e-01, 9.9351829e-01],\n",
       "       [2.0753744e-03, 8.1254164e-04],\n",
       "       [6.2237769e-01, 3.9189777e-01],\n",
       "       [9.9745196e-01, 9.9350935e-01],\n",
       "       [5.9958386e-01, 3.6929020e-01],\n",
       "       [1.5853673e-03, 6.2051072e-04],\n",
       "       [5.6293660e-01, 3.3494449e-01],\n",
       "       [1.6225346e-03, 6.3507201e-04],\n",
       "       [1.5856134e-03, 6.2060717e-04],\n",
       "       [1.6248859e-03, 6.3599332e-04],\n",
       "       [5.4680657e-01, 3.2055590e-01],\n",
       "       [5.3980672e-01, 3.1444272e-01],\n",
       "       [5.9442586e-01, 3.6431083e-01],\n",
       "       [1.6117272e-03, 6.3083781e-04],\n",
       "       [1.5812607e-03, 6.1890157e-04],\n",
       "       [5.9841281e-01, 3.6815542e-01],\n",
       "       [1.5823089e-03, 6.1931222e-04],\n",
       "       [1.5885935e-03, 6.2177441e-04],\n",
       "       [1.5861584e-03, 6.2082073e-04],\n",
       "       [6.1047477e-01, 3.7996748e-01],\n",
       "       [5.9834343e-01, 3.6808825e-01],\n",
       "       [2.0948688e-03, 8.2018331e-04],\n",
       "       [1.5878100e-03, 6.2146777e-04],\n",
       "       [1.5843019e-03, 6.2009337e-04],\n",
       "       [9.9744958e-01, 9.9350327e-01],\n",
       "       [5.7049763e-01, 3.4183830e-01],\n",
       "       [1.5839535e-03, 6.1995653e-04],\n",
       "       [1.5816251e-03, 6.1904459e-04],\n",
       "       [1.6186446e-03, 6.3354796e-04],\n",
       "       [6.6186087e-03, 2.5984861e-03],\n",
       "       [1.8614871e-02, 7.3622596e-03],\n",
       "       [1.5807339e-03, 6.1869517e-04],\n",
       "       [1.6689436e-03, 6.5325532e-04],\n",
       "       [6.4818114e-01, 4.1874173e-01],\n",
       "       [9.9745220e-01, 9.9351007e-01],\n",
       "       [1.5839203e-03, 6.1994384e-04],\n",
       "       [1.5803665e-03, 6.1855128e-04],\n",
       "       [1.5805698e-03, 6.1863119e-04],\n",
       "       [5.9608150e-01, 3.6590374e-01],\n",
       "       [1.5888943e-03, 6.2189234e-04],\n",
       "       [6.2078691e-01, 3.9028725e-01],\n",
       "       [1.5833864e-03, 6.1973470e-04],\n",
       "       [1.5820287e-03, 6.1920250e-04],\n",
       "       [1.5830834e-03, 6.1961572e-04],\n",
       "       [6.0254693e-01, 3.7217295e-01],\n",
       "       [1.6352237e-03, 6.4004393e-04],\n",
       "       [1.5834091e-03, 6.1974331e-04],\n",
       "       [6.4118540e-01, 4.1132718e-01],\n",
       "       [1.5805367e-03, 6.1861792e-04],\n",
       "       [1.5818133e-03, 6.1911833e-04],\n",
       "       [6.1012965e-01, 3.7962565e-01],\n",
       "       [1.5820890e-03, 6.1922602e-04],\n",
       "       [1.5823389e-03, 6.1932433e-04],\n",
       "       [6.0162121e-01, 3.7127063e-01],\n",
       "       [1.5835661e-03, 6.1980501e-04],\n",
       "       [9.9740171e-01, 9.9338174e-01],\n",
       "       [7.1582659e-03, 2.8112864e-03],\n",
       "       [6.2159485e-01, 3.9110458e-01],\n",
       "       [1.5909714e-03, 6.2270631e-04],\n",
       "       [1.5885103e-03, 6.2174175e-04],\n",
       "       [1.6249153e-03, 6.3600478e-04],\n",
       "       [5.8122629e-01, 3.5178891e-01],\n",
       "       [1.5886509e-03, 6.2179717e-04],\n",
       "       [1.5828846e-03, 6.1953807e-04],\n",
       "       [1.5818059e-03, 6.1911542e-04],\n",
       "       [1.6120956e-03, 6.3098239e-04],\n",
       "       [1.5829026e-03, 6.1954511e-04],\n",
       "       [1.5863186e-03, 6.2088337e-04],\n",
       "       [1.5861178e-03, 6.2080444e-04],\n",
       "       [1.5810349e-03, 6.1881338e-04],\n",
       "       [1.5841465e-03, 6.2003249e-04],\n",
       "       [1.5816597e-03, 6.1905792e-04],\n",
       "       [6.9049472e-01, 4.6591258e-01],\n",
       "       [1.5823330e-03, 6.1932200e-04],\n",
       "       [1.5855317e-03, 6.2057516e-04],\n",
       "       [1.5806706e-03, 6.1867066e-04],\n",
       "       [9.9737298e-01, 9.9330902e-01],\n",
       "       [1.5847636e-03, 6.2027393e-04],\n",
       "       [1.5812712e-03, 6.1890599e-04],\n",
       "       [5.7875139e-01, 3.4947571e-01],\n",
       "       [9.9745542e-01, 9.9351799e-01],\n",
       "       [9.9745470e-01, 9.9351621e-01],\n",
       "       [1.7322212e-03, 6.7804987e-04],\n",
       "       [1.5813555e-03, 6.1893900e-04],\n",
       "       [1.5862203e-03, 6.2084472e-04],\n",
       "       [6.0256779e-01, 3.7219334e-01],\n",
       "       [1.5827534e-03, 6.1948638e-04],\n",
       "       [1.5956636e-03, 6.2454445e-04],\n",
       "       [1.5847514e-03, 6.2026945e-04],\n",
       "       [1.6521567e-03, 6.4667803e-04],\n",
       "       [3.1157003e-03, 1.2206191e-03],\n",
       "       [1.5809701e-03, 6.1878772e-04],\n",
       "       [6.2035084e-01, 3.8984665e-01],\n",
       "       [1.6062382e-03, 6.2868721e-04],\n",
       "       [5.9774274e-01, 3.6750722e-01],\n",
       "       [1.5812892e-03, 6.1891275e-04],\n",
       "       [1.5856451e-03, 6.2061928e-04],\n",
       "       [1.6143381e-03, 6.3186069e-04],\n",
       "       [1.5887431e-03, 6.2183302e-04],\n",
       "       [1.5908806e-03, 6.2267075e-04],\n",
       "       [9.9746048e-01, 9.9353117e-01],\n",
       "       [1.6227044e-03, 6.3513883e-04],\n",
       "       [6.3420283e-03, 2.4894800e-03],\n",
       "       [1.5804780e-03, 6.1859516e-04],\n",
       "       [1.5932013e-03, 6.2357995e-04],\n",
       "       [1.5838676e-03, 6.1992317e-04],\n",
       "       [1.5867339e-03, 6.2104594e-04],\n",
       "       [9.9744844e-01, 9.9350041e-01],\n",
       "       [1.5807670e-03, 6.1870838e-04],\n",
       "       [6.8849468e-01, 4.6358865e-01],\n",
       "       [3.2573908e-03, 1.2762394e-03],\n",
       "       [1.5819264e-03, 6.1916263e-04],\n",
       "       [1.5833775e-03, 6.1973114e-04],\n",
       "       [6.0083514e-01, 3.7050557e-01],\n",
       "       [1.5823587e-03, 6.1933202e-04],\n",
       "       [1.5819941e-03, 6.1918917e-04],\n",
       "       [1.6105445e-03, 6.3037442e-04],\n",
       "       [5.7562494e-01, 3.4656882e-01],\n",
       "       [6.0546029e-01, 3.7502348e-01],\n",
       "       [9.9742460e-01, 9.9343997e-01],\n",
       "       [1.5810528e-03, 6.1882043e-04],\n",
       "       [9.9746156e-01, 9.9353373e-01],\n",
       "       [1.5842883e-03, 6.2008802e-04],\n",
       "       [1.5827006e-03, 6.1946572e-04],\n",
       "       [9.9745601e-01, 9.9351972e-01],\n",
       "       [3.3649092e-03, 1.3184512e-03],\n",
       "       [1.5865738e-03, 6.2098313e-04],\n",
       "       [1.5886765e-03, 6.2180724e-04],\n",
       "       [6.7423959e-03, 2.6472858e-03],\n",
       "       [4.2088437e-03, 1.6499747e-03],\n",
       "       [6.3148808e-01, 4.0121895e-01],\n",
       "       [7.6302779e-03, 2.9975264e-03],\n",
       "       [6.8788761e-01, 4.6288532e-01],\n",
       "       [1.5857522e-03, 6.2066125e-04],\n",
       "       [1.5808452e-03, 6.1873876e-04],\n",
       "       [1.5829870e-03, 6.1957788e-04],\n",
       "       [1.7197218e-03, 6.7315204e-04],\n",
       "       [9.9746037e-01, 9.9353069e-01],\n",
       "       [1.5830097e-03, 6.1958708e-04],\n",
       "       [1.5824912e-03, 6.1938399e-04],\n",
       "       [1.5855575e-03, 6.2058528e-04],\n",
       "       [1.5945049e-03, 6.2409037e-04],\n",
       "       [1.6165668e-03, 6.3273421e-04],\n",
       "       [1.6304464e-03, 6.3817186e-04],\n",
       "       [1.5817997e-03, 6.1911275e-04],\n",
       "       [1.5809957e-03, 6.1879773e-04],\n",
       "       [1.5813179e-03, 6.1892427e-04],\n",
       "       [9.9745637e-01, 9.9352056e-01],\n",
       "       [1.6016276e-03, 6.2688120e-04],\n",
       "       [6.2727851e-01, 3.9689118e-01],\n",
       "       [1.6110507e-03, 6.3057267e-04],\n",
       "       [6.7881840e-01, 4.5248196e-01],\n",
       "       [6.3567263e-01, 4.0555695e-01],\n",
       "       [1.5842235e-03, 6.2006264e-04],\n",
       "       [1.5907125e-03, 6.2260486e-04],\n",
       "       [1.6324517e-03, 6.3895754e-04],\n",
       "       [1.5817771e-03, 6.1910419e-04],\n",
       "       [1.5816086e-03, 6.1903778e-04],\n",
       "       [5.9008646e-01, 3.6015958e-01],\n",
       "       [1.5945900e-03, 6.2412373e-04],\n",
       "       [9.9738568e-01, 9.9334115e-01],\n",
       "       [1.5835342e-03, 6.1979255e-04],\n",
       "       [1.5806013e-03, 6.1864324e-04],\n",
       "       [1.5840636e-03, 6.1999966e-04],\n",
       "       [1.5970576e-03, 6.2509079e-04],\n",
       "       [7.3530966e-01, 5.2067226e-01],\n",
       "       [1.5823768e-03, 6.1933912e-04],\n",
       "       [1.5823783e-03, 6.1933935e-04],\n",
       "       [1.5844604e-03, 6.2015542e-04],\n",
       "       [5.9545088e-01, 3.6529645e-01],\n",
       "       [6.2141269e-01, 3.9092019e-01],\n",
       "       [1.5817033e-03, 6.1907503e-04],\n",
       "       [1.5842400e-03, 6.2006916e-04],\n",
       "       [1.5952445e-03, 6.2438042e-04],\n",
       "       [1.5811387e-03, 6.1885378e-04],\n",
       "       [5.7135820e-01, 3.4262913e-01],\n",
       "       [1.5944655e-03, 6.2407495e-04],\n",
       "       [1.5920777e-03, 6.2313973e-04],\n",
       "       [1.6383795e-03, 6.4128038e-04],\n",
       "       [6.7189777e-01, 4.4467404e-01],\n",
       "       [1.5807819e-03, 6.1871432e-04],\n",
       "       [1.5812441e-03, 6.1889534e-04],\n",
       "       [5.7487887e-01, 3.4587765e-01],\n",
       "       [1.5811508e-03, 6.1885884e-04],\n",
       "       [1.5940663e-03, 6.2391855e-04],\n",
       "       [6.1845696e-01, 3.8793740e-01],\n",
       "       [9.9735200e-01, 9.9325585e-01],\n",
       "       [1.5905123e-03, 6.2252651e-04],\n",
       "       [1.9589175e-02, 7.7522532e-03],\n",
       "       [1.6287707e-03, 6.3751527e-04],\n",
       "       [9.9740040e-01, 9.9337864e-01],\n",
       "       [1.5964297e-03, 6.2484451e-04],\n",
       "       [6.2036347e-01, 3.8985941e-01],\n",
       "       [1.5847441e-03, 6.2026625e-04],\n",
       "       [1.5875607e-03, 6.2136975e-04],\n",
       "       [5.6389701e-01, 3.3581474e-01],\n",
       "       [1.5825079e-03, 6.1939016e-04],\n",
       "       [6.1142981e-01, 3.8091454e-01],\n",
       "       [1.5843774e-03, 6.2012259e-04],\n",
       "       [1.6447518e-03, 6.4377673e-04],\n",
       "       [1.5810528e-03, 6.1882014e-04],\n",
       "       [1.5858262e-03, 6.2069023e-04],\n",
       "       [1.6401995e-03, 6.4199342e-04],\n",
       "       [9.9746585e-01, 9.9354470e-01],\n",
       "       [1.5815557e-03, 6.1901746e-04],\n",
       "       [1.6071666e-03, 6.2905136e-04],\n",
       "       [1.5812636e-03, 6.1890302e-04],\n",
       "       [1.5897086e-03, 6.2221161e-04],\n",
       "       [1.5895376e-03, 6.2214455e-04],\n",
       "       [1.5898373e-03, 6.2226172e-04],\n",
       "       [5.8028516e-03, 2.2770816e-03],\n",
       "       [1.5853718e-03, 6.2051218e-04],\n",
       "       [1.5846367e-03, 6.2022451e-04],\n",
       "       [1.5855394e-03, 6.2057812e-04],\n",
       "       [3.9985114e-01, 2.0667587e-01],\n",
       "       [5.6208909e-01, 3.3417773e-01],\n",
       "       [9.9745458e-01, 9.9351597e-01],\n",
       "       [1.5822125e-03, 6.1927474e-04],\n",
       "       [1.5804297e-03, 6.1857630e-04],\n",
       "       [1.5800475e-03, 6.1842659e-04],\n",
       "       [9.9745065e-01, 9.9350595e-01],\n",
       "       [1.5828242e-03, 6.1951438e-04],\n",
       "       [2.4956095e-03, 9.7732013e-04],\n",
       "       [1.5812938e-03, 6.1891484e-04],\n",
       "       [1.5808257e-03, 6.1873137e-04],\n",
       "       [9.9745959e-01, 9.9352878e-01],\n",
       "       [6.0961694e-01, 3.7911826e-01],\n",
       "       [9.9743783e-01, 9.9347371e-01],\n",
       "       [5.9630263e-01, 3.6611691e-01],\n",
       "       [1.5827836e-03, 6.1949855e-04],\n",
       "       [1.5889807e-03, 6.2192604e-04],\n",
       "       [1.6325107e-03, 6.3898100e-04],\n",
       "       [1.5802477e-03, 6.1850500e-04],\n",
       "       [9.9731833e-01, 9.9317038e-01],\n",
       "       [9.9745578e-01, 9.9351889e-01],\n",
       "       [1.6114649e-03, 6.3073501e-04],\n",
       "       [6.0350913e-01, 3.7311271e-01],\n",
       "       [5.7738292e-01, 3.4820119e-01],\n",
       "       [1.5905474e-03, 6.2253990e-04],\n",
       "       [6.0198575e-01, 3.7162572e-01],\n",
       "       [1.5805531e-03, 6.1862438e-04],\n",
       "       [1.8907711e-03, 7.4018317e-04],\n",
       "       [6.2208277e-01, 3.9159882e-01],\n",
       "       [1.5841465e-03, 6.2003249e-04],\n",
       "       [1.5889973e-03, 6.2193262e-04],\n",
       "       [1.5924142e-03, 6.2327163e-04],\n",
       "       [9.9745983e-01, 9.9352914e-01],\n",
       "       [1.5929024e-03, 6.2346290e-04],\n",
       "       [9.9745077e-01, 9.9350643e-01],\n",
       "       [6.1985213e-01, 3.8934317e-01],\n",
       "       [2.1646381e-03, 8.4753585e-04],\n",
       "       [1.6201524e-03, 6.3413871e-04],\n",
       "       [1.5855998e-03, 6.2060182e-04],\n",
       "       [1.5839488e-03, 6.1995472e-04],\n",
       "       [5.7655638e-01, 3.4743303e-01],\n",
       "       [1.5809851e-03, 6.1879359e-04],\n",
       "       [1.5899629e-03, 6.2231126e-04],\n",
       "       [6.5533626e-01, 4.2643398e-01],\n",
       "       [1.5854323e-03, 6.2053587e-04],\n",
       "       [1.6238574e-03, 6.3559035e-04],\n",
       "       [6.1656791e-01, 3.8604003e-01],\n",
       "       [1.5823301e-03, 6.1932084e-04],\n",
       "       [1.5814038e-03, 6.1895791e-04],\n",
       "       [1.5805772e-03, 6.1863405e-04],\n",
       "       [1.5964813e-03, 6.2486506e-04],\n",
       "       [1.5903005e-03, 6.2244321e-04],\n",
       "       [1.8891304e-03, 7.3954015e-04],\n",
       "       [1.5832583e-03, 6.1968446e-04],\n",
       "       [9.9744594e-01, 9.9349397e-01],\n",
       "       [1.5841677e-03, 6.2004046e-04],\n",
       "       [1.5813615e-03, 6.1894133e-04],\n",
       "       [1.5897297e-03, 6.2221987e-04],\n",
       "       [1.5907048e-03, 6.2260160e-04],\n",
       "       [5.7874310e-01, 3.4946793e-01],\n",
       "       [6.0699981e-01, 3.7653622e-01],\n",
       "       [1.5801815e-03, 6.1847904e-04],\n",
       "       [1.5950075e-03, 6.2428735e-04],\n",
       "       [1.5884785e-03, 6.2172959e-04],\n",
       "       [9.9745136e-01, 9.9350786e-01],\n",
       "       [6.2993938e-01, 3.9962262e-01],\n",
       "       [1.5892197e-03, 6.2202004e-04],\n",
       "       [1.5864667e-03, 6.2094146e-04],\n",
       "       [1.5888475e-03, 6.2187394e-04],\n",
       "       [1.5814111e-03, 6.1896053e-04],\n",
       "       [9.9745864e-01, 9.9352622e-01],\n",
       "       [1.5862854e-03, 6.2087044e-04],\n",
       "       [5.7194358e-01, 3.4316769e-01],\n",
       "       [5.8217853e-01, 3.5268185e-01],\n",
       "       [1.5894088e-03, 6.2209414e-04],\n",
       "       [1.5815964e-03, 6.1903312e-04],\n",
       "       [1.5847697e-03, 6.2027661e-04],\n",
       "       [1.5983187e-03, 6.2558486e-04],\n",
       "       [1.5805593e-03, 6.1862671e-04],\n",
       "       [5.6215620e-01, 3.3423841e-01],\n",
       "       [1.7375627e-03, 6.8014261e-04],\n",
       "       [5.8286047e-01, 3.5332218e-01],\n",
       "       [1.5841224e-03, 6.2002306e-04],\n",
       "       [5.9817708e-01, 3.6792722e-01],\n",
       "       [1.5884119e-03, 6.2170328e-04],\n",
       "       [1.5923324e-03, 6.2323955e-04],\n",
       "       [1.5948070e-03, 6.2420906e-04],\n",
       "       [9.9744886e-01, 9.9350148e-01],\n",
       "       [6.0733712e-01, 3.7686825e-01],\n",
       "       [1.5824144e-03, 6.1935355e-04],\n",
       "       [1.5834499e-03, 6.1975955e-04],\n",
       "       [6.0782647e-01, 3.7735039e-01],\n",
       "       [9.9745053e-01, 9.9350595e-01],\n",
       "       [1.5857763e-03, 6.2067073e-04],\n",
       "       [1.5818750e-03, 6.1914255e-04],\n",
       "       [5.8496505e-01, 3.5530397e-01],\n",
       "       [5.9492916e-01, 3.6479455e-01],\n",
       "       [1.5841767e-03, 6.2004395e-04],\n",
       "       [1.5815964e-03, 6.1903341e-04],\n",
       "       [1.5876000e-03, 6.2138517e-04],\n",
       "       [9.9741733e-01, 9.9342149e-01],\n",
       "       [5.7233715e-01, 3.4353021e-01],\n",
       "       [1.5821236e-03, 6.1923987e-04],\n",
       "       [1.5818736e-03, 6.1914191e-04],\n",
       "       [1.5857387e-03, 6.2065595e-04],\n",
       "       [1.5806465e-03, 6.1866123e-04],\n",
       "       [1.5972933e-03, 6.2518282e-04],\n",
       "       [6.1626565e-01, 3.8573712e-01],\n",
       "       [1.5810318e-03, 6.1881222e-04],\n",
       "       [1.5845025e-03, 6.2017195e-04],\n",
       "       [9.9741155e-01, 9.9340665e-01],\n",
       "       [1.5818074e-03, 6.1911601e-04],\n",
       "       [1.5855513e-03, 6.2058290e-04],\n",
       "       [6.1079681e-01, 3.8028663e-01],\n",
       "       [1.5811990e-03, 6.1887736e-04],\n",
       "       [1.6300458e-03, 6.3801528e-04],\n",
       "       [1.5904594e-03, 6.2250573e-04],\n",
       "       [5.9246302e-01, 3.6242881e-01],\n",
       "       [1.5909079e-03, 6.2268117e-04],\n",
       "       [1.5824459e-03, 6.1936624e-04],\n",
       "       [1.5845887e-03, 6.2020565e-04],\n",
       "       [9.9744618e-01, 9.9349469e-01],\n",
       "       [1.5886221e-03, 6.2178593e-04],\n",
       "       [1.5952566e-03, 6.2438491e-04],\n",
       "       [9.9745578e-01, 9.9351913e-01],\n",
       "       [1.5837967e-03, 6.1989512e-04],\n",
       "       [1.7063746e-03, 6.6792179e-04],\n",
       "       [6.2195748e-01, 3.9147186e-01],\n",
       "       [6.1199641e-01, 3.8147730e-01],\n",
       "       [6.1485213e-01, 3.8432276e-01],\n",
       "       [1.5821040e-03, 6.1923225e-04],\n",
       "       [5.4261297e-01, 3.1688416e-01],\n",
       "       [1.6426077e-03, 6.4293673e-04],\n",
       "       [5.8998001e-01, 3.6005810e-01],\n",
       "       [1.5812652e-03, 6.1890366e-04],\n",
       "       [5.8241129e-01, 3.5290030e-01],\n",
       "       [1.5806629e-03, 6.1866769e-04],\n",
       "       [9.9745625e-01, 9.9352032e-01],\n",
       "       [5.9256697e-01, 3.6252832e-01],\n",
       "       [1.5824356e-03, 6.1936211e-04],\n",
       "       [9.9745733e-01, 9.9352300e-01],\n",
       "       [1.5818344e-03, 6.1912637e-04],\n",
       "       [1.5856617e-03, 6.2062609e-04],\n",
       "       [1.5810952e-03, 6.1883673e-04],\n",
       "       [1.5931529e-03, 6.2356063e-04],\n",
       "       [9.9737620e-01, 9.9331725e-01],\n",
       "       [1.5814503e-03, 6.1897613e-04],\n",
       "       [1.5862128e-03, 6.2084169e-04],\n",
       "       [1.6297976e-03, 6.3791766e-04],\n",
       "       [1.5803396e-03, 6.1854062e-04],\n",
       "       [6.0682279e-01, 3.7636209e-01],\n",
       "       [1.5823857e-03, 6.1934232e-04],\n",
       "       [6.0469991e-01, 3.7427795e-01],\n",
       "       [5.6975991e-01, 3.4116137e-01],\n",
       "       [1.4796776e-02, 5.8384580e-03],\n",
       "       [3.9048735e-03, 1.5305257e-03],\n",
       "       [1.5822125e-03, 6.1927451e-04],\n",
       "       [1.5838072e-03, 6.1989925e-04],\n",
       "       [1.5908215e-03, 6.2264758e-04],\n",
       "       [9.9733585e-01, 9.9321496e-01],\n",
       "       [6.1039478e-01, 3.7988821e-01],\n",
       "       [9.9741250e-01, 9.9340916e-01],\n",
       "       [9.9745148e-01, 9.9350810e-01]], dtype=float32), label_ids=array([0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 1, 2, 2], dtype=int64), metrics={'test_loss': 0.9564207196235657, 'test_accuracy': 0.7261146496815286, 'test_f1': 0.2804428044280443, 'test_precision': 0.24203821656050953, 'test_recall': 0.3333333333333333, 'test_runtime': 0.4757, 'test_samples_per_second': 990.067, 'test_steps_per_second': 31.531})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "51f5d543",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-e31358d7d4fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m54343\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-b9e4a792da84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         )\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\transformers\\models\\electra\\modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary\n",
    "summary(model, (4, 54343))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dbf156bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54343, 768])\n",
      "electra.embeddings.word_embeddings.weight\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, param in model.named_parameters():\n",
    "    count+=1\n",
    "    if count==1:\n",
    "        print(param.size())\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014a37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
