{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bcf2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc79799",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME= \"beomi/kcbert-base\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b57c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  hate\n",
       "0  (ÌòÑÏû¨ Ìò∏ÌÖîÏ£ºÏù∏ Ïã¨Ï†ï) ÏïÑ18 ÎÇú ÎßàÎ•∏ÌïòÎäòÏóê ÎÇ†Î≤ºÎùΩÎßûÍ≥† Ìò∏ÌÖîÎßùÌïòÍ≤åÏÉùÍ≤ºÎäîÎç∞ ÎàÑÍµ∞ Í≥ÑÏÜç...     2\n",
       "1  ....ÌïúÍµ≠Ï†ÅÏù∏ ÎØ∏Ïù∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Î∂Ñ...ÎÑàÎ¨¥ÎÇò Í≥±Í≥†ÏïÑÎ¶ÑÎã§Ïö¥Î™®Ïäµ...Í∑∏Î™®ÏäµÎí§Ïùò Ïä¨ÌîîÏùÑ...     0\n",
       "2  ...Î™ªÎêú ÎÑòÎì§...ÎÇ®Ïùò Í≥†ÌÜµÏùÑ Ï¶êÍ≤ºÎçò ÎÑòÎì§..Ïù¥Ï†† ÎßàÎïÖÌïú Ï≤òÎ≤åÏùÑ Î∞õÏïÑÏïºÏßÄ..,Í∑∏Îûò...     2\n",
       "3                 1,2Ìôî Ïñ¥ÏÑ§ÌéêÎäîÎç∞ 3,4Ìôî ÏßÄÎÇòÏÑúÎ∂ÄÌÑ∞Îäî Í∞àÏàòÎ°ù ÎÑàÎ¨¥ Ïû¨Î∞åÎçòÎç∞     0\n",
       "4  1. ÏÇ¨Îûå ÏñºÍµ¥ ÏÜêÌÜ±ÏúºÎ°ú Í∏ÅÏùÄÍ≤ÉÏùÄ Ïù∏Í≤©ÏÇ¥Ìï¥Ïù¥Í≥†2. ÎèôÏòÅÏÉÅÏù¥ Î™∞Ïπ¥ÎÉê? Î©îÍ±∏Î¶¨ÏïàÎì§ ÏÉùÍ∞Å...     2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path ='C:/Users/USER/Desktop/2021_korean_hate_speech_detection/hs_CORAL/dataset/'\n",
    "koco_train_df = pd.read_csv(data_path+\"koco_hate_train.txt\", sep=\"\\t\")\n",
    "koco_test_df = pd.read_csv(data_path+\"koco_hate_test.txt\", sep=\"\\t\")\n",
    "koco_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9be962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "                            list(koco_train_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(koco_test_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403040c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414120f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = koco_train_df[\"hate\"].values\n",
    "test_label =  koco_test_df[\"hate\"].values\n",
    "\n",
    "train_dataset = MyDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e4ac5",
   "metadata": {},
   "source": [
    "# Î™®Îç∏ ÌäúÎãù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3048f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.losses import CoralLoss\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.dataset import proba_to_label\n",
    "from coral_pytorch.losses import corn_loss\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fcb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156bf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel\n",
    "import torch.nn as nn\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = 0.2\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels-1)\n",
    "        \n",
    "        #self.coral_layer = CoralLayer(config.hidden_size, config.num_labels)\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        #logits = self.coral_layer(pooled_output)\n",
    "#         self.probas1 = torch.sigmoid(logits)\n",
    "#         self.probas = torch.cumprod(self.probas1, dim=1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == 'CORAL':\n",
    "                #loss_fct = CoralLoss()\n",
    "                #levels = levels_from_labelbatch(labels.view(-1) , num_classes=3).to(device)\n",
    "                #loss = loss_fct(logits, levels)\n",
    "                loss = corn_loss(logits, labels, self.config.num_labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63d77cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    predicts = pred.predictions\n",
    "    preds = corn_label_from_logits(torch.tensor(predicts))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df469b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, \n",
    "                                                      num_labels=3,\n",
    "                                                      problem_type='CORAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf7a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/', # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    num_train_epochs=10,                # ÌïôÏäµ epoch ÏÑ§Ï†ï\n",
    "    per_device_train_batch_size=4,      # train batch_size ÏÑ§Ï†ï\n",
    "    per_device_eval_batch_size=32,      # test batch_size ÏÑ§Ï†ï\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/logs/',# ÌïôÏäµlog Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    logging_steps=500,                  # ÌïôÏäµlog Í∏∞Î°ù Îã®ÏúÑ\n",
    "    save_total_limit=2,                 # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû• ÏµúÎåÄÍ∞ØÏàò \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f4f3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model.load_state_dict(torch.load('KcBERT_CORN_outputs/output/pytorch_model.bin'))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # ÌïôÏäµÌïòÍ≥†ÏûêÌïòÎäî ü§ó Transformers model\n",
    "    args=training_args,                  # ÏúÑÏóêÏÑú Ï†ïÏùòÌïú Training Arguments\n",
    "    train_dataset=train_dataset,         # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    eval_dataset=test_dataset,           # ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    compute_metrics=compute_metrics,     # ÌèâÍ∞ÄÏßÄÌëú\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cebd4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 23:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.470100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.376100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.402200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.357200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.280500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.285400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.169500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-5500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-5500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-16000\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT_CORN_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.36895295020415547, metrics={'train_runtime': 1434.2684, 'train_samples_per_second': 55.052, 'train_steps_per_second': 13.763, 'total_flos': 2596906116403200.0, 'train_loss': 0.36895295020415547, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2c71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.091366171836853,\n",
       " 'eval_accuracy': 0.6348195329087049,\n",
       " 'eval_f1': 0.6377932116830745,\n",
       " 'eval_precision': 0.6570620692813152,\n",
       " 'eval_recall': 0.6376619105444242,\n",
       " 'eval_runtime': 0.4448,\n",
       " 'eval_samples_per_second': 1058.8,\n",
       " 'eval_steps_per_second': 33.72,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "462efc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31954d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24214f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[0.01196167, 0.00279913],\n",
       "       [0.9987545 , 0.00366343],\n",
       "       [0.99886715, 0.00459284],\n",
       "       [0.9988626 , 0.00653753],\n",
       "       [0.9982925 , 0.0023647 ],\n",
       "       [0.9972818 , 0.98211086],\n",
       "       [0.01196181, 0.00279925],\n",
       "       [0.01196158, 0.00279907],\n",
       "       [0.01196646, 0.00279931],\n",
       "       [0.9881052 , 0.0024444 ],\n",
       "       [0.01196609, 0.00279915],\n",
       "       [0.9988367 , 0.00422737],\n",
       "       [0.01196127, 0.00279913],\n",
       "       [0.9983139 , 0.00240705],\n",
       "       [0.9964881 , 0.951866  ],\n",
       "       [0.01198476, 0.00279908],\n",
       "       [0.99881834, 0.00410454],\n",
       "       [0.997282  , 0.9821103 ],\n",
       "       [0.9987999 , 0.0039464 ],\n",
       "       [0.9929872 , 0.00142527],\n",
       "       [0.9984269 , 0.00258752],\n",
       "       [0.9984744 , 0.00268117],\n",
       "       [0.9987596 , 0.00368377],\n",
       "       [0.9987447 , 0.00359177],\n",
       "       [0.99659747, 0.00155426],\n",
       "       [0.01196194, 0.00279924],\n",
       "       [0.998825  , 0.0041474 ],\n",
       "       [0.9972819 , 0.98211044],\n",
       "       [0.01196667, 0.00279886],\n",
       "       [0.9980107 , 0.44858414],\n",
       "       [0.9970675 , 0.00164097],\n",
       "       [0.9987332 , 0.00353218],\n",
       "       [0.01196206, 0.00279919],\n",
       "       [0.01197418, 0.0027988 ],\n",
       "       [0.01196185, 0.00279927],\n",
       "       [0.01197065, 0.00279862],\n",
       "       [0.9986842 , 0.00331045],\n",
       "       [0.9975313 , 0.00178911],\n",
       "       [0.01199095, 0.00279843],\n",
       "       [0.01197354, 0.00279868],\n",
       "       [0.9972844 , 0.98207855],\n",
       "       [0.9972819 , 0.9821101 ],\n",
       "       [0.9972818 , 0.98211133],\n",
       "       [0.99728227, 0.98210895],\n",
       "       [0.99652845, 0.00152973],\n",
       "       [0.01196211, 0.00279908],\n",
       "       [0.9972818 , 0.98211133],\n",
       "       [0.99698216, 0.00160811],\n",
       "       [0.01196298, 0.00279901],\n",
       "       [0.99866986, 0.00324565],\n",
       "       [0.997647  , 0.5922672 ],\n",
       "       [0.01198652, 0.00279901],\n",
       "       [0.9984407 , 0.00261474],\n",
       "       [0.99877363, 0.00377041],\n",
       "       [0.99740463, 0.00174209],\n",
       "       [0.99825424, 0.00231031],\n",
       "       [0.0119616 , 0.00279912],\n",
       "       [0.01861674, 0.00395448],\n",
       "       [0.01196449, 0.00279896],\n",
       "       [0.01196189, 0.00279912],\n",
       "       [0.01196176, 0.00279921],\n",
       "       [0.01302143, 0.00287779],\n",
       "       [0.9952437 , 0.00143129],\n",
       "       [0.01196363, 0.00279882],\n",
       "       [0.9972933 , 0.9819835 ],\n",
       "       [0.01196119, 0.00279898],\n",
       "       [0.9929114 , 0.00148218],\n",
       "       [0.99809295, 0.00214073],\n",
       "       [0.01196137, 0.00279913],\n",
       "       [0.9972818 , 0.9821108 ],\n",
       "       [0.0119617 , 0.00279914],\n",
       "       [0.01196218, 0.00279923],\n",
       "       [0.01196158, 0.00279909],\n",
       "       [0.9988813 , 0.00480681],\n",
       "       [0.01196163, 0.00279911],\n",
       "       [0.01196192, 0.00279914],\n",
       "       [0.01207811, 0.00280247],\n",
       "       [0.99728227, 0.9821101 ],\n",
       "       [0.01196188, 0.00279915],\n",
       "       [0.99852175, 0.0027924 ],\n",
       "       [0.01196176, 0.00279918],\n",
       "       [0.99830675, 0.00238777],\n",
       "       [0.997282  , 0.98211056],\n",
       "       [0.01383566, 0.00297515],\n",
       "       [0.01196181, 0.0027991 ],\n",
       "       [0.11385954, 0.02433028],\n",
       "       [0.01196235, 0.00279916],\n",
       "       [0.01196273, 0.00279899],\n",
       "       [0.0119698 , 0.00279898],\n",
       "       [0.09210934, 0.02012013],\n",
       "       [0.01196179, 0.00279923],\n",
       "       [0.01242104, 0.00282441],\n",
       "       [0.01968626, 0.00415867],\n",
       "       [0.9987463 , 0.09104366],\n",
       "       [0.99728227, 0.9821095 ],\n",
       "       [0.9978053 , 0.5107022 ],\n",
       "       [0.9963721 , 0.93674076],\n",
       "       [0.99728227, 0.98210764],\n",
       "       [0.9972832 , 0.9821018 ],\n",
       "       [0.9987109 , 0.0034168 ],\n",
       "       [0.9989127 , 0.00522086],\n",
       "       [0.998988  , 0.00917883],\n",
       "       [0.99843603, 0.00260014],\n",
       "       [0.9956393 , 0.00148036],\n",
       "       [0.9975545 , 0.00220375],\n",
       "       [0.9972844 , 0.9820881 ],\n",
       "       [0.9986041 , 0.00302657],\n",
       "       [0.99732447, 0.00171971],\n",
       "       [0.01196686, 0.002799  ],\n",
       "       [0.99812204, 0.00215979],\n",
       "       [0.9985599 , 0.00289355],\n",
       "       [0.04614346, 0.01028965],\n",
       "       [0.9972818 , 0.9821107 ],\n",
       "       [0.01196535, 0.00279894],\n",
       "       [0.01201351, 0.00279921],\n",
       "       [0.01207916, 0.00280291],\n",
       "       [0.01197096, 0.00279872],\n",
       "       [0.9983903 , 0.00251671],\n",
       "       [0.99771035, 0.56368655],\n",
       "       [0.9972824 , 0.98210776],\n",
       "       [0.01196256, 0.00279887],\n",
       "       [0.01963681, 0.00415779],\n",
       "       [0.11392649, 0.02104629],\n",
       "       [0.01217554, 0.00280835],\n",
       "       [0.99748343, 0.00183152],\n",
       "       [0.01196166, 0.00279903],\n",
       "       [0.01196144, 0.00279904],\n",
       "       [0.9988011 , 0.00397456],\n",
       "       [0.99728227, 0.9821095 ],\n",
       "       [0.01196637, 0.00279889],\n",
       "       [0.01196206, 0.00279912],\n",
       "       [0.01205162, 0.00280066],\n",
       "       [0.99864596, 0.00314953],\n",
       "       [0.01196214, 0.00279926],\n",
       "       [0.9972825 , 0.9821056 ],\n",
       "       [0.01196157, 0.00279894],\n",
       "       [0.01196712, 0.00279887],\n",
       "       [0.01196195, 0.00279917],\n",
       "       [0.997291  , 0.9820077 ],\n",
       "       [0.03757961, 0.00839888],\n",
       "       [0.01196252, 0.00279892],\n",
       "       [0.9972844 , 0.9820854 ],\n",
       "       [0.01196155, 0.002799  ],\n",
       "       [0.01196238, 0.00279903],\n",
       "       [0.99728215, 0.98210907],\n",
       "       [0.01196183, 0.0027991 ],\n",
       "       [0.0119619 , 0.00279924],\n",
       "       [0.0119696 , 0.00279881],\n",
       "       [0.01196176, 0.00279913],\n",
       "       [0.99834085, 0.00243724],\n",
       "       [0.99849105, 0.00271478],\n",
       "       [0.99728215, 0.9821073 ],\n",
       "       [0.0119614 , 0.00279899],\n",
       "       [0.99881124, 0.00405337],\n",
       "       [0.01196155, 0.00279908],\n",
       "       [0.9972818 , 0.98211056],\n",
       "       [0.9984073 , 0.00255181],\n",
       "       [0.01196318, 0.00279886],\n",
       "       [0.01196175, 0.00279889],\n",
       "       [0.99489635, 0.00140855],\n",
       "       [0.01196185, 0.00279922],\n",
       "       [0.01196149, 0.00279908],\n",
       "       [0.9894275 , 0.00257983],\n",
       "       [0.9987282 , 0.00350865],\n",
       "       [0.01196175, 0.00279913],\n",
       "       [0.01196153, 0.00279912],\n",
       "       [0.01196179, 0.00279915],\n",
       "       [0.01196137, 0.00279909],\n",
       "       [0.9985341 , 0.00281629],\n",
       "       [0.9986811 , 0.00329722],\n",
       "       [0.99728215, 0.98210883],\n",
       "       [0.99823207, 0.00232261],\n",
       "       [0.01196175, 0.00279913],\n",
       "       [0.9972819 , 0.982111  ],\n",
       "       [0.9972826 , 0.9821049 ],\n",
       "       [0.9972818 , 0.98211056],\n",
       "       [0.01196915, 0.00279887],\n",
       "       [0.01196159, 0.00279913],\n",
       "       [0.01196195, 0.0027988 ],\n",
       "       [0.996558  , 0.95354503],\n",
       "       [0.01196218, 0.00279885],\n",
       "       [0.01196188, 0.00279914],\n",
       "       [0.01196194, 0.00279918],\n",
       "       [0.0119617 , 0.00279913],\n",
       "       [0.01198105, 0.00279889],\n",
       "       [0.01196203, 0.00279928],\n",
       "       [0.9972818 , 0.98211086],\n",
       "       [0.9983046 , 0.00239071],\n",
       "       [0.9954171 , 0.00163705],\n",
       "       [0.01196155, 0.00279917],\n",
       "       [0.01196244, 0.00279899],\n",
       "       [0.99658895, 0.00154704],\n",
       "       [0.997867  , 0.00198982],\n",
       "       [0.01384075, 0.00297739],\n",
       "       [0.99728227, 0.9821103 ],\n",
       "       [0.9984762 , 0.00268424],\n",
       "       [0.9972819 , 0.9821101 ],\n",
       "       [0.9974349 , 0.0017601 ],\n",
       "       [0.998456  , 0.00264278],\n",
       "       [0.9972818 , 0.98211086],\n",
       "       [0.01197486, 0.00279891],\n",
       "       [0.99856865, 0.00291124],\n",
       "       [0.01196154, 0.00279912],\n",
       "       [0.99728286, 0.9821018 ],\n",
       "       [0.998437  , 0.00261163],\n",
       "       [0.01196125, 0.0027991 ],\n",
       "       [0.01196189, 0.00279917],\n",
       "       [0.9972819 , 0.98211133],\n",
       "       [0.01196292, 0.00279893],\n",
       "       [0.01196181, 0.00279917],\n",
       "       [0.9972818 , 0.98211133],\n",
       "       [0.99787045, 0.00197894],\n",
       "       [0.0895341 , 0.02036552],\n",
       "       [0.99728215, 0.9821101 ],\n",
       "       [0.01196189, 0.00279911],\n",
       "       [0.9972818 , 0.982111  ],\n",
       "       [0.9985499 , 0.0028648 ],\n",
       "       [0.9980331 , 0.0021204 ],\n",
       "       [0.99728215, 0.98210895],\n",
       "       [0.9985241 , 0.00279309],\n",
       "       [0.01196181, 0.00279905],\n",
       "       [0.996628  , 0.00156718],\n",
       "       [0.13861653, 0.0257925 ],\n",
       "       [0.99501365, 0.00143944],\n",
       "       [0.9965121 , 0.95135194],\n",
       "       [0.99871004, 0.0034172 ],\n",
       "       [0.0119614 , 0.00279908],\n",
       "       [0.01196189, 0.00279917],\n",
       "       [0.01196149, 0.00279905],\n",
       "       [0.02220592, 0.00482395],\n",
       "       [0.01196179, 0.00279913],\n",
       "       [0.9972819 , 0.9821117 ],\n",
       "       [0.01196207, 0.00279924],\n",
       "       [0.01196182, 0.00279887],\n",
       "       [0.01196376, 0.00279885],\n",
       "       [0.99463993, 0.00161448],\n",
       "       [0.99818903, 0.0022449 ],\n",
       "       [0.9973297 , 0.00171115],\n",
       "       [0.01196185, 0.00279925],\n",
       "       [0.0119626 , 0.00279897],\n",
       "       [0.01196202, 0.00279923],\n",
       "       [0.99728966, 0.98202175],\n",
       "       [0.9965049 , 0.94918877],\n",
       "       [0.9989962 , 0.00975829],\n",
       "       [0.996309  , 0.9211036 ],\n",
       "       [0.9986405 , 0.00336454],\n",
       "       [0.998019  , 0.00208096],\n",
       "       [0.01196166, 0.00279912],\n",
       "       [0.07708997, 0.0171498 ],\n",
       "       [0.9987048 , 0.00339674],\n",
       "       [0.01196242, 0.00279883],\n",
       "       [0.01196167, 0.00279912],\n",
       "       [0.99408144, 0.00140615],\n",
       "       [0.01196172, 0.00279915],\n",
       "       [0.99892104, 0.02346404],\n",
       "       [0.01197087, 0.00279898],\n",
       "       [0.01196212, 0.00279913],\n",
       "       [0.01197325, 0.00279885],\n",
       "       [0.01689313, 0.00352789],\n",
       "       [0.998293  , 0.00236524],\n",
       "       [0.99580234, 0.00144282],\n",
       "       [0.01196131, 0.00279907],\n",
       "       [0.01196175, 0.00279905],\n",
       "       [0.04830277, 0.01109184],\n",
       "       [0.99728227, 0.98210883],\n",
       "       [0.01198313, 0.00279883],\n",
       "       [0.01196151, 0.00279918],\n",
       "       [0.7038368 , 0.03388334],\n",
       "       [0.98761564, 0.00272262],\n",
       "       [0.99889   , 0.00479734],\n",
       "       [0.9989574 , 0.01160203],\n",
       "       [0.99830604, 0.00238463],\n",
       "       [0.9974433 , 0.00175751],\n",
       "       [0.997282  , 0.98211044],\n",
       "       [0.01196223, 0.00279912],\n",
       "       [0.01196157, 0.00279904],\n",
       "       [0.01196191, 0.00279921],\n",
       "       [0.01196805, 0.00279892],\n",
       "       [0.9984623 , 0.00265011],\n",
       "       [0.99707377, 0.96498394],\n",
       "       [0.99836534, 0.0024703 ],\n",
       "       [0.01203951, 0.00280059],\n",
       "       [0.99850625, 0.00274528],\n",
       "       [0.9985324 , 0.00281972],\n",
       "       [0.01198972, 0.0027988 ],\n",
       "       [0.9860101 , 0.01686893],\n",
       "       [0.9972818 , 0.9821107 ],\n",
       "       [0.01196102, 0.00279919],\n",
       "       [0.01196801, 0.00279898],\n",
       "       [0.9972817 , 0.98211145],\n",
       "       [0.01196292, 0.00279884],\n",
       "       [0.9983063 , 0.00238175],\n",
       "       [0.9985954 , 0.00300325],\n",
       "       [0.9987025 , 0.00339169],\n",
       "       [0.01196174, 0.00279924],\n",
       "       [0.01196165, 0.00279897],\n",
       "       [0.01557758, 0.00326488],\n",
       "       [0.99391866, 0.00141645],\n",
       "       [0.12573436, 0.02860495],\n",
       "       [0.99832207, 0.00240633],\n",
       "       [0.0119623 , 0.0027992 ],\n",
       "       [0.9972818 , 0.9821111 ],\n",
       "       [0.99728215, 0.9821102 ],\n",
       "       [0.9983255 , 0.00243141],\n",
       "       [0.9925251 , 0.001509  ],\n",
       "       [0.01196466, 0.00279887],\n",
       "       [0.01196253, 0.00279934],\n",
       "       [0.9983197 , 0.00240422],\n",
       "       [0.01238346, 0.00282088],\n",
       "       [0.998623  , 0.00510992],\n",
       "       [0.99865025, 0.00317934],\n",
       "       [0.01196201, 0.00279906],\n",
       "       [0.01196684, 0.00279893],\n",
       "       [0.01196357, 0.00279915],\n",
       "       [0.99728227, 0.9821092 ],\n",
       "       [0.01196186, 0.00279907],\n",
       "       [0.99858785, 0.00295765],\n",
       "       [0.01196706, 0.00279902],\n",
       "       [0.01196189, 0.00279916],\n",
       "       [0.9972819 , 0.9821107 ],\n",
       "       [0.9972826 , 0.98210573],\n",
       "       [0.9972818 , 0.9821117 ],\n",
       "       [0.01196195, 0.00279912],\n",
       "       [0.9946807 , 0.00140641],\n",
       "       [0.99843556, 0.002614  ],\n",
       "       [0.0121618 , 0.00280808],\n",
       "       [0.98467815, 0.00295391],\n",
       "       [0.997282  , 0.98211104],\n",
       "       [0.997282  , 0.98210984],\n",
       "       [0.99898726, 0.00803055],\n",
       "       [0.9962347 , 0.94651884],\n",
       "       [0.998787  , 0.00387455],\n",
       "       [0.01196197, 0.00279903],\n",
       "       [0.9981421 , 0.00221521],\n",
       "       [0.01196188, 0.00279924],\n",
       "       [0.99728227, 0.9821095 ],\n",
       "       [0.9972818 , 0.9821117 ],\n",
       "       [0.99796104, 0.00202978],\n",
       "       [0.01196355, 0.00279895],\n",
       "       [0.99795353, 0.00202466],\n",
       "       [0.9972819 , 0.98211133],\n",
       "       [0.9986873 , 0.00333491],\n",
       "       [0.9972818 , 0.9821111 ],\n",
       "       [0.997282  , 0.9821108 ],\n",
       "       [0.9986947 , 0.00337757],\n",
       "       [0.0119621 , 0.00279882],\n",
       "       [0.01196167, 0.00279903],\n",
       "       [0.99728227, 0.98210937],\n",
       "       [0.99728525, 0.98208094],\n",
       "       [0.01196166, 0.00279911],\n",
       "       [0.01198548, 0.00279906],\n",
       "       [0.99728215, 0.9821097 ],\n",
       "       [0.9158565 , 0.02269958],\n",
       "       [0.01196821, 0.00279881],\n",
       "       [0.99871373, 0.00343308],\n",
       "       [0.99724185, 0.0016888 ],\n",
       "       [0.998621  , 0.00306961],\n",
       "       [0.01196188, 0.00279925],\n",
       "       [0.99759275, 0.00181016],\n",
       "       [0.99822253, 0.00228259],\n",
       "       [0.99804866, 0.0021013 ],\n",
       "       [0.99832517, 0.00241512],\n",
       "       [0.9972818 , 0.9821112 ],\n",
       "       [0.99610883, 0.00146803],\n",
       "       [0.01196184, 0.00279923],\n",
       "       [0.01197189, 0.00279866],\n",
       "       [0.99880075, 0.00393434],\n",
       "       [0.99584275, 0.00144835],\n",
       "       [0.9972819 , 0.98211056],\n",
       "       [0.01196173, 0.00279908],\n",
       "       [0.011962  , 0.00279897],\n",
       "       [0.01196135, 0.00279915],\n",
       "       [0.99896324, 0.01803659],\n",
       "       [0.9986228 , 0.00307477],\n",
       "       [0.01274208, 0.00285006],\n",
       "       [0.0119622 , 0.00279904],\n",
       "       [0.9965154 , 0.858179  ],\n",
       "       [0.01196477, 0.00279895],\n",
       "       [0.997282  , 0.9821111 ],\n",
       "       [0.01495142, 0.0031488 ],\n",
       "       [0.9990011 , 0.00884306],\n",
       "       [0.99846613, 0.00266423],\n",
       "       [0.0119618 , 0.00279896],\n",
       "       [0.01196164, 0.00279927],\n",
       "       [0.99873656, 0.0035764 ],\n",
       "       [0.01196162, 0.00279887],\n",
       "       [0.9985744 , 0.00291967],\n",
       "       [0.99742657, 0.98004633],\n",
       "       [0.01196723, 0.0027989 ],\n",
       "       [0.99728227, 0.98210895],\n",
       "       [0.99821776, 0.00228731],\n",
       "       [0.9986405 , 0.00313758],\n",
       "       [0.01196799, 0.00279892],\n",
       "       [0.99836797, 0.00249779],\n",
       "       [0.994951  , 0.00142159],\n",
       "       [0.997282  , 0.9821101 ],\n",
       "       [0.9989827 , 0.00948221],\n",
       "       [0.01196222, 0.00279926],\n",
       "       [0.01196247, 0.00279885],\n",
       "       [0.99822325, 0.00227533],\n",
       "       [0.99881387, 0.00413264],\n",
       "       [0.99862504, 0.00308758],\n",
       "       [0.01196233, 0.00279896],\n",
       "       [0.9972819 , 0.9821112 ],\n",
       "       [0.99839896, 0.00253453],\n",
       "       [0.99836856, 0.00249166],\n",
       "       [0.01196194, 0.00279915],\n",
       "       [0.01196189, 0.00279916],\n",
       "       [0.99728227, 0.98210895],\n",
       "       [0.9984048 , 0.00257487],\n",
       "       [0.01196122, 0.00279914],\n",
       "       [0.01196185, 0.00279915],\n",
       "       [0.01196763, 0.00279896],\n",
       "       [0.01206219, 0.00280127],\n",
       "       [0.01988823, 0.00420104],\n",
       "       [0.99874496, 0.00360216],\n",
       "       [0.01196398, 0.00279892],\n",
       "       [0.01196248, 0.00279916],\n",
       "       [0.99728215, 0.9821087 ],\n",
       "       [0.01196205, 0.00279907],\n",
       "       [0.24408898, 0.03364675],\n",
       "       [0.9944596 , 0.00144855],\n",
       "       [0.01196387, 0.00279896],\n",
       "       [0.9964217 , 0.9431759 ],\n",
       "       [0.9959913 , 0.00148386],\n",
       "       [0.9972819 , 0.9821102 ],\n",
       "       [0.99873275, 0.00354792],\n",
       "       [0.01196612, 0.00279917],\n",
       "       [0.99780566, 0.00192961],\n",
       "       [0.99898225, 0.00820669],\n",
       "       [0.9985298 , 0.00280959],\n",
       "       [0.0119619 , 0.00279924],\n",
       "       [0.99728227, 0.9821085 ],\n",
       "       [0.9977233 , 0.00187691],\n",
       "       [0.9980276 , 0.00208747],\n",
       "       [0.9984554 , 0.00264814],\n",
       "       [0.01196612, 0.00279906],\n",
       "       [0.14382207, 0.02702668],\n",
       "       [0.996201  , 0.00152158],\n",
       "       [0.998979  , 0.00730266],\n",
       "       [0.9981207 , 0.00216313],\n",
       "       [0.01196841, 0.0027989 ],\n",
       "       [0.01196192, 0.00279923],\n",
       "       [0.998432  , 0.00263077],\n",
       "       [0.01196212, 0.00279924],\n",
       "       [0.997282  , 0.9821087 ],\n",
       "       [0.99869376, 0.00334599],\n",
       "       [0.01196199, 0.00279914],\n",
       "       [0.997282  , 0.98211104],\n",
       "       [0.0119612 , 0.00279907],\n",
       "       [0.0119617 , 0.00279907],\n",
       "       [0.01196185, 0.00279922],\n",
       "       [0.99677   , 0.00161171],\n",
       "       [0.99728215, 0.98210996],\n",
       "       [0.01196149, 0.00279908],\n",
       "       [0.01196113, 0.00279898],\n",
       "       [0.997412  , 0.00174361],\n",
       "       [0.0131818 , 0.00289433],\n",
       "       [0.9985543 , 0.00286645],\n",
       "       [0.01196162, 0.00279909],\n",
       "       [0.9972819 , 0.9821108 ],\n",
       "       [0.0119619 , 0.00279921],\n",
       "       [0.99728596, 0.9820653 ],\n",
       "       [0.9963163 , 0.9328506 ],\n",
       "       [0.99861646, 0.00305628],\n",
       "       [0.01196196, 0.00279905],\n",
       "       [0.01196293, 0.00279894],\n",
       "       [0.9988348 , 0.00434679],\n",
       "       [0.9984314 , 0.00259955],\n",
       "       [0.99728215, 0.98211104],\n",
       "       [0.9954331 , 0.00153239]], dtype=float32), label_ids=array([0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0,\n",
       "       1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1,\n",
       "       1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 2, 0, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 2, 0], dtype=int64), metrics={'test_loss': 1.091366171836853, 'test_accuracy': 0.6348195329087049, 'test_f1': 0.6377932116830745, 'test_precision': 0.6570620692813152, 'test_recall': 0.6376619105444242, 'test_runtime': 0.4308, 'test_samples_per_second': 1093.193, 'test_steps_per_second': 34.815})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc40eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corn_label_from_logits(logits):\n",
    "    #probas = torch.cumprod(logits, dim=1)\n",
    "    #probas = logits\n",
    "    probas = logits\n",
    "    predict_levels = probas > 0.5\n",
    "    predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f307ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       160\n",
      "           1       0.58      0.52      0.55       189\n",
      "           2       0.77      0.58      0.66       122\n",
      "\n",
      "    accuracy                           0.63       471\n",
      "   macro avg       0.66      0.64      0.64       471\n",
      "weighted avg       0.64      0.63      0.63       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "y_test = test_dataset.labels\n",
    "preds_list = corn_label_from_logits(torch.tensor(predictions.predictions))\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3c6259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coral_pytorch.dataset import proba_to_label\n",
    "\n",
    "def compute_mae_and_mse(label, preds_list):\n",
    "\n",
    "    mae, mse = 0., 0.\n",
    "    num_examples = len(label)\n",
    "    targets = torch.tensor(label)\n",
    "    predicted_labels = torch.tensor(preds_list)\n",
    "    \n",
    "    mae += torch.sum(torch.abs(predicted_labels - targets))\n",
    "    mse += torch.sum((predicted_labels - targets)**2)\n",
    "\n",
    "    mae = mae / num_examples\n",
    "    mse = mse / num_examples\n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eae385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3885)\n",
      "tensor(0.4352)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe68b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9156fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb707c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0176c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2298ffd2",
   "metadata": {},
   "source": [
    "# iw and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149f5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "import pandas as pd\n",
    "\n",
    "def custom_proba_to_label(probas, first_threshold, second_threshold):\n",
    "    predict_levels = pd.DataFrame(probas)\n",
    "    class_O = predict_levels[0].apply(lambda x: x > first_threshold)\n",
    "    class_H = predict_levels[1].apply(lambda x: x > second_threshold)\n",
    "    labels_v3 = pd.concat([class_O, class_H], axis=1)\n",
    "    labels_v3 = labels_v3.sum(axis=1)\n",
    "    return labels_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf32ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel\n",
    "import torch.nn as nn\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = 0.2\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        #self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "        self.coral_layer = CoralLayer(config.hidden_size, config.num_labels)\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        #logits = self.classifier(pooled_output)\n",
    "        logits = self.coral_layer(pooled_output)\n",
    "        probas = torch.sigmoid(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == 'CORAL':\n",
    "                iw = torch.tensor([1, 0.5]).to(device)\n",
    "                loss_fct = CoralLoss()\n",
    "                levels = levels_from_labelbatch(labels.view(-1) , num_classes=3).to(device)\n",
    "                loss = loss_fct(logits, levels, importance_weights=iw)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=probas,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59015e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['coral_layer.coral_bias', 'coral_layer.coral_weights.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, \n",
    "                                                      num_labels=3,\n",
    "                                                      problem_type='CORAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba95898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/', # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    num_train_epochs=10,                # ÌïôÏäµ epoch ÏÑ§Ï†ï\n",
    "    per_device_train_batch_size=4,      # train batch_size ÏÑ§Ï†ï\n",
    "    per_device_eval_batch_size=32,      # test batch_size ÏÑ§Ï†ï\n",
    "    logging_dir='C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/logs/',# ÌïôÏäµlog Ï†ÄÏû•Í≤ΩÎ°ú\n",
    "    logging_steps=500,                  # ÌïôÏäµlog Í∏∞Î°ù Îã®ÏúÑ\n",
    "    save_total_limit=2,                 # ÌïôÏäµÍ≤∞Í≥º Ï†ÄÏû• ÏµúÎåÄÍ∞ØÏàò \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62587ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#model.load_state_dict(torch.load('KcELECTRA_output/KcELECTRA_hate_outputs/pytorch_model.bin'))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # ÌïôÏäµÌïòÍ≥†ÏûêÌïòÎäî ü§ó Transformers model\n",
    "    args=training_args,                  # ÏúÑÏóêÏÑú Ï†ïÏùòÌïú Training Arguments\n",
    "    train_dataset=train_dataset,         # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    eval_dataset=test_dataset,           # ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    "    compute_metrics=compute_metrics,     # ÌèâÍ∞ÄÏßÄÌëú\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ac9491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19740\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19740' max='19740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19740/19740 21:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.885100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.854900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.879700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.734900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.753700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.980900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.993500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.986100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.978100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.985700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.975300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.935100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.839700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.690600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.671300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-19000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-1000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-1000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-19500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-1500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-1500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-2000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-2000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-1000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-2500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-2500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-1500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-3000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-3000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-2000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-3500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-3500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-2500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-4000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-4000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-3000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-4500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-4500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-3500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-5000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-5000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-4000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-5500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-4500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-6000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-6000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-5000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-6500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-6500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-5500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-7000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-7000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-7000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-6000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-7500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-7500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-7500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-6500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-8000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-8000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-8000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-7000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-8500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-8500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-8500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-7500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-9000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-9000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-9000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-8000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-9500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-9500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-9500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-8500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-10000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-10000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-10000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-9000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-10500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-10500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-10500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-9500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-11000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-11000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-11000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-10000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-11500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-11500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-11500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-10500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-12000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-12000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-12000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-11000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-12500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-12500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-12500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-11500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-13000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-13000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-13000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-12000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-13500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-13500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-13500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-12500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-14000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-14000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-14000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-13000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-14500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-14500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-14500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-13500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-15000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-15000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-15000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-14000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-15500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-15500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-15500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-14500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-16000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-16000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-16000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-15000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-16500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-16500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-16500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-15500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-17000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-17000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-17000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-16000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-17500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-17500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-17500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-16500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-18000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-18000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-18000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-17000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-18500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-18500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-18500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-17500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-19000\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-19000\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-19000\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-18000] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-19500\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-19500\\config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/checkpoint-19500\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\USER\\Desktop\\2022_master\\KoBERT\\KcBERT(CORAL)_outputs\\output\\checkpoint-18500] due to args.save_total_limit\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19740, training_loss=0.8487452776598713, metrics={'train_runtime': 1302.1469, 'train_samples_per_second': 60.638, 'train_steps_per_second': 15.16, 'total_flos': 2596882830151680.0, 'train_loss': 0.8487452776598713, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c96191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9886317849159241,\n",
       " 'eval_accuracy': 0.33970276008492567,\n",
       " 'eval_f1': 0.16904384574749076,\n",
       " 'eval_precision': 0.11323425336164189,\n",
       " 'eval_recall': 0.3333333333333333,\n",
       " 'eval_runtime': 0.4568,\n",
       " 'eval_samples_per_second': 1031.135,\n",
       " 'eval_steps_per_second': 32.839,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11fdd243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/\n",
      "Configuration saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/config.json\n",
      "Model weights saved in C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT(CORAL)_outputs/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ad12b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 32\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cc564ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_threshold = custom_proba_to_label(predictions.predictions.tolist(), 0.3, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a5f2858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       160\n",
      "           1       0.58      0.52      0.55       189\n",
      "           2       0.72      0.57      0.64       122\n",
      "\n",
      "    accuracy                           0.63       471\n",
      "   macro avg       0.64      0.63      0.63       471\n",
      "weighted avg       0.63      0.63      0.62       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## classification_report\n",
    "y_test = predictions.label_ids\n",
    "preds_list = predicts_threshold\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, preds_list)\n",
    "print(clf_report)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, preds_list)\n",
    "\n",
    "# Ïò§Ï∞®ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a909ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[0.0201702 , 0.00810584],\n",
       "       [0.8221827 , 0.6473356 ],\n",
       "       [0.861545  , 0.71183723],\n",
       "       [0.76889575, 0.56911176],\n",
       "       [0.7563527 , 0.5520428 ],\n",
       "       [0.9795409 , 0.950017  ],\n",
       "       [0.02081099, 0.00836663],\n",
       "       [0.02024265, 0.00813532],\n",
       "       [0.02019457, 0.00811576],\n",
       "       [0.09039934, 0.0379562 ],\n",
       "       [0.2927595 , 0.14113708],\n",
       "       [0.9338768 , 0.8486389 ],\n",
       "       [0.02028785, 0.00815371],\n",
       "       [0.7271976 , 0.5141442 ],\n",
       "       [0.91697085, 0.8142742 ],\n",
       "       [0.6873844 , 0.46606755],\n",
       "       [0.77251524, 0.5741272 ],\n",
       "       [0.94340307, 0.8687192 ],\n",
       "       [0.7634409 , 0.56162983],\n",
       "       [0.9044221 , 0.7897627 ],\n",
       "       [0.08394334, 0.03510097],\n",
       "       [0.77507925, 0.57770485],\n",
       "       [0.7565168 , 0.552263  ],\n",
       "       [0.75580394, 0.5513067 ],\n",
       "       [0.02361184, 0.00950892],\n",
       "       [0.0201889 , 0.00811345],\n",
       "       [0.76822835, 0.56819135],\n",
       "       [0.97986   , 0.9507735 ],\n",
       "       [0.693492  , 0.47318506],\n",
       "       [0.95972544, 0.9043974 ],\n",
       "       [0.69289964, 0.47249085],\n",
       "       [0.7626713 , 0.5605815 ],\n",
       "       [0.02028163, 0.00815118],\n",
       "       [0.67140424, 0.44786146],\n",
       "       [0.02019574, 0.00811623],\n",
       "       [0.6142811 , 0.38733825],\n",
       "       [0.69151634, 0.47087288],\n",
       "       [0.693069  , 0.47268924],\n",
       "       [0.7583118 , 0.55467737],\n",
       "       [0.0224462 , 0.00903305],\n",
       "       [0.7968174 , 0.6088933 ],\n",
       "       [0.9627577 , 0.9112099 ],\n",
       "       [0.9754902 , 0.94047624],\n",
       "       [0.832528  , 0.66369236],\n",
       "       [0.75597113, 0.55153096],\n",
       "       [0.02268006, 0.00912847],\n",
       "       [0.97867936, 0.9479782 ],\n",
       "       [0.7585052 , 0.5549382 ],\n",
       "       [0.04092214, 0.01665647],\n",
       "       [0.8547069 , 0.7001784 ],\n",
       "       [0.76823115, 0.56819534],\n",
       "       [0.02018596, 0.00811225],\n",
       "       [0.7548558 , 0.55003744],\n",
       "       [0.7576756 , 0.5538206 ],\n",
       "       [0.7622184 , 0.55996555],\n",
       "       [0.79522   , 0.6065479 ],\n",
       "       [0.02035322, 0.00818031],\n",
       "       [0.75587   , 0.5513953 ],\n",
       "       [0.02018427, 0.00811157],\n",
       "       [0.02370119, 0.00954542],\n",
       "       [0.0201672 , 0.00810462],\n",
       "       [0.6937206 , 0.47345325],\n",
       "       [0.02014398, 0.00809518],\n",
       "       [0.16762275, 0.07402611],\n",
       "       [0.975878  , 0.94138455],\n",
       "       [0.02036179, 0.0081838 ],\n",
       "       [0.0535647 , 0.02197412],\n",
       "       [0.6882023 , 0.46701545],\n",
       "       [0.02027038, 0.0081466 ],\n",
       "       [0.9688306 , 0.925034  ],\n",
       "       [0.0202894 , 0.00815434],\n",
       "       [0.02111683, 0.00849117],\n",
       "       [0.0203591 , 0.0081827 ],\n",
       "       [0.9655349 , 0.9175017 ],\n",
       "       [0.02034893, 0.00817856],\n",
       "       [0.04733984, 0.01934543],\n",
       "       [0.07892373, 0.03289714],\n",
       "       [0.83732074, 0.6714098 ],\n",
       "       [0.02353768, 0.00947862],\n",
       "       [0.8903485 , 0.76322585],\n",
       "       [0.02029124, 0.00815509],\n",
       "       [0.8255256 , 0.65257645],\n",
       "       [0.97862816, 0.94785726],\n",
       "       [0.02018908, 0.00811352],\n",
       "       [0.02020429, 0.00811971],\n",
       "       [0.07844195, 0.03268635],\n",
       "       [0.02102543, 0.00845395],\n",
       "       [0.02020138, 0.00811853],\n",
       "       [0.06102977, 0.02515357],\n",
       "       [0.5702998 , 0.34506935],\n",
       "       [0.02026185, 0.00814313],\n",
       "       [0.02018757, 0.00811291],\n",
       "       [0.6936364 , 0.47335452],\n",
       "       [0.7585772 , 0.5550353 ],\n",
       "       [0.97781134, 0.9459293 ],\n",
       "       [0.8475443 , 0.688177  ],\n",
       "       [0.94253355, 0.86686414],\n",
       "       [0.97221214, 0.9328375 ],\n",
       "       [0.978457  , 0.9474527 ],\n",
       "       [0.81420285, 0.63499254],\n",
       "       [0.88601804, 0.75525504],\n",
       "       [0.96065855, 0.90648746],\n",
       "       [0.7618491 , 0.5594636 ],\n",
       "       [0.04323156, 0.01762163],\n",
       "       [0.7415988 , 0.532563  ],\n",
       "       [0.960997  , 0.90724677],\n",
       "       [0.7583425 , 0.5547188 ],\n",
       "       [0.03224699, 0.01305542],\n",
       "       [0.02956639, 0.01195046],\n",
       "       [0.7617556 , 0.5593366 ],\n",
       "       [0.6933367 , 0.473003  ],\n",
       "       [0.3202279 , 0.15754846],\n",
       "       [0.97874683, 0.9481379 ],\n",
       "       [0.65505797, 0.4298382 ],\n",
       "       [0.7542371 , 0.5492104 ],\n",
       "       [0.681968  , 0.45982987],\n",
       "       [0.4318972 , 0.23183596],\n",
       "       [0.6935799 , 0.4732883 ],\n",
       "       [0.96778864, 0.9226448 ],\n",
       "       [0.9675937 , 0.9221988 ],\n",
       "       [0.0217046 , 0.00873065],\n",
       "       [0.05690857, 0.02339464],\n",
       "       [0.02028831, 0.0081539 ],\n",
       "       [0.6921106 , 0.47156742],\n",
       "       [0.06324661, 0.02610347],\n",
       "       [0.0202605 , 0.00814258],\n",
       "       [0.02406639, 0.00969467],\n",
       "       [0.90796864, 0.796607  ],\n",
       "       [0.977164  , 0.94440484],\n",
       "       [0.05987418, 0.02465944],\n",
       "       [0.02018242, 0.00811081],\n",
       "       [0.15197997, 0.0664209 ],\n",
       "       [0.76761293, 0.567344  ],\n",
       "       [0.02020154, 0.00811859],\n",
       "       [0.9784    , 0.9473182 ],\n",
       "       [0.02026615, 0.00814488],\n",
       "       [0.02176449, 0.00875506],\n",
       "       [0.0202526 , 0.00813937],\n",
       "       [0.9604134 , 0.9059378 ],\n",
       "       [0.65191025, 0.42643484],\n",
       "       [0.02052755, 0.00825125],\n",
       "       [0.954513  , 0.89282405],\n",
       "       [0.02032282, 0.00816794],\n",
       "       [0.0257985 , 0.01040344],\n",
       "       [0.96063435, 0.9064332 ],\n",
       "       [0.02017792, 0.00810898],\n",
       "       [0.02046035, 0.0082239 ],\n",
       "       [0.02025436, 0.00814008],\n",
       "       [0.02028267, 0.0081516 ],\n",
       "       [0.7549274 , 0.5501331 ],\n",
       "       [0.8801091 , 0.74452186],\n",
       "       [0.9782024 , 0.9468519 ],\n",
       "       [0.02028993, 0.00815456],\n",
       "       [0.7677485 , 0.5675306 ],\n",
       "       [0.02141908, 0.0086143 ],\n",
       "       [0.978209  , 0.9468674 ],\n",
       "       [0.7564301 , 0.5521467 ],\n",
       "       [0.02081244, 0.00836722],\n",
       "       [0.04511107, 0.01840917],\n",
       "       [0.02020304, 0.0081192 ],\n",
       "       [0.02045438, 0.00822147],\n",
       "       [0.02020577, 0.00812031],\n",
       "       [0.71874416, 0.50359553],\n",
       "       [0.76048464, 0.5576129 ],\n",
       "       [0.05522896, 0.02268038],\n",
       "       [0.02017314, 0.00810704],\n",
       "       [0.02017913, 0.00810947],\n",
       "       [0.0205571 , 0.00826328],\n",
       "       [0.7646403 , 0.5632671 ],\n",
       "       [0.02015875, 0.00810118],\n",
       "       [0.9783811 , 0.9472735 ],\n",
       "       [0.02832807, 0.01144124],\n",
       "       [0.02036111, 0.00818352],\n",
       "       [0.8708828 , 0.728085  ],\n",
       "       [0.8376455 , 0.67193586],\n",
       "       [0.9789342 , 0.948581  ],\n",
       "       [0.02018196, 0.00811063],\n",
       "       [0.02025856, 0.00814179],\n",
       "       [0.02092717, 0.00841394],\n",
       "       [0.79070765, 0.5999695 ],\n",
       "       [0.02022215, 0.00812698],\n",
       "       [0.06052844, 0.02493911],\n",
       "       [0.02691775, 0.01086224],\n",
       "       [0.02055619, 0.00826291],\n",
       "       [0.05520842, 0.02267165],\n",
       "       [0.02022613, 0.0081286 ],\n",
       "       [0.81812775, 0.6410342 ],\n",
       "       [0.7556837 , 0.5511458 ],\n",
       "       [0.6864339 , 0.46496788],\n",
       "       [0.0201876 , 0.00811292],\n",
       "       [0.02105362, 0.00846543],\n",
       "       [0.0565859 , 0.02325731],\n",
       "       [0.7615772 , 0.55909437],\n",
       "       [0.13346627, 0.05762153],\n",
       "       [0.96867377, 0.92467386],\n",
       "       [0.742901  , 0.5342571 ],\n",
       "       [0.8227648 , 0.6482452 ],\n",
       "       [0.7659072 , 0.56500137],\n",
       "       [0.7586863 , 0.5551824 ],\n",
       "       [0.9689993 , 0.92542136],\n",
       "       [0.0210656 , 0.00847031],\n",
       "       [0.6935165 , 0.4732138 ],\n",
       "       [0.02032517, 0.00816889],\n",
       "       [0.8678019 , 0.72268176],\n",
       "       [0.75634915, 0.5520381 ],\n",
       "       [0.02020477, 0.00811991],\n",
       "       [0.02019141, 0.00811447],\n",
       "       [0.9795394 , 0.9500135 ],\n",
       "       [0.03274025, 0.01325914],\n",
       "       [0.02656385, 0.0107171 ],\n",
       "       [0.97922736, 0.94927454],\n",
       "       [0.7729568 , 0.5747418 ],\n",
       "       [0.0548186 , 0.0225061 ],\n",
       "       [0.97860134, 0.94779396],\n",
       "       [0.05002472, 0.02047672],\n",
       "       [0.97937405, 0.94962186],\n",
       "       [0.06909934, 0.02862406],\n",
       "       [0.03815971, 0.01550561],\n",
       "       [0.82899904, 0.6580668 ],\n",
       "       [0.7617244 , 0.5592942 ],\n",
       "       [0.6935919 , 0.47330222],\n",
       "       [0.6481863 , 0.42243585],\n",
       "       [0.8789708 , 0.7424728 ],\n",
       "       [0.7564406 , 0.55216074],\n",
       "       [0.7525804 , 0.5470018 ],\n",
       "       [0.8769632 , 0.7388737 ],\n",
       "       [0.7590998 , 0.55574036],\n",
       "       [0.02028014, 0.00815057],\n",
       "       [0.02060702, 0.0082836 ],\n",
       "       [0.7003028 , 0.48122928],\n",
       "       [0.02021581, 0.0081244 ],\n",
       "       [0.97908825, 0.9489454 ],\n",
       "       [0.0202251 , 0.00812818],\n",
       "       [0.02016385, 0.00810326],\n",
       "       [0.02072428, 0.00833133],\n",
       "       [0.7634032 , 0.5615784 ],\n",
       "       [0.6919176 , 0.4713417 ],\n",
       "       [0.69361186, 0.47332573],\n",
       "       [0.02021977, 0.00812601],\n",
       "       [0.06744222, 0.02790851],\n",
       "       [0.02028736, 0.00815351],\n",
       "       [0.9062657 , 0.7933126 ],\n",
       "       [0.92467946, 0.8297472 ],\n",
       "       [0.87426907, 0.7340728 ],\n",
       "       [0.69401014, 0.4737931 ],\n",
       "       [0.74369615, 0.5352938 ],\n",
       "       [0.7663378 , 0.5655918 ],\n",
       "       [0.02042711, 0.00821038],\n",
       "       [0.02048447, 0.00823372],\n",
       "       [0.7616524 , 0.55919653],\n",
       "       [0.02040941, 0.00820317],\n",
       "       [0.02021824, 0.00812538],\n",
       "       [0.07068928, 0.02931201],\n",
       "       [0.02020346, 0.00811937],\n",
       "       [0.68173856, 0.4595671 ],\n",
       "       [0.02015533, 0.00809979],\n",
       "       [0.02027053, 0.00814666],\n",
       "       [0.03283918, 0.01330001],\n",
       "       [0.08412345, 0.03518032],\n",
       "       [0.6938878 , 0.47364953],\n",
       "       [0.62466544, 0.39784318],\n",
       "       [0.02026265, 0.00814346],\n",
       "       [0.02019986, 0.00811791],\n",
       "       [0.75686747, 0.5527339 ],\n",
       "       [0.975419  , 0.94030946],\n",
       "       [0.02041252, 0.00820444],\n",
       "       [0.02556009, 0.0103058 ],\n",
       "       [0.06292965, 0.02596749],\n",
       "       [0.6681687 , 0.44424674],\n",
       "       [0.6904923 , 0.46967807],\n",
       "       [0.74722326, 0.5399146 ],\n",
       "       [0.85251373, 0.6964808 ],\n",
       "       [0.08939535, 0.03751063],\n",
       "       [0.769351  , 0.5697404 ],\n",
       "       [0.61131835, 0.3843793 ],\n",
       "       [0.02020786, 0.00812116],\n",
       "       [0.03356062, 0.01359823],\n",
       "       [0.05676274, 0.02333257],\n",
       "       [0.68737346, 0.46605474],\n",
       "       [0.8894694 , 0.7616005 ],\n",
       "       [0.69311315, 0.47274104],\n",
       "       [0.6690063 , 0.44518015],\n",
       "       [0.8955367 , 0.7728947 ],\n",
       "       [0.77893376, 0.5831226 ],\n",
       "       [0.04927543, 0.02016063],\n",
       "       [0.07831476, 0.03263072],\n",
       "       [0.97977567, 0.95057344],\n",
       "       [0.02025909, 0.00814201],\n",
       "       [0.21298616, 0.09701178],\n",
       "       [0.8667283 , 0.7208087 ],\n",
       "       [0.03007692, 0.01216062],\n",
       "       [0.87368083, 0.7330289 ],\n",
       "       [0.9782217 , 0.94689745],\n",
       "       [0.757458  , 0.55352783],\n",
       "       [0.0203687 , 0.0081866 ],\n",
       "       [0.02118437, 0.00851868],\n",
       "       [0.3999698 , 0.20925045],\n",
       "       [0.7607248 , 0.5579383 ],\n",
       "       [0.67496264, 0.4518642 ],\n",
       "       [0.07208417, 0.02991671],\n",
       "       [0.02286832, 0.0092053 ],\n",
       "       [0.97940654, 0.9496988 ],\n",
       "       [0.86833906, 0.7236209 ],\n",
       "       [0.49549633, 0.28052202],\n",
       "       [0.6918548 , 0.47126833],\n",
       "       [0.02258334, 0.009089  ],\n",
       "       [0.02017661, 0.00810845],\n",
       "       [0.6924629 , 0.47197956],\n",
       "       [0.69099855, 0.4702685 ],\n",
       "       [0.2705465 , 0.12834072],\n",
       "       [0.4403032 , 0.2379793 ],\n",
       "       [0.02205354, 0.00887291],\n",
       "       [0.02218483, 0.00892644],\n",
       "       [0.02018178, 0.00811055],\n",
       "       [0.9782184 , 0.9468895 ],\n",
       "       [0.02794701, 0.0112847 ],\n",
       "       [0.762966  , 0.56098276],\n",
       "       [0.02062298, 0.00829009],\n",
       "       [0.02026871, 0.00814592],\n",
       "       [0.97672087, 0.9433628 ],\n",
       "       [0.96571076, 0.9179017 ],\n",
       "       [0.9719776 , 0.9322938 ],\n",
       "       [0.02021619, 0.00812455],\n",
       "       [0.23710752, 0.10983165],\n",
       "       [0.02137305, 0.00859555],\n",
       "       [0.02040843, 0.00820277],\n",
       "       [0.757687  , 0.5538359 ],\n",
       "       [0.9792508 , 0.9493301 ],\n",
       "       [0.9787371 , 0.9481148 ],\n",
       "       [0.97087204, 0.9297358 ],\n",
       "       [0.683386  , 0.46145624],\n",
       "       [0.7673628 , 0.5669999 ],\n",
       "       [0.61666   , 0.3897263 ],\n",
       "       [0.74502695, 0.5370331 ],\n",
       "       [0.02026691, 0.00814519],\n",
       "       [0.85526276, 0.70111865],\n",
       "       [0.94080746, 0.8631951 ],\n",
       "       [0.39126277, 0.20328863],\n",
       "       [0.02076354, 0.00834731],\n",
       "       [0.8714039 , 0.7290031 ],\n",
       "       [0.9796387 , 0.9502489 ],\n",
       "       [0.9694912 , 0.9265524 ],\n",
       "       [0.9791397 , 0.94906706],\n",
       "       [0.91299725, 0.80642337],\n",
       "       [0.7641535 , 0.56260204],\n",
       "       [0.53730005, 0.31553227],\n",
       "       [0.02039089, 0.00819563],\n",
       "       [0.95490265, 0.8936832 ],\n",
       "       [0.8290267 , 0.6581109 ],\n",
       "       [0.02031283, 0.00816387],\n",
       "       [0.02516209, 0.01014285],\n",
       "       [0.9237753 , 0.8279155 ],\n",
       "       [0.6926701 , 0.47222197],\n",
       "       [0.02111076, 0.0084887 ],\n",
       "       [0.970794  , 0.9295557 ],\n",
       "       [0.02140147, 0.00860712],\n",
       "       [0.02017993, 0.0081098 ],\n",
       "       [0.02092846, 0.00841446],\n",
       "       [0.76090324, 0.55818015],\n",
       "       [0.6833721 , 0.4614402 ],\n",
       "       [0.02396539, 0.00965339],\n",
       "       [0.7619391 , 0.55958587],\n",
       "       [0.97978735, 0.9506012 ],\n",
       "       [0.686832  , 0.4654282 ],\n",
       "       [0.02017868, 0.00810929],\n",
       "       [0.6847076 , 0.46297613],\n",
       "       [0.6877537 , 0.4664953 ],\n",
       "       [0.02236816, 0.00900122],\n",
       "       [0.6911192 , 0.4704092 ],\n",
       "       [0.02026131, 0.00814291],\n",
       "       [0.0203394 , 0.00817468],\n",
       "       [0.02022696, 0.00812893],\n",
       "       [0.93619263, 0.8534717 ],\n",
       "       [0.8297037 , 0.65918636],\n",
       "       [0.7547528 , 0.54989964],\n",
       "       [0.0208728 , 0.0083918 ],\n",
       "       [0.7631516 , 0.56123555],\n",
       "       [0.02052975, 0.00825214],\n",
       "       [0.9673117 , 0.9215534 ],\n",
       "       [0.02028521, 0.00815263],\n",
       "       [0.7965148 , 0.60844815],\n",
       "       [0.9020212 , 0.78516597],\n",
       "       [0.02032301, 0.00816801],\n",
       "       [0.02028814, 0.00815383],\n",
       "       [0.6897958 , 0.46886688],\n",
       "       [0.03711369, 0.01507084],\n",
       "       [0.02311249, 0.00930498],\n",
       "       [0.7562859 , 0.5519531 ],\n",
       "       [0.03755141, 0.0152527 ],\n",
       "       [0.9422313 , 0.8662203 ],\n",
       "       [0.69232243, 0.4718152 ],\n",
       "       [0.69276226, 0.47232994],\n",
       "       [0.68648297, 0.46502453],\n",
       "       [0.65418714, 0.42889452],\n",
       "       [0.66876495, 0.44491103],\n",
       "       [0.9746669 , 0.93855083],\n",
       "       [0.7656818 , 0.56469244],\n",
       "       [0.02066841, 0.00830859],\n",
       "       [0.02447299, 0.00986092],\n",
       "       [0.6597284 , 0.43492764],\n",
       "       [0.97917706, 0.9491555 ],\n",
       "       [0.75680935, 0.5526559 ],\n",
       "       [0.02022167, 0.00812678],\n",
       "       [0.9782938 , 0.9470676 ],\n",
       "       [0.7764024 , 0.57955927],\n",
       "       [0.7721324 , 0.5735947 ],\n",
       "       [0.02021111, 0.00812248],\n",
       "       [0.02026043, 0.00814255],\n",
       "       [0.97777927, 0.94585377],\n",
       "       [0.767984  , 0.56785476],\n",
       "       [0.02027809, 0.00814974],\n",
       "       [0.02028735, 0.00815351],\n",
       "       [0.03036411, 0.0122789 ],\n",
       "       [0.6705478 , 0.44690225],\n",
       "       [0.02138507, 0.00860044],\n",
       "       [0.6893011 , 0.4682914 ],\n",
       "       [0.02045278, 0.00822082],\n",
       "       [0.23325305, 0.10775397],\n",
       "       [0.8777239 , 0.7402353 ],\n",
       "       [0.02106363, 0.00846951],\n",
       "       [0.02031784, 0.00816591],\n",
       "       [0.66190064, 0.4373109 ],\n",
       "       [0.07647542, 0.03182729],\n",
       "       [0.75695795, 0.5528555 ],\n",
       "       [0.6865273 , 0.46507576],\n",
       "       [0.7741769 , 0.5764434 ],\n",
       "       [0.69342506, 0.47310662],\n",
       "       [0.02018924, 0.00811359],\n",
       "       [0.75690436, 0.5527834 ],\n",
       "       [0.78425276, 0.59067714],\n",
       "       [0.9255578 , 0.83153075],\n",
       "       [0.02121659, 0.00853181],\n",
       "       [0.96904415, 0.92552453],\n",
       "       [0.68252146, 0.46046406],\n",
       "       [0.7233951 , 0.50937563],\n",
       "       [0.7773996 , 0.5809606 ],\n",
       "       [0.02334445, 0.0093997 ],\n",
       "       [0.08031753, 0.03350767],\n",
       "       [0.7552691 , 0.55059046],\n",
       "       [0.8610756 , 0.7110305 ],\n",
       "       [0.6870366 , 0.46566486],\n",
       "       [0.0408538 , 0.01662795],\n",
       "       [0.68916214, 0.4681299 ],\n",
       "       [0.05634629, 0.02315536],\n",
       "       [0.02020361, 0.00811943],\n",
       "       [0.7827583 , 0.5885453 ],\n",
       "       [0.9696102 , 0.92682624],\n",
       "       [0.6800908 , 0.4576841 ],\n",
       "       [0.9727542 , 0.93409556],\n",
       "       [0.02023594, 0.00813259],\n",
       "       [0.02025204, 0.00813914],\n",
       "       [0.02023153, 0.00813079],\n",
       "       [0.75830054, 0.5546622 ],\n",
       "       [0.9520104 , 0.8873279 ],\n",
       "       [0.02039748, 0.00819832],\n",
       "       [0.0202716 , 0.0081471 ],\n",
       "       [0.6803919 , 0.45802775],\n",
       "       [0.02065893, 0.00830473],\n",
       "       [0.755242  , 0.5505541 ],\n",
       "       [0.02017687, 0.00810855],\n",
       "       [0.93618983, 0.85346574],\n",
       "       [0.02016069, 0.00810197],\n",
       "       [0.7666033 , 0.56595623],\n",
       "       [0.97595584, 0.94156736],\n",
       "       [0.6929072 , 0.47249967],\n",
       "       [0.02034754, 0.00817799],\n",
       "       [0.49986687, 0.28406408],\n",
       "       [0.8818458 , 0.7476594 ],\n",
       "       [0.07754189, 0.0322929 ],\n",
       "       [0.7965987 , 0.6085715 ],\n",
       "       [0.77771914, 0.5814102 ]], dtype=float32), label_ids=array([0, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0,\n",
       "       1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0,\n",
       "       2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1,\n",
       "       1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2,\n",
       "       1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2,\n",
       "       2, 0, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1,\n",
       "       1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 0, 1, 2,\n",
       "       1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 2, 0, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 2, 0], dtype=int64), metrics={'test_loss': 0.9886317849159241, 'test_accuracy': 0.33970276008492567, 'test_f1': 0.16904384574749076, 'test_precision': 0.11323425336164189, 'test_recall': 0.3333333333333333, 'test_runtime': 0.4638, 'test_samples_per_second': 1015.61, 'test_steps_per_second': 32.344})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd69ee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3992)\n",
      "tensor(0.4544)\n"
     ]
    }
   ],
   "source": [
    "mae, mse = compute_mae_and_mse(y_test, preds_list)\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb23e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de08d293",
   "metadata": {},
   "source": [
    "# kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565427c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_hate_df = pd.read_csv(data_path+\"kaggle_hate_test.txt\", sep='\\t')\n",
    "tokenized_test_sentences = tokenizer(\n",
    "                            list(kaggle_hate_df['comments']),\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=64,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d45910",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label =  kaggle_hate_df[\"hate\"].values\n",
    "test_dataset = MyDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c85a8432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f3fccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "model_path = 'C:/Users/USER/Desktop/2022_master/KoBERT/KcBERT_CORN_outputs/output/pytorch_model.bin'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # ÌïôÏäµÌïòÍ≥†ÏûêÌïòÎäî ü§ó Transformers model                # ÏúÑÏóêÏÑú Ï†ïÏùòÌïú Training Arguments\n",
    "    eval_dataset=test_dataset           # ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b439d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 974\n",
      "  Batch size = 8\n",
      "C:\\Users\\USER\\anaconda3\\envs\\badText10-KcBERT\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122/122 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0cda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corn_label_from_logits(logits):\n",
    "    probas = torch.cumprod(logits, dim=1)\n",
    "    probas = logits\n",
    "    predict_levels = probas > 0.5\n",
    "    predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc5456b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = corn_label_from_logits(torch.tensor(predictions.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "096015d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>„Öã„Öã„Öã„Öã Í∑∏ÎûòÎèÑ Ï°∞ÏïÑÌï¥Ï£ºÎäî Ìå¨Îì§ ÎßéÏïÑÏÑú Ï¢ãÍ≤†Îã§ „Ö†„Ö† ÎãàÎì§ÏùÄ Ïò®Ïú†Í∞Ä ÏïàÎßåÏ†∏Ï§å „Ö†„Ö†</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÎëòÎã§ ÎÑò Ï¢ãÎã§~ÌñâÎ≥µÌïòÏÑ∏Ïöî</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Í∑ºÎç∞ ÎßåÏõêÏù¥ÌïòÎäî ÌòÑÍ∏àÍ≤∞Ï†úÎßå ÌïòÎùºÍ≥† Ïç®ÎÜìÏùÄÏßë Ïö∞Î¶¨ÎÇòÎùºÏóê ÏóÑÏ≤≠ ÎßéÏùÄÎç∞</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ÏõêÍ≥°ÏÉùÍ∞ÅÌïòÎÇòÎèÑ ÏïàÎÇòÍ≥† Îü¨Î∏îÎ¶¨Ï¶à Ïã†Í≥°ÎÇòÏò®Ï§Ñ!!! ÎÑàÎ¨¥ ÏòàÏÅòÍ≤å ÏûòÎ¥§Ïñ¥Ïöî</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ïû•ÌòÑÏäπ ÏñòÎèÑ Ï∞∏ Ïù¥Ï†† Ïß†ÌïòÎã§...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>ÎåÄÎ∞ï Í≤åÏä§Ìä∏... Íº≠ Î¥êÏïºÏßï~ Ïª®ÏÖâÏù¥ Î∞îÎÄåÎãàÍπê Ïû¨ÎØ∏ÏßÄÎÑπ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>ÏÑ±ÌòïÏúºÎ°ú Îã§ ÎúØÏñ¥Í≥†Ï≥êÎÜìÍ≥† ÏòàÏÅúÏ≤ô. ÏÑ±Ìòï Ï†Ñ Îãà ÏñºÍµ¥ Îã§ ÏïåÍ≥†ÏûàÎã§. ÏàúÏûêÏ≤òÎüº ÎêúÏû•ÎÉÑÏÉà...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Î∂ÑÏúÑÍ∏∞Îäî ÎπÑÏä∑ÌïòÎã§Îßå Ï†ÑÌòÄÎã§Î•∏ Ï†ÑÍ∞úÎçòÎç∞ Î¨¥Ïä®„Öã„Öã„Ñ± Ïö∞Î¶¨ÎÇòÎùºÏÇ¨ÎûåÎì§ÏùÄ Î∂ÑÏúÑÍ∏∞Îßå ÎπÑÏä∑ÌïòÎ©¥ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>ÏûÖÏóê ÏÜêÍ∞ÄÎ¶≠Ïù¥ 10Í∞ú ÏûàÏúºÎãà ÏßïÍ∑∏ÎüΩÎã§</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>ÎÇú Ï°∞Î≥¥ÏïÑ Ïù¥ÎªêÏÑú Î≥¥ÎäîÎç∞ Î∞±Ï¢ÖÏõê Í¥ÄÏã¨Î¨¥</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  label\n",
       "0         „Öã„Öã„Öã„Öã Í∑∏ÎûòÎèÑ Ï°∞ÏïÑÌï¥Ï£ºÎäî Ìå¨Îì§ ÎßéÏïÑÏÑú Ï¢ãÍ≤†Îã§ „Ö†„Ö† ÎãàÎì§ÏùÄ Ïò®Ïú†Í∞Ä ÏïàÎßåÏ†∏Ï§å „Ö†„Ö†      1\n",
       "1                                        ÎëòÎã§ ÎÑò Ï¢ãÎã§~ÌñâÎ≥µÌïòÏÑ∏Ïöî      0\n",
       "2                 Í∑ºÎç∞ ÎßåÏõêÏù¥ÌïòÎäî ÌòÑÍ∏àÍ≤∞Ï†úÎßå ÌïòÎùºÍ≥† Ïç®ÎÜìÏùÄÏßë Ïö∞Î¶¨ÎÇòÎùºÏóê ÏóÑÏ≤≠ ÎßéÏùÄÎç∞      1\n",
       "3                ÏõêÍ≥°ÏÉùÍ∞ÅÌïòÎÇòÎèÑ ÏïàÎÇòÍ≥† Îü¨Î∏îÎ¶¨Ï¶à Ïã†Í≥°ÎÇòÏò®Ï§Ñ!!! ÎÑàÎ¨¥ ÏòàÏÅòÍ≤å ÏûòÎ¥§Ïñ¥Ïöî      0\n",
       "4                                   Ïû•ÌòÑÏäπ ÏñòÎèÑ Ï∞∏ Ïù¥Ï†† Ïß†ÌïòÎã§...      0\n",
       "..                                                 ...    ...\n",
       "969                     ÎåÄÎ∞ï Í≤åÏä§Ìä∏... Íº≠ Î¥êÏïºÏßï~ Ïª®ÏÖâÏù¥ Î∞îÎÄåÎãàÍπê Ïû¨ÎØ∏ÏßÄÎÑπ      0\n",
       "970  ÏÑ±ÌòïÏúºÎ°ú Îã§ ÎúØÏñ¥Í≥†Ï≥êÎÜìÍ≥† ÏòàÏÅúÏ≤ô. ÏÑ±Ìòï Ï†Ñ Îãà ÏñºÍµ¥ Îã§ ÏïåÍ≥†ÏûàÎã§. ÏàúÏûêÏ≤òÎüº ÎêúÏû•ÎÉÑÏÉà...      2\n",
       "971  Î∂ÑÏúÑÍ∏∞Îäî ÎπÑÏä∑ÌïòÎã§Îßå Ï†ÑÌòÄÎã§Î•∏ Ï†ÑÍ∞úÎçòÎç∞ Î¨¥Ïä®„Öã„Öã„Ñ± Ïö∞Î¶¨ÎÇòÎùºÏÇ¨ÎûåÎì§ÏùÄ Î∂ÑÏúÑÍ∏∞Îßå ÎπÑÏä∑ÌïòÎ©¥ ...      0\n",
       "972                               ÏûÖÏóê ÏÜêÍ∞ÄÎ¶≠Ïù¥ 10Í∞ú ÏûàÏúºÎãà ÏßïÍ∑∏ÎüΩÎã§      2\n",
       "973                              ÎÇú Ï°∞Î≥¥ÏïÑ Ïù¥ÎªêÏÑú Î≥¥ÎäîÎç∞ Î∞±Ï¢ÖÏõê Í¥ÄÏã¨Î¨¥      1\n",
       "\n",
       "[974 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(preds_list)\n",
    "kaggle_df = pd.concat([kaggle_hate_df['comments'], pred_df[0]], axis=1)\n",
    "kaggle_df.columns = ['comments', 'label']\n",
    "kaggle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e9c7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv(\"kaggle_hate_KcBERT_CORN.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badText10-KcBERT",
   "language": "python",
   "name": "badtext10-kcbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
